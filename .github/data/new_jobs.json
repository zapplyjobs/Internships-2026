[
  {
    "job_title": "",
    "employer_name": "AgZen",
    "job_city": "Cambridge",
    "job_state": "MA",
    "job_description": ".fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-mobile-site-gutter, 6vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (8 - 1)) ) / 8 ); display: grid; position: relative; grid-area: 1/1/-1/-1; grid-template-rows: repeat(12,minmax(24px, auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(8, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); row-gap: 11.0px; column-gap: 11.0px; overflow-x: hidden; overflow-x: clip; } @media (min-width: 768px) { .background-width--inset .fe-681e70c2a649507003c3aab5 { --inset-padding: calc(var(--sqs-site-gutter) * 2); } .fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-site-gutter, 4vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (24 - 1)) ) / 24 ); --inset-padding: 0vw; --row-height-scaling-factor: 0.0215; --container-width: min(var(--sqs-site-max-width, 1500px), calc(100vw - var(--sqs-site-gutter, 4vw) * 2 - var(--inset-padding) )); grid-template-rows: repeat(13,minmax(calc(var(--container-width) * var(--row-height-scaling-factor)), auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(24, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); } } .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/7/10; z-index: 1; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/2/26; z-index: 2; position: sticky; top: calc(0px + var(--header-fixed-top-offset, 0px)); } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } } .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 7/2/13/10; z-index: 2; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 2/2/7/26; z-index: 1; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } }",
    "job_apply_link": "https://www.agzen.com/jobs?gh_jid=4048593009",
    "job_posted_at_datetime_utc": "2025-10-21T00:25:19.000Z",
    "job_employment_type": "FULLTIME",
    "job_posted_at": "1h",
    "id": "agzen--cambridge",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Engineering Manager, Detection and Response",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5071506008",
    "job_posted_at_datetime_utc": "2026-01-15T20:08:22-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We are seeking a Detection and Response Engineering Manager to lead our Detection and Response teams in creating comprehensive Security Observability, Detection Lifecycle, and Security Incident Response programs for Anthropic. You will collaborate closely with teams and leaders across Anthropic, focusing on the observability, detection, investigation, incident response, and intelligence portions of the security lifecycle. You will collaborate closely with preventative security engineering teams and other cross-functional teams. What you’ll do: Manage and grow a high-performing D&R team, planning strategy and hiring to support Anthropic's rapid growth and unique AI safety requirements Navigate prioritization in a fast-paced frontier environment, balancing operational demands with building innovative, scalable solutions for the future Collaborate across security engineering teams to build comprehensive prevention, observability, detection, and response capabilities throughout the security lifecycle Facilitate development of scalable, AI-leveraged D&R solutions that enable self-service observability and detection capabilities across Anthropic Build partnerships with product, infrastructure, and research teams to instill security monitoring best practices Own and continuously improve Security Incident Response, Data Management, and Detection Engineering policies and playbooks Continuously drive capability maturity across the detection lifecycle, establishing metrics and KPIs to measure effectiveness Who you are: 10+ years building detection and response capabilities in a cloud-native organization 5+ years of engineering management experience with a proven track record of building and scaling security teams Deep understanding of security monitoring, threat detection, incident response, and forensics best practices Experienced in securing complex cloud environments (Kubernetes, AWS/GCP) with modern detection technologies Knowledgeable in AI/ML security risks, detection patterns, and response strategies Strong verbal and written communication skills with the ability to distill complex security topics Skilled at collaborating cross-functionally and effectively balancing security requirements with business objectives Able to drive high-impact work while incorporating feedback and adapting to changing priorities Passionate about building diverse, high-performing teams and growing engineers in a fast-paced environment Low ego, high empathy, and have a track record as a talent magnet who attracts and retains top security talent Deadline to apply: None, applications will be received on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$405,000 - $485,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-engineering-manager-detection-and-response-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5071506008",
    "title": "Engineering Manager, Detection and Response",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5071506008",
    "departments": [
      "Security"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T20:08:22-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;We are seeking a Detection and Response Engineering Manager to lead our Detection and Response teams in creating comprehensive Security Observability, Detection Lifecycle, and Security Incident Response programs for Anthropic. You will collaborate closely with teams and leaders across Anthropic, focusing on the observability, detection, investigation, incident response, and intelligence portions of the security lifecycle. You will collaborate closely with preventative security engineering teams and other cross-functional teams.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;What you’ll do:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Manage and grow a high-performing D&amp;amp;R team, planning strategy and hiring to support Anthropic&#39;s rapid growth and unique AI safety requirements&lt;/li&gt;\n&lt;li&gt;Navigate prioritization in a fast-paced frontier environment, balancing operational demands with building innovative, scalable solutions for the future&lt;/li&gt;\n&lt;li&gt;Collaborate across security engineering teams to build comprehensive prevention, observability, detection, and response capabilities throughout the security lifecycle&lt;/li&gt;\n&lt;li&gt;Facilitate development of scalable, AI-leveraged D&amp;amp;R solutions that enable self-service observability and detection capabilities across Anthropic&lt;/li&gt;\n&lt;li&gt;Build partnerships with product, infrastructure, and research teams to instill security monitoring best practices&lt;/li&gt;\n&lt;li&gt;Own and continuously improve Security Incident Response, Data Management, and Detection Engineering policies and playbooks&lt;/li&gt;\n&lt;li&gt;Continuously drive capability maturity across the detection lifecycle, establishing metrics and KPIs to measure effectiveness&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Who you are:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;10+ years building detection and response capabilities in a cloud-native organization&lt;/li&gt;\n&lt;li&gt;5+ years of engineering management experience with a proven track record of building and scaling security teams&lt;/li&gt;\n&lt;li&gt;Deep understanding of security monitoring, threat detection, incident response, and forensics best practices&lt;/li&gt;\n&lt;li&gt;Experienced in securing complex cloud environments (Kubernetes, AWS/GCP) with modern detection technologies&lt;/li&gt;\n&lt;li&gt;Knowledgeable in AI/ML security risks, detection patterns, and response strategies&lt;/li&gt;\n&lt;li&gt;Strong verbal and written communication skills with the ability to distill complex security topics&lt;/li&gt;\n&lt;li&gt;Skilled at collaborating cross-functionally and effectively balancing security requirements with business objectives&lt;/li&gt;\n&lt;li&gt;Able to drive high-impact work while incorporating feedback and adapting to changing priorities&lt;/li&gt;\n&lt;li&gt;Passionate about building diverse, high-performing teams and growing engineers in a fast-paced environment&lt;/li&gt;\n&lt;li&gt;Low ego, high empathy, and have a track record as a talent magnet who attracts and retains top security talent&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None, applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$405,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$485,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5071506008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Product Manager, Learning",
    "employer_name": "duolingo",
    "job_city": "New York, NY",
    "job_apply_link": "https://careers.duolingo.com/jobs/8377539002?gh_jid=8377539002",
    "job_posted_at_datetime_utc": "2026-01-15T19:43:04-05:00",
    "job_description": "Develop the best education in the world and make it universally available.",
    "id": "duolingo-senior-product-manager-learning-new-york-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "8377539002",
    "title": "Senior Product Manager, Learning",
    "company_name": "duolingo",
    "company_slug": "duolingo",
    "location": "New York, NY",
    "locations": [
      "New York, NY"
    ],
    "url": "https://careers.duolingo.com/jobs/8377539002?gh_jid=8377539002",
    "departments": [
      "Product Management"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:43:04-05:00",
    "fetched_at": "2026-01-17T04:05:20.664Z",
    "description": "&lt;p&gt;Duolingo is the world&#39;s most popular learning app. Beyond our core learning product, we also offer English proficiency testing with the Duolingo English Test, and are bringing new subjects into the Duolingo app, where people can develop their Math and Music skills.&lt;/p&gt;\n&lt;p&gt;We are passionate about educating our users, making fact-based decisions, and finding innovative solutions to complex problems. We offer meaningful work, limitless learning opportunities, and collaboration with world-class minds. Come brighten your life and over half a billion more!&lt;/p&gt;\n&lt;p&gt;You&#39;ll be a product manager in our Learning Pillar and will be responsible for developing products that make learning a new language fun and effective, regardless of one&#39;s level. We&#39;ve recently introduced a number of new ways to learn, including Stories, DuoRadio, Adventures, and Video Call, and are always looking for better ways to teach. You will partner with your cross-functional peers to build delightful learning experiences, shape our overall learning strategy, and impact the lives of tens of millions of learners.&lt;/p&gt;\n&lt;hr&gt;\n&lt;h4&gt;&lt;strong&gt;:brain: &lt;/strong&gt;&lt;strong&gt;You Will...&lt;/strong&gt;&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;Be responsible for improving the learning experience through delightful and impactful products&lt;/li&gt;\n&lt;li&gt;Drive product features through their entire creative cycle: ideation, specification, development, release, analysis, and iteration&lt;/li&gt;\n&lt;li&gt;Establish the strategy for your focus area, and build alignment across product teams, cross-functional partners, and the leadership team&lt;/li&gt;\n&lt;li&gt;Perform qualitative and quantitative research to explore and validate feature ideas&lt;/li&gt;\n&lt;li&gt;Work with engineers to help guide feature development&lt;/li&gt;\n&lt;li&gt;Perform experiment analysis on features and find opportunities for optimization&lt;/li&gt;\n&lt;li&gt;Execute with urgency and excellence&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h4&gt;&lt;strong&gt;:check: You have...&lt;/strong&gt;&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;A desire to make the world a better place through technology and education&lt;/li&gt;\n&lt;li&gt;Experience generating outstanding results as a product manager&lt;/li&gt;\n&lt;li&gt;Ability to utilize user insights, data, and statistical analyses to inform decisions&lt;/li&gt;\n&lt;li&gt;Top-tier design sense -- every pixel matters at Duolingo&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to be resourceful, curious, and innovative&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;&lt;strong&gt;We post a multi-level salary range for all of our roles.&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;This is not inclusive of the rest of our awesome portfolio that includes equity compensation and world-class benefits. Our salary ranges are the same for all US locations. Your recruiter can share more details about the range for a specific level during the hiring process. &lt;/em&gt;&lt;em&gt;The actual salary within the range is determined by many factors including but not limited to, skills, experience, education, and internal equity.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Salary Range: &lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$177,700&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$240,400 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;p class=&quot;Z7ph2&quot;&gt;Take a peek at how we care for our employees&#39; holistic well-being with our benefits&lt;a class=&quot;Z7ph2&quot; href=&quot;https://careers.duolingo.com/#benefits&quot;&gt;&amp;nbsp;here&lt;/a&gt;.&lt;/p&gt;\n&lt;p class=&quot;Z7ph2&quot;&gt;We will do everything we can within reason to make sure that your interview takes place in an environment that fairly and accurately assesses your skills. If you need assistance or accommodation, please contact&amp;nbsp;&lt;a class=&quot;Z7ph2&quot; href=&quot;mailto:accommodations@duolingo.com&quot; target=&quot;_blank&quot; data-stringify-link=&quot;mailto:accommodations@duolingo.com&quot; data-sk=&quot;tooltip_parent&quot;&gt;accommodations@duolingo.com&lt;/a&gt;.&lt;/p&gt;\n&lt;p class=&quot;Z7ph2&quot;&gt;Duolingo is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.&lt;/p&gt;\n&lt;p class=&quot;Z7ph2&quot;&gt;By applying for this position your data will be processed as per the&lt;a class=&quot;Z7ph2&quot; href=&quot;https://docs.google.com/document/d/e/2PACX-1vTX9GKeRMOMA9Vtm0vfGibrYPYz8ysl0Dg8KSXgj_PxeT5ChsdnNZZWtpxu4t7xillTPGnngnKCjIbV/pub&quot;&gt;&amp;nbsp;Duolingo Applicant Privacy Notice&lt;/a&gt;.&lt;/p&gt;\n&lt;p class=&quot;Z7ph2&quot;&gt;Sign up for job alerts&amp;nbsp;&lt;a href=&quot;http://my.greenhouse.io/users/sign_in?job_board=duolingo&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 8377539002
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Research Scientist, Interpretability",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4980427008",
    "job_posted_at_datetime_utc": "2026-01-15T19:41:28-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: When you see what modern language models are capable of, do you wonder, \"How do these things work? How can we trust them?\" The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts. People mean many different things by \"interpretability\". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do \"biology\" or \"neuroscience\" of neural networks using “microscopes” we build, or as treating neural networks as binary computer programs we're trying to \"reverse engineer\". A few places to learn more about our work and team at a high level are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team's notable publications include A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, Toy Models of Superposition, Scaling Monosemanticity, and our Circuits’ Methods and Biology papers. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks. We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our vision post). In the short term, we have focused on resolving the issue of \"superposition\" (see Toy Models of Superposition, Superposition, Memorization, and Double Descent, and our May 2023 update), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent work found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model's computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks. We often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer. We also have an Interpretability Architectures project that involves collaborating with Pretraining. Responsibilities: Develop methods for understanding LLMs by reverse engineering algorithms learned in their weights Design and run robust experiments, both quickly in toy scenarios and at scale in large models Create and analyze new interpretability features and circuits to better understand how models work. Build infrastructure for running experiments and visualizing results Work with colleagues to communicate results internally and publicly You may be a good fit if you: Have a strong track record of scientific research (in any field), and have done some work on Interpretability Enjoy team science – working collaboratively to make big discoveries Are comfortable with messy experimental science. We're inventing the field as we work, and the first textbook is years away You view research and engineering as two sides of the same coin. Every team member writes code, designs and runs experiments, and interprets results You can clearly articulate and discuss the motivations behind your work, and teach us about what you've learned. You like writing up and communicating your results, even when they're null To learn more about the skills we look for and how to prepare for this role, see our blog post – So You Want to Work in Mechanistic Interpretability? Familiarity with Python is required for this role. Role Specific Location Policy: This role is based in San Francisco office; however, we are open to considering exceptional candidates for remote work on a case-by-case basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-scientist-interpretability-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4980427008",
    "title": "Research Scientist, Interpretability",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4980427008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:41:28-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;When you see what modern language models are capable of, do you wonder, &quot;How do these things work? How can we trust them?&quot;&lt;/p&gt;\n&lt;p&gt;The Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We’re looking for researchers and engineers to join our efforts.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;People mean many different things by &quot;interpretability&quot;. We&#39;re focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do &quot;biology&quot; or &quot;neuroscience&quot; of neural networks using “microscopes” we build, or as treating neural networks as binary computer programs we&#39;re trying to &quot;reverse engineer&quot;.&lt;/p&gt;\n&lt;p&gt;A few places to learn more about our work and team at a high level are &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://www.youtube.com/watch?v=TxhhMTOTMDg&quot; target=&quot;_blank&quot;&gt;this introduction to Interpretability&lt;/a&gt; from our research lead, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://colah.github.io/about.html&quot; target=&quot;_blank&quot;&gt;Chris Olah&lt;/a&gt;; a &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://open.spotify.com/episode/5UF79Uu94ia0fwC32a89LU&quot; target=&quot;_blank&quot;&gt;discussion of our work&lt;/a&gt; on the &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://www.nytimes.com/column/hard-fork&quot; target=&quot;_blank&quot;&gt;Hard Fork podcast&lt;/a&gt; produced by the New York Times, and this &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://www.anthropic.com/research/engineering-challenges-interpretability&quot; target=&quot;_blank&quot;&gt;blog post&lt;/a&gt; (and accompanying video) sharing more about some of the engineering challenges we’d had to solve to get these results. Some of our team&#39;s notable publications include &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2021/framework/index.html&quot; target=&quot;_blank&quot;&gt;A Mathematical Framework for Transformer Circuits&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html&quot; target=&quot;_blank&quot;&gt;In-context Learning and Induction Heads&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot; target=&quot;_blank&quot;&gt;Toy Models of Superposition&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2024/scaling-monosemanticity/&quot; target=&quot;_blank&quot;&gt;Scaling Monosemanticity&lt;/a&gt;, and our Circuits’ &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/methods.html&quot; target=&quot;_blank&quot;&gt;Methods&lt;/a&gt; and &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/biology.html&quot; target=&quot;_blank&quot;&gt;Biology&lt;/a&gt; papers. This work builds on ideas from members&#39; work prior to Anthropic such as the &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://distill.pub/2020/circuits/&quot; target=&quot;_blank&quot;&gt;original circuits thread&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://distill.pub/2021/multimodal-neurons/&quot; target=&quot;_blank&quot;&gt;Multimodal Neurons&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://distill.pub/2019/activation-atlas/&quot; target=&quot;_blank&quot;&gt;Activation Atlases&lt;/a&gt;, and &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://distill.pub/2018/building-blocks/&quot; target=&quot;_blank&quot;&gt;Building Blocks&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;We aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2023/interpretability-dreams/index.html&quot; target=&quot;_blank&quot;&gt;vision post&lt;/a&gt;). In the short term, we have focused on resolving the issue of &quot;superposition&quot; (see &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2022/toy_model/index.html&quot; target=&quot;_blank&quot;&gt;Toy Models of Superposition&lt;/a&gt;, &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2023/toy-double-descent/index.html&quot; target=&quot;_blank&quot;&gt;Superposition, Memorization, and Double Descent&lt;/a&gt;, and our &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2023/may-update/index.html&quot; target=&quot;_blank&quot;&gt;May 2023 update&lt;/a&gt;), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://www.anthropic.com/news/mapping-mind-language-model&quot; target=&quot;_blank&quot;&gt;work&lt;/a&gt; found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model&#39;s computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.” This is a stepping stone towards our overall goal of mechanistically understanding neural networks.&lt;/p&gt;\n&lt;p&gt;We often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic’s models safer. We also have an &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2024/april-update/index.html#interpretability-architecture&quot; target=&quot;_blank&quot;&gt;Interpretability Architectures project&lt;/a&gt; that involves collaborating with Pretraining.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Develop methods for understanding LLMs by reverse engineering algorithms learned in their weights&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Design and run robust experiments, both quickly in toy scenarios and at scale in large models&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Create and analyze new interpretability features and circuits to better understand how models work.&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build infrastructure for running experiments and visualizing results&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Work with colleagues to communicate results internally and publicly&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Have a strong track record of scientific research (in any field), and have done &lt;em&gt;some&lt;/em&gt; work on Interpretability&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Enjoy team science – working collaboratively to make big discoveries&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are comfortable with messy experimental science. We&#39;re inventing the field as we work, and the first textbook is years away&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;You view research and engineering as two sides of the same coin. Every team member writes code, designs and runs experiments, and interprets results&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;You can clearly articulate and discuss the motivations behind your work, and teach us about what you&#39;ve learned. You like writing up and communicating your results, even when they&#39;re null&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;To learn more about the skills we look for and how to prepare for this role, see our blog post – &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://transformer-circuits.pub/2025/april-update/index.html#work&quot; target=&quot;_blank&quot;&gt;So You Want to Work in Mechanistic Interpretability?&lt;/a&gt;&lt;/p&gt;\n&lt;p&gt;Familiarity with Python is required for this role.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Role Specific Location Policy:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;This role is based in San Francisco office; however, we are open to considering exceptional candidates for remote work on a case-by-case basis.&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4980427008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Software Engineer, ML Networking",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4926242008",
    "job_posted_at_datetime_utc": "2026-01-15T19:38:31-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Role Summary A systems-level engineer specializing in network infrastructure and network optimization, with expertise in building and maintaining software that interacts with networks. You will be responsible for writing and maintaining software that interfaces between our accelerators and our high-speed networks. This role requires deep technical knowledge of network protocols, kernel-space and/or user-space networks, interfacing with hardware, and the ability to debug and optimize distributed software at the network level. You may be a good fit if you have: Networking Systems Engineering: Expert-level proficiency with network protocols and networking concepts Deep kernel networking: TCP/IP stack internals, XDP, eBPF, io_uring, and epoll User-space networking: DPDK, RDMA, kernel bypass techniques Understanding of how to build higher-level abstractions like collectives and RPC Skilled at diagnosing and resolving networking issues in distributed systems, especially at OSI model layers 2-4 Low-Level Systems and OS Programming: Strong programming skills in a systems programming language, including memory management, lock-free data structures, and NUMA-aware programming Software, driver, and OS performance optimization tools and techniques Comfort with or desire to learn Rust Strong candidates may have: Understanding of ML accelerators and accelerator drivers Demonstrated ability to design new network protocols Experience with PCIe and drivers for PCIe devices Expertise in algorithms used in networking, including compression and graph algorithms Experience programming on SmartNICs 5+ years of experience in systems programming or network programming Often comes from backgrounds in: HPC, telecommunications, host networking software, OS/kernel engineering, or embedded systems Strong debugging mindset with patience for complex, multi-layered issues Representative Projects: Build a system for accelerator-initiated tensor movement over the network Benchmark software for a new networking environment Implement a new collective algorithm to improve latency Optimize congestion control algorithms for large-scale synchronous workloads Debug kernel-level network latency spikes The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-software-engineer-ml-networking-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4926242008",
    "title": "Software Engineer, ML Networking",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4926242008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:38:31-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;Role Summary&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;A systems-level engineer specializing in network infrastructure and network optimization, with expertise in building and maintaining software that interacts with networks. You will be responsible for writing and maintaining software that interfaces between our accelerators and our high-speed networks. This role requires deep technical knowledge of network protocols, kernel-space and/or user-space networks, interfacing with hardware, and the ability to debug and optimize distributed software at the network level.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;Networking Systems Engineering:&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Expert-level proficiency with network protocols and networking concepts&lt;/li&gt;\n&lt;li&gt;Deep kernel networking: TCP/IP stack internals, XDP, eBPF, io_uring, and epoll&lt;/li&gt;\n&lt;li&gt;User-space networking: DPDK, RDMA, kernel bypass techniques&lt;/li&gt;\n&lt;li&gt;Understanding of how to build higher-level abstractions like collectives and RPC&lt;/li&gt;\n&lt;li&gt;Skilled at diagnosing and resolving networking issues in distributed systems, especially at OSI model layers 2-4&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Low-Level Systems and OS Programming:&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Strong programming skills in a systems programming language, including memory management, lock-free data structures, and NUMA-aware programming&lt;/li&gt;\n&lt;li&gt;Software, driver, and OS performance optimization tools and techniques&lt;/li&gt;\n&lt;li&gt;Comfort with or desire to learn Rust&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Understanding of ML accelerators and accelerator drivers&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to design new network protocols&lt;/li&gt;\n&lt;li&gt;Experience with PCIe and drivers for PCIe devices&lt;/li&gt;\n&lt;li&gt;Expertise in algorithms used in networking, including compression and graph algorithms&lt;/li&gt;\n&lt;li&gt;Experience programming on SmartNICs&lt;/li&gt;\n&lt;li&gt;5+ years of experience in systems programming or network programming&lt;/li&gt;\n&lt;li&gt;Often comes from backgrounds in: HPC, telecommunications, host networking software, OS/kernel engineering, or embedded systems&lt;/li&gt;\n&lt;li&gt;Strong debugging mindset with patience for complex, multi-layered issues&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative Projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Build a system for accelerator-initiated tensor movement over the network&lt;/li&gt;\n&lt;li&gt;Benchmark software for a new networking environment&lt;/li&gt;\n&lt;li&gt;Implement a new collective algorithm to improve latency&lt;/li&gt;\n&lt;li&gt;Optimize congestion control algorithms for large-scale synchronous workloads&lt;/li&gt;\n&lt;li&gt;Debug kernel-level network latency spikes&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4926242008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Pretraining Scaling",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4938432008",
    "job_posted_at_datetime_utc": "2026-01-15T19:37:28-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role: Anthropic's ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company's future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you'll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems. This role lives at the boundary between research and engineering. You'll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can't wait for tomorrow. Responsibilities: Own critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability Debug and resolve complex issues across the full stack—from hardware errors and networking to training dynamics and evaluation infrastructure Design and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance Respond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams Build and maintain production logging, monitoring dashboards, and evaluation infrastructure Add new capabilities to the training codebase, such as long context support or novel architectures Collaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams Contribute to the team's institutional knowledge by documenting systems, debugging approaches, and lessons learned You May Be a Good Fit If You: Have hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems Genuinely enjoy both research and engineering work—you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other Are excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure Thrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs Excel at debugging complex, ambiguous problems across multiple layers of the stack Communicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents Are passionate about the work itself and want to refine your craft as a research engineer Care about the societal impacts of AI and responsible scaling Strong Candidates May Also Have: Previous experience training LLM’s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale Contributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax) Published research on model training, scaling laws, or ML systems Experience with production ML systems, observability tools, or evaluation infrastructure Background as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence What Makes This Role Unique: This is not a typical research engineering role. The work is highly operational—you'll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends. However, this operational intensity comes with extraordinary learning opportunities. You'll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You'll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can't be easily transferred. For people who thrive on this type of work, it's uniquely rewarding. We're building a close-knit team of people who genuinely care about doing excellent work together. If you're someone who wants to be part of training the models that will define the future of AI—and you're excited about the full reality of what that entails—we'd love to hear from you. Location:This role requires working in-office 5 days per week in San Francisco. Deadline to apply: None. Applications will be reviewed on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-engineer-pretraining-scaling-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4938432008",
    "title": "Research Engineer, Pretraining Scaling",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4938432008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:37:28-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic&#39;s ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company&#39;s future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you&#39;ll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems.&lt;/p&gt;\n&lt;p&gt;This role lives at the boundary between research and engineering. You&#39;ll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can&#39;t wait for tomorrow.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Own critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability&lt;/li&gt;\n&lt;li&gt;Debug and resolve complex issues across the full stack—from hardware errors and networking to training dynamics and evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Design and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance&lt;/li&gt;\n&lt;li&gt;Respond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams&lt;/li&gt;\n&lt;li&gt;Build and maintain production logging, monitoring dashboards, and evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Add new capabilities to the training codebase, such as long context support or novel architectures&lt;/li&gt;\n&lt;li&gt;Collaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams&lt;/li&gt;\n&lt;li&gt;Contribute to the team&#39;s institutional knowledge by documenting systems, debugging approaches, and lessons learned&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You May Be a Good Fit If You:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Genuinely enjoy both research and engineering work—you&#39;d describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other&lt;/li&gt;\n&lt;li&gt;Are excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure&lt;/li&gt;\n&lt;li&gt;Thrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs&lt;/li&gt;\n&lt;li&gt;Excel at debugging complex, ambiguous problems across multiple layers of the stack&lt;/li&gt;\n&lt;li&gt;Communicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents&lt;/li&gt;\n&lt;li&gt;Are passionate about the work itself and want to refine your craft as a research engineer&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of AI and responsible scaling&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong Candidates May Also Have:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Previous experience training LLM’s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale&lt;/li&gt;\n&lt;li&gt;Contributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax)&lt;/li&gt;\n&lt;li&gt;Published research on model training, scaling laws, or ML systems&lt;/li&gt;\n&lt;li&gt;Experience with production ML systems, observability tools, or evaluation infrastructure&lt;/li&gt;\n&lt;li&gt;Background as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;What Makes This Role Unique:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;This is not a typical research engineering role. The work is highly operational—you&#39;ll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends.&lt;/p&gt;\n&lt;p&gt;However, this operational intensity comes with extraordinary learning opportunities. You&#39;ll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You&#39;ll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can&#39;t be easily transferred. For people who thrive on this type of work, it&#39;s uniquely rewarding.&lt;/p&gt;\n&lt;p&gt;We&#39;re building a close-knit team of people who genuinely care about doing excellent work together. If you&#39;re someone who wants to be part of training the models that will define the future of AI—and you&#39;re excited about the full reality of what that entails—we&#39;d love to hear from you.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt;This role requires working in-office 5 days per week in San Francisco.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4938432008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "TPU Kernel Engineer",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4720576008",
    "job_posted_at_datetime_utc": "2026-01-15T19:34:17-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a TPU Kernel Engineer, you'll be responsible for identifying and addressing performance issues across many different ML systems, including research, training, and inference. A significant portion of this work will involve designing and optimizing kernels for the TPU. You will also provide feedback to researchers about how model changes impact performance. Strong candidates will have a track record of solving large-scale systems problems and low-level optimization. You may be a good fit if you: Have significant experience optimizing ML systems for TPUs, GPUs, or other accelerators Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems Designing and implementing kernels for TPUs or other ML accelerators Understanding accelerators at a deep level, e.g. a background in computer architecture ML framework internals Language modeling with transformers Representative projects: Implement low-latency, high-throughput sampling for large language models Adapt existing models for low-precision inference Build quantitative models of system performance Design and implement custom collective communication algorithms Debug kernel performance at the assembly level The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-tpu-kernel-engineer-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4720576008",
    "title": "TPU Kernel Engineer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4720576008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:34:17-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a TPU Kernel Engineer, you&#39;ll be responsible for identifying and addressing performance issues across many different ML systems, including research, training, and inference. A significant portion of this work will involve designing and optimizing kernels for the TPU. You will also provide feedback to researchers about how model changes impact performance. Strong candidates will have a track record of solving large-scale systems problems and low-level optimization.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant experience optimizing ML systems for TPUs, GPUs, or other accelerators&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;Designing and implementing kernels for TPUs or other ML accelerators&lt;/li&gt;\n&lt;li&gt;Understanding accelerators at a deep level, e.g. a background in computer architecture&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Representative projects:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement low-latency, high-throughput sampling for large language models&lt;/li&gt;\n&lt;li&gt;Adapt existing models for low-precision inference&lt;/li&gt;\n&lt;li&gt;Build quantitative models of system performance&lt;/li&gt;\n&lt;li&gt;Design and implement custom collective communication algorithms&lt;/li&gt;\n&lt;li&gt;Debug kernel performance at the assembly level&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&amp;nbsp;&lt;/h2&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4720576008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Performance Engineer",
    "employer_name": "anthropic",
    "job_city": "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4020350008",
    "job_posted_at_datetime_utc": "2026-01-15T19:33:38-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: Running machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you'll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also. You may be a good fit if you: Have significant software engineering or machine learning experience, particularly at supercomputing scale Are results-oriented, with a bias towards flexibility and impact Pick up slack, even if it goes outside your job description Enjoy pair programming (we love to pair!) Want to learn more about machine learning research Care about the societal impacts of your work Strong candidates may also have experience with: High performance, large-scale ML systems GPU/Accelerator programming ML framework internals OS internals Language modeling with transformers Representative projects: Implement low-latency high-throughput sampling for large language models Implement GPU kernels to adapt our models to low-precision inference Write a custom load-balancing algorithm to optimize serving efficiency Build quantitative models of system performance Design and implement a fault-tolerant distributed system running with a complex network topology Debug kernel-level network latency spikes in a containerized environment Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-performance-engineer-new-york-city-ny-seattle-wa-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4020350008",
    "title": "Performance Engineer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "New York City, NY | Seattle, WA; San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4020350008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:33:38-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;div&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;Running machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you&#39;ll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also.&lt;/div&gt;\n&lt;/div&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software engineering or machine learning experience, particularly at supercomputing scale&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Want to learn more about machine learning research&lt;/li&gt;\n&lt;li&gt;Care about the societal impacts of your work&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;GPU/Accelerator programming&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;OS internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement low-latency high-throughput sampling for large language models&lt;/li&gt;\n&lt;li&gt;Implement GPU kernels to adapt our models to low-precision inference&lt;/li&gt;\n&lt;li&gt;Write a custom load-balancing algorithm to optimize serving efficiency&lt;/li&gt;\n&lt;li&gt;Build quantitative models of system performance&lt;/li&gt;\n&lt;li&gt;Design and implement a fault-tolerant distributed system running with a complex network topology&lt;/li&gt;\n&lt;li&gt;Debug kernel-level network latency spikes in a containerized environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4020350008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Machine Learning (Reinforcement Learning) ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "job_posted_at_datetime_utc": "2026-01-15T19:33:06-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the teams Our Reinforcement Learning teams lead Anthropic's reinforcement learning research and development, playing a critical role in advancing our AI systems. We've contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude Sonnet 4.5 and Opus 4.5. Our work spans several key areas: Developing systems that enable models to use computers effectively Advancing code generation through reinforcement learning Pioneering fundamental RL research for large language models Building scalable RL infrastructure and training methodologies Enhancing model reasoning capabilities We collaborate closely with Anthropic's alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and are dedicated to implement our research at scale. Our Reinforcement Learning teams sit at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish. About the Role As a Research Engineer within Reinforcement Learning, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You'll work on fundamental research in reinforcement learning, creating 'agentic' models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation. Representative projects: Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows. Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models. Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows. Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research. You may be a good fit if you: Are proficient in Python and async/concurrent programming with frameworks like Trio Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX) Have industry experience in machine learning research Can balance research exploration with engineering implementation Enjoy pair programming (we love to pair!) Care about code quality, testing, and performance Have strong systems design and communication skills Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems Strong candidates may have: Familiarity with LLM architectures and training methodologies Experience with reinforcement learning techniques and environments Experience with virtualization and sandboxed code execution environments Experience with Kubernetes Experience with distributed systems or high-performance computing Experience with Rust and/or C++ Strong candidates need not have: Formal certifications or education credentials Academic research experience or publication history Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-engineer-machine-learning-reinforcement-learning-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613568008",
    "title": "Research Engineer, Machine Learning (Reinforcement Learning) ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613568008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:33:06-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the teams&lt;/h2&gt;\n&lt;p&gt;Our Reinforcement Learning teams lead Anthropic&#39;s reinforcement learning research and development, playing a critical role in advancing our AI systems. We&#39;ve contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude Sonnet 4.5 and Opus 4.5. Our work spans several key areas:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Developing systems that enable models to use computers effectively&lt;/li&gt;\n&lt;li&gt;Advancing code generation through reinforcement learning&lt;/li&gt;\n&lt;li&gt;Pioneering fundamental RL research for large language models&lt;/li&gt;\n&lt;li&gt;Building scalable RL infrastructure and training methodologies&lt;/li&gt;\n&lt;li&gt;Enhancing model reasoning capabilities&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We collaborate closely with Anthropic&#39;s alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and are dedicated to implement our research at scale. Our Reinforcement Learning teams sit at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish.&lt;/p&gt;\n&lt;/div&gt;\n&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;div&gt;\n&lt;p&gt;As a Research Engineer within Reinforcement Learning, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You&#39;ll work on fundamental research in reinforcement learning, creating &#39;agentic&#39; models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation.&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Architect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows.&lt;/li&gt;\n&lt;li&gt;Design, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models.&lt;/li&gt;\n&lt;li&gt;Drive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows.&lt;/li&gt;\n&lt;li&gt;Collaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are proficient in Python and async/concurrent programming with frameworks like Trio&lt;/li&gt;\n&lt;li&gt;Have experience with machine learning frameworks (PyTorch, TensorFlow, JAX)&lt;/li&gt;\n&lt;li&gt;Have industry experience in machine learning research&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering implementation&lt;/li&gt;\n&lt;li&gt;Enjoy pair programming (we love to pair!)&lt;/li&gt;\n&lt;li&gt;Care about code quality, testing, and performance&lt;/li&gt;\n&lt;li&gt;Have strong systems design and communication skills&lt;/li&gt;\n&lt;li&gt;Are passionate about the potential impact of AI and are committed to developing safe and beneficial systems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Familiarity with LLM architectures and training methodologies&lt;/li&gt;\n&lt;li&gt;Experience with reinforcement learning techniques and environments&lt;/li&gt;\n&lt;li&gt;Experience with virtualization and sandboxed code execution environments&lt;/li&gt;\n&lt;li&gt;Experience with Kubernetes&lt;/li&gt;\n&lt;li&gt;Experience with distributed systems or high-performance computing&lt;/li&gt;\n&lt;li&gt;Experience with Rust and/or C++&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates need not have:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;ul&gt;\n&lt;li&gt;Formal certifications or education credentials&lt;/li&gt;\n&lt;li&gt;Academic research experience or publication history&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613568008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Engineering Manager, ML Acceleration",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4741104008",
    "job_posted_at_datetime_utc": "2026-01-15T19:32:07-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: Anthropic’s performance and scaling teams focus on making the most efficient and impactful use of our compute resources, be it inference or training. As an Engineering Manager on these teams you will be responsible for ensuring you and your team are identifying and removing bottlenecks, building robust and durable solutions, and maximizing the efficiency of our systems. You also will help bring clarity, focus, and context to your teams in a fast paced, dynamic environment. Responsibilities: Provide front-line leadership of engineering efforts to improve model performance and scale our inference and training systems Become familiar with the team’s technical stack enough to make targeted contributions as an individual contributor Manage day-to-day execution of the team's work Prioritize the team’s work and manage projects in a highly dynamic, fast paced environment Coach and support your reports in understanding, and pursuing, their professional growth Maintain a deep understanding of the team's technical work and its implications for AI safety You may be a good fit if you: Have 1+ years of management experience in a technical environment, particularly performance or distributed systems Have a background in machine learning, AI, or a similar related technical field Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development Excel at building strong relationships with stakeholders at all levels Are a quick learner, capable of understanding and contributing to discussions on complex technical topics Have experience managing teams through periods of rapid growth and change Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you’ll need to understand (at a high level of abstraction) to be effective Strong candidates may also have experience with: High performance, large-scale ML systems GPU/Accelerator programming ML framework internals OS internals Language modeling with transformers The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-engineering-manager-ml-acceleration-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4741104008",
    "title": "Engineering Manager, ML Acceleration",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4741104008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T19:32:07-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;Anthropic’s performance and scaling teams focus on making the most efficient and impactful use of our compute resources, be it inference or training.&amp;nbsp; As an Engineering Manager on these teams you will be responsible for ensuring you and your team are identifying and removing bottlenecks, building robust and durable solutions, and maximizing the efficiency of our systems.&amp;nbsp; You also will help bring clarity, focus, and context to your teams in a fast paced, dynamic environment.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;Responsibilities:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Provide front-line leadership of engineering efforts to improve model performance and scale our inference and training systems&lt;/li&gt;\n&lt;li&gt;Become familiar with the team’s technical stack enough to make targeted contributions as an individual contributor&lt;/li&gt;\n&lt;li&gt;Manage day-to-day execution of the team&#39;s work&lt;/li&gt;\n&lt;li&gt;Prioritize the team’s work and manage projects in a highly dynamic, fast paced environment&lt;/li&gt;\n&lt;li&gt;Coach and support your reports in understanding, and pursuing, their professional growth&lt;/li&gt;\n&lt;li&gt;Maintain a deep understanding of the team&#39;s technical work and its implications for AI safety&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;You may be a good fit if you:&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 1+ years of management experience in a technical environment, particularly performance or distributed systems&lt;/li&gt;\n&lt;li&gt;Have a background in machine learning, AI, or a similar related technical field&lt;/li&gt;\n&lt;li&gt;Are deeply interested in the potential transformative effects of advanced AI systems and are committed to ensuring their safe development&lt;/li&gt;\n&lt;li&gt;Excel at building strong relationships with stakeholders at all levels&lt;/li&gt;\n&lt;li&gt;Are a quick learner, capable of understanding and contributing to discussions on complex technical topics&lt;/li&gt;\n&lt;li&gt;Have experience managing teams through periods of rapid growth and change&lt;/li&gt;\n&lt;li&gt;Are a quick study: this team sits at the intersection of a large number of different complex technical systems that you’ll need to understand (at a high level of abstraction) to be effective&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;Strong candidates may also have experience with:&amp;nbsp;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;High performance, large-scale ML systems&lt;/li&gt;\n&lt;li&gt;GPU/Accelerator programming&lt;/li&gt;\n&lt;li&gt;ML framework internals&lt;/li&gt;\n&lt;li&gt;OS internals&lt;/li&gt;\n&lt;li&gt;Language modeling with transformers&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4741104008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]