[
  {
    "job_title": "",
    "employer_name": "AgZen",
    "job_city": "Cambridge",
    "job_state": "MA",
    "job_description": ".fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-mobile-site-gutter, 6vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (8 - 1)) ) / 8 ); display: grid; position: relative; grid-area: 1/1/-1/-1; grid-template-rows: repeat(12,minmax(24px, auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(8, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); row-gap: 11.0px; column-gap: 11.0px; overflow-x: hidden; overflow-x: clip; } @media (min-width: 768px) { .background-width--inset .fe-681e70c2a649507003c3aab5 { --inset-padding: calc(var(--sqs-site-gutter) * 2); } .fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-site-gutter, 4vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (24 - 1)) ) / 24 ); --inset-padding: 0vw; --row-height-scaling-factor: 0.0215; --container-width: min(var(--sqs-site-max-width, 1500px), calc(100vw - var(--sqs-site-gutter, 4vw) * 2 - var(--inset-padding) )); grid-template-rows: repeat(13,minmax(calc(var(--container-width) * var(--row-height-scaling-factor)), auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(24, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); } } .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/7/10; z-index: 1; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/2/26; z-index: 2; position: sticky; top: calc(0px + var(--header-fixed-top-offset, 0px)); } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } } .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 7/2/13/10; z-index: 2; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 2/2/7/26; z-index: 1; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } }",
    "job_apply_link": "https://www.agzen.com/jobs?gh_jid=4048593009",
    "job_posted_at_datetime_utc": "2025-10-21T00:25:19.000Z",
    "job_employment_type": "FULLTIME",
    "job_posted_at": "1h",
    "id": "agzen--cambridge",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Research Engineer, Production Model Post Training",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "job_posted_at_datetime_utc": "2026-01-15T18:56:11-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role Anthropic's production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you'll train our base models through the complete post-training stack to deliver the production Claude models that users interact with. You'll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models. Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends. Responsibilities: Implement and optimize post-training techniques at scale on frontier models Conduct research to develop and optimize post-training recipes that directly improve production model quality Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation Develop tools to measure and improve model performance across various dimensions Collaborate with research teams to translate emerging techniques into production-ready implementations Debug complex issues in training pipelines and model behavior Help establish best practices for reliable, reproducible model post-training You may be a good fit if you: Thrive in controlled chaos and are energised, rather than overwhelmed, when juggling multiple urgent priorities Adapt quickly to changing priorities Maintain clarity when debugging complex, time-sensitive issues Have strong software engineering skills with experience building complex ML systems Are comfortable working with large-scale distributed systems and high-performance computing Have experience with training, fine-tuning, or evaluating large language models Can balance research exploration with engineering rigor and operational reliability Are adept at analyzing and debugging model training processes Enjoy collaborating across research and engineering disciplines Can navigate ambiguity and make progress in fast-moving research environments Strong candidates may also: Have experience with LLMs Have a keen interest in AI safety and responsible deployment We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-engineer-production-model-post-training-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4613592008",
    "title": "Research Engineer, Production Model Post Training",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4613592008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:56:11-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;Anthropic&#39;s production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you&#39;ll train our base models through the complete post-training stack to deliver the production Claude models that users interact with.&lt;/p&gt;\n&lt;p&gt;You&#39;ll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Implement and optimize post-training techniques at scale on frontier models&lt;/li&gt;\n&lt;li&gt;Conduct research to develop and optimize post-training recipes that directly improve production model quality&lt;/li&gt;\n&lt;li&gt;Design, build, and run robust, efficient pipelines for model fine-tuning and evaluation&lt;/li&gt;\n&lt;li&gt;Develop tools to measure and improve model performance across various dimensions&lt;/li&gt;\n&lt;li&gt;Collaborate with research teams to translate emerging techniques into production-ready implementations&lt;/li&gt;\n&lt;li&gt;Debug complex issues in training pipelines and model behavior&lt;/li&gt;\n&lt;li&gt;Help establish best practices for reliable, reproducible model post-training&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Thrive in controlled chaos and&amp;nbsp;are energised, rather than overwhelmed, when juggling multiple urgent priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Adapt quickly to changing priorities&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;1&quot;&gt;Maintain clarity when debugging complex, time-sensitive issues&lt;/li&gt;\n&lt;li&gt;Have strong software engineering skills with experience building complex ML systems&lt;/li&gt;\n&lt;li&gt;Are comfortable working with large-scale distributed systems and high-performance computing&lt;/li&gt;\n&lt;li&gt;Have experience with training, fine-tuning, or evaluating large language models&lt;/li&gt;\n&lt;li&gt;Can balance research exploration with engineering rigor and operational reliability&lt;/li&gt;\n&lt;li&gt;Are adept at analyzing and debugging model training processes&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating across research and engineering disciplines&lt;/li&gt;\n&lt;li&gt;Can navigate ambiguity and make progress in fast-moving research environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience with LLMs&lt;/li&gt;\n&lt;li&gt;Have a keen interest in AI safety and responsible deployment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4613592008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Scientist, Alignment Science",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4631822008",
    "job_posted_at_datetime_utc": "2026-01-15T18:55:31-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the role: You want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you'll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our Responsible Scaling Policy), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team. Our blog provides an overview of topics that the Alignment Science team is either currently exploring or has previously explored. Our current topics of focus include... Scalable Oversight: Developing techniques to keep highly capable models helpful and honest, even as they surpass human-level intelligence in various domains. AI Control: Creating methods to ensure advanced AI systems remain safe and harmless in unfamiliar or adversarial scenarios. Alignment Stress-testing: Creating model organisms of misalignment to improve our empirical understanding of how alignment failures might arise. Automated Alignment Research: Building and aligning a system that can speed up & improve alignment research. Alignment Assessments: Understanding and documenting the highest-stakes and most concerning emerging properties of models through pre-deployment alignment and welfare assessments (see our Claude 4 System Card), misalignment-risk safety cases, and coordination with third-party evaluators. Safeguards Research: Developing robust defenses against adversarial attacks, comprehensive evaluation frameworks for model safety, and automated systems to detect and mitigate potential risks before deployment. Model Welfare: Investigating and addressing potential model welfare, moral status, and related questions. See our program announcement and welfare assessment in the Claude 4 system card for more. Note: For this role, we conduct all interviews in Python and prefer candidates to be based in the Bay Area. Representative projects: Testing the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions. Run multi-agent reinforcement learning experiments to test out techniques like AI Debate. Build tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks. Write scripts and prompts to efficiently produce evaluation questions to test models’ reasoning abilities in safety-relevant contexts. Contribute ideas, figures, and writing to research papers, blog posts, and talks. Run experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our Responsible Scaling Policy. You may be a good fit if you: Have significant software, ML, or research engineering experience Have some experience contributing to empirical AI research projects Have some familiarity with technical AI safety research Prefer fast-moving collaborative projects to extensive solo efforts Pick up slack, even if it goes outside your job description Care about the impacts of AI Strong candidates may also: Have experience authoring research papers in machine learning, NLP, or AI safety Have experience with LLMs Have experience with reinforcement learning Have experience with Kubernetes clusters and complex shared codebases Candidates need not have: 100% of the skills needed to perform the job Formal certifications or education credentials The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-engineer-scientist-alignment-science-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4631822008",
    "title": "Research Engineer / Scientist, Alignment Science",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4631822008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:55:31-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;You want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you&#39;ll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our &lt;a class=&quot;postings-link&quot; href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot;&gt;Responsible Scaling Policy&lt;/a&gt;), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team.&lt;/div&gt;\n&lt;div&gt;&amp;nbsp;&lt;/div&gt;\n&lt;div&gt;&lt;a href=&quot;https://alignment.anthropic.com/&quot;&gt;Our blog&lt;/a&gt; provides an overview of topics that the Alignment Science team is either currently exploring or has previously explored. Our current topics of focus include...\n&lt;ul class=&quot;p-rich_text_list p-rich_text_list__bullet p-rich_text_list--nested&quot; data-stringify-type=&quot;unordered-list&quot; data-list-tree=&quot;true&quot; data-indent=&quot;0&quot; data-border=&quot;0&quot;&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Scalable Oversight:&amp;nbsp;&lt;/strong&gt;Developing techniques to keep highly capable models helpful and honest, even as they surpass human-level intelligence in various domains.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;AI Control:&amp;nbsp;&lt;/strong&gt;Creating methods to ensure advanced AI systems remain safe and harmless in unfamiliar or adversarial scenarios.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;&lt;a class=&quot;c-link&quot; href=&quot;https://www.lesswrong.com/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.lesswrong.com/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic&quot; data-sk=&quot;tooltip_parent&quot;&gt;Alignment Stress-testing&lt;/a&gt;&lt;/strong&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;:&lt;/strong&gt;&amp;nbsp;Creating&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.lesswrong.com/posts/ChDH335ckdvpxXaXX/model-organisms-of-misalignment-the-case-for-a-new-pillar-of-1&quot; data-sk=&quot;tooltip_parent&quot;&gt;model organisms of misalignment&lt;/a&gt;&amp;nbsp;to improve our empirical understanding of how alignment failures might arise.&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Automated Alignment Research:&amp;nbsp;&lt;/strong&gt;Building and aligning a system that can speed up &amp;amp; improve alignment research.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;strong&gt;Alignment Assessments&lt;/strong&gt;: Understanding and documenting the highest-stakes and most concerning emerging properties of models through pre-deployment alignment and welfare assessments (see our &lt;span class=&quot;s1&quot;&gt;&lt;a href=&quot;https://www-cdn.anthropic.com/6be99a52cb68eb70eb9572b4cafad13df32ed995.pdf&quot;&gt;&lt;span class=&quot;s2&quot;&gt;Claude 4 System Card&lt;/span&gt;&lt;/a&gt;)&lt;/span&gt;, misalignment-risk safety cases, and coordination with third-party evaluators.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;a href=&quot;https://job-boards.greenhouse.io/anthropic/jobs/4459012008&quot;&gt;&lt;strong&gt;Safeguards Research&lt;/strong&gt;&lt;/a&gt;: Developing robust defenses against adversarial attacks, comprehensive evaluation frameworks for model safety, and automated systems to detect and mitigate potential risks before deployment.&lt;/li&gt;\n&lt;li class=&quot;whitespace-normal break-words&quot;&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Model Welfare:&amp;nbsp;&lt;/strong&gt;Investigating and addressing potential model welfare, moral status, and related questions. See our&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/research/exploring-model-welfare&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/research/exploring-model-welfare&quot; data-sk=&quot;tooltip_parent&quot;&gt;program announcement&lt;/a&gt;&amp;nbsp;and welfare assessment in the&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www-cdn.anthropic.com/07b2a3f9902ee19fe39a36ca638e5ae987bc64dd.pdf&quot; data-sk=&quot;tooltip_parent&quot;&gt;Claude 4 system card&lt;/a&gt;&amp;nbsp;for more.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python and prefer candidates to be based in the Bay Area.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Representative projects:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Testing the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions.&lt;/li&gt;\n&lt;li&gt;Run multi-agent reinforcement learning experiments to test out techniques like&amp;nbsp;&lt;a class=&quot;postings-link&quot; href=&quot;https://arxiv.org/abs/1805.00899&quot;&gt;AI Debate&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;Build tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks.&lt;/li&gt;\n&lt;li&gt;Write scripts and prompts to efficiently produce evaluation questions to test models’ reasoning abilities in safety-relevant contexts.&lt;/li&gt;\n&lt;li&gt;Contribute ideas, figures, and writing to research papers, blog posts, and talks.&lt;/li&gt;\n&lt;li&gt;Run experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our&amp;nbsp;&lt;a class=&quot;postings-link&quot; href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot;&gt;Responsible Scaling Policy&lt;/a&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have significant software, ML, or research engineering experience&lt;/li&gt;\n&lt;li&gt;Have some experience contributing to empirical AI research projects&lt;/li&gt;\n&lt;li&gt;Have some familiarity with technical AI safety research&lt;/li&gt;\n&lt;li&gt;Prefer fast-moving collaborative projects to extensive solo efforts&lt;/li&gt;\n&lt;li&gt;Pick up slack, even if it goes outside your job description&lt;/li&gt;\n&lt;li&gt;Care about the impacts of AI&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Strong candidates may also:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience authoring research papers in machine learning, NLP, or AI safety&lt;/li&gt;\n&lt;li&gt;Have experience with LLMs&lt;/li&gt;\n&lt;li&gt;Have experience with reinforcement learning&lt;/li&gt;\n&lt;li&gt;Have experience with Kubernetes clusters and complex shared codebases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;section page-centered&quot;&gt;\n&lt;div&gt;\n&lt;h2&gt;Candidates need not have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;100% of the skills needed to perform the job&lt;/li&gt;\n&lt;li&gt;Formal certifications or education credentials&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4631822008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Senior Motion Designer, Brand Studio",
    "employer_name": "gusto",
    "job_city": "Denver, CO",
    "job_apply_link": "https://job-boards.greenhouse.io/gusto/jobs/6963956",
    "job_posted_at_datetime_utc": "2026-01-15T18:53:54-05:00",
    "job_description": "About Gusto At Gusto, we're on a mission to grow the small business economy. We handle the hard stuff—like payroll, health insurance, 401(k)s, and HR—so owners can focus on their craft and customers. With teams in Denver, San Francisco, and New York, we’re proud to support more than 400,000 small businesses across the country, and we’re building a workplace that represents and celebrates the customers we serve. Learn more about our Total Rewards philosophy. About the Opportunity Editing and motion are where our stories truly take shape. Pacing, sound, motion, and color aren’t finishing touches—they’re the work. They’re how we earn trust, convey clarity, and make people feel something. Gusto is expanding our in-house creative studio inside our fast-moving, late-stage startup. We make cinematic brand films, product stories, and customer-driven narratives—and we also partner closely with our social team to bring those stories to life where our audience spends time. It’s common to shift between a polished long-form piece and fast-turn social work in the same week. We’re looking for a Staff Motion Designer who is a hands-on maker: someone who loves editing and motion design, takes real ownership of the final product, and wants to help shape how video and motion show up across our brand. This is a senior individual contributor role, focused on post-production craft and storytelling. In this role, you’ll own the motion and edit from rough cut through final delivery. You’ll make judgment calls about pacing, sound, animation, and color. You’ll collaborate closely with other creatives and cross-functional partners on our marketing team to produce great work that defines our brand and that has an impact. And you’ll help us raise the bar while also making the work easier to scale—through better workflows, smarter templates, and mindful use of modern tools. If you’re energized by being close to the work, care deeply about taste, and enjoy improving both the output and the process, this role will be a top-notch fit. Here’s what you’ll do day-to-day Edit brand films, product stories, interviews, explainers, and social-first content Design motion graphics, typography, transitions, and animation that serve the story—not the other way around Shape expressive arcs through pacing, sound design, and color Partner closely with other creatives and cross-functional partners from our marketing, comms and social teams from rough cut through final delivery Build repeatable templates and workflows that enable faster turnaround without sacrificing quality Use modern editing and motion tools—including AI-enabled workflows—to explore, iterate, and produce more proficiently Keep post-production organized and deliver final assets that meet creative and technical standards Here’s what we’re looking for 8+ years of experience editing and designing motion for brand, film, agency, or content studios Expert-level fluency in editing and motion tools, with curiosity and judgment around emerging AI-enabled methods A portfolio that demonstrates robust storytelling, mindful motion design, and range across formats Sharp instincts for sound design, pacing, color, and transitions Comfort shifting between polished, narrative-driven work and fast, social-first content Proficient collaboration skills across creative, production, and marketing partners A maker mindset—you enjoy improving how work gets made, not just making the work itself Compensation Details At Gusto, we strive to provide rewards that empower employees to achieve their financial and personal goals. We offer competitive compensation packages with a strong emphasis on equity based compensation (ownership in Gusto). To learn more about Gusto’s compensation philosophy and benefits offerings please view our Total Rewards Approach page. Our cash compensation range for this role is $146,000/yr to $183,000/yr in Denver & most remote locations, and $177,000/yr to $222,000/yr in San Francisco, Seattle & New York. Final offer amounts are determined by multiple factors, including candidate experience and expertise, and may vary from the amounts listed above. Gusto has physical office spaces in Denver, San Francisco, and New York City. Employees who are based in those locations will be expected to work from the office on designated days approximately 2-3 days per week (or more depending on role). The same office expectations apply to all Symmetry roles, Gusto's subsidiary, whose physical office is in Scottsdale. Note: The San Francisco office expectations encompass both the San Francisco and San Jose metro areas. When approved to work from a location other than a Gusto office, a secure, reliable, and consistent internet connection is required. This includes non-office days for hybrid employees. Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto. Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. We want to see our candidates perform to the best of their ability. If you require a medical or religious accommodation at any time throughout your candidate journey, please fill out this form and a member of our team will get in touch with you. Gusto takes security and protection of your personal information very seriously. Please review our Fraudulent Activity Disclaimer. Personal information collected and processed as part of your Gusto application will be subject to Gusto's Applicant Privacy Notice.",
    "id": "gusto-senior-motion-designer-brand-studio-denver-co",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "6963956",
    "title": "Senior Motion Designer, Brand Studio",
    "company_name": "gusto",
    "company_slug": "gusto",
    "location": "Denver, CO",
    "locations": [
      "Denver, CO"
    ],
    "url": "https://job-boards.greenhouse.io/gusto/jobs/6963956",
    "departments": [
      "Product Design"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:53:54-05:00",
    "fetched_at": "2026-01-17T04:05:36.415Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;p style=&quot;line-height: 1.2;&quot;&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Gusto&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;At Gusto, we&#39;re on a mission to grow the small business economy. We handle the hard stuff—like payroll, health insurance, 401(k)s, and HR—so owners can focus on their craft and customers. With teams in Denver, San Francisco, and New York, we’re proud to support more than 400,000 small businesses across the country, and we’re building a workplace that represents and celebrates the customers we serve. Learn more about our &lt;/span&gt;&lt;a href=&quot;https://gusto.com/about/careers/total-rewards&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Total Rewards philosophy&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;h4&gt;&lt;strong&gt;About the Opportunity&lt;/strong&gt;&lt;/h4&gt;\n&lt;p&gt;Editing and motion are where our stories truly take shape. Pacing, sound, motion, and color aren’t finishing touches—they’re the work. They’re how we earn trust, convey clarity, and make people feel something.&lt;/p&gt;\n&lt;p&gt;Gusto is expanding our in-house creative studio inside our fast-moving, late-stage startup. We make cinematic brand films, product stories, and customer-driven narratives—and we also partner closely with our social team to bring those stories to life where our audience spends time. It’s common to shift between a polished long-form piece and fast-turn social work in the same week.&lt;/p&gt;\n&lt;p&gt;We’re looking for a&amp;nbsp;Staff Motion Designer who is a hands-on maker: someone who loves editing and motion design, takes real ownership of the final product, and wants to help shape how video and motion show up across our brand. This is a senior individual contributor role, focused on post-production craft and storytelling.&lt;/p&gt;\n&lt;p&gt;In this role, you’ll own the motion and edit from rough cut through final delivery. You’ll make judgment calls about pacing, sound, animation, and color. You’ll collaborate closely with other creatives and cross-functional partners on our marketing team to produce great work that defines our brand and that has an impact. And you’ll help us raise the bar while also making the work easier to scale—through better workflows, smarter templates, and mindful use of modern tools.&lt;/p&gt;\n&lt;p&gt;If you’re energized by being close to the work, care deeply about taste, and enjoy improving both the output &lt;em&gt;and&lt;/em&gt; the process, this role will be a top-notch fit.&lt;/p&gt;\n&lt;h4&gt;&lt;strong&gt;Here’s what you’ll do day-to-day&lt;/strong&gt;&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;Edit brand films, product stories, interviews, explainers, and social-first content&lt;/li&gt;\n&lt;li&gt;Design motion graphics, typography, transitions, and animation that serve the story—not the other way around&lt;/li&gt;\n&lt;li&gt;Shape expressive arcs through pacing, sound design, and color&lt;/li&gt;\n&lt;li&gt;Partner closely with other creatives and cross-functional partners from our marketing, comms and social teams from rough cut through final delivery&lt;/li&gt;\n&lt;li&gt;Build repeatable templates and workflows that enable faster turnaround without sacrificing quality&lt;/li&gt;\n&lt;li&gt;Use modern editing and motion tools—including AI-enabled workflows—to explore, iterate, and produce more proficiently&lt;/li&gt;\n&lt;li&gt;Keep post-production organized and deliver final assets that meet creative and technical standards&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4&gt;&lt;strong&gt;Here’s what we’re looking for&lt;/strong&gt;&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of experience editing and designing motion for brand, film, agency, or content studios&lt;/li&gt;\n&lt;li&gt;Expert-level fluency in editing and motion tools, with curiosity and judgment around emerging AI-enabled methods&lt;/li&gt;\n&lt;li&gt;A portfolio that demonstrates robust storytelling, mindful motion design, and range across formats&lt;/li&gt;\n&lt;li&gt;Sharp instincts for sound design, pacing, color, and transitions&lt;/li&gt;\n&lt;li&gt;Comfort shifting between polished, narrative-driven work and fast, social-first content&lt;/li&gt;\n&lt;li&gt;Proficient collaboration skills across creative, production, and marketing partners&lt;/li&gt;\n&lt;li&gt;A maker mindset—you enjoy improving how work gets made, not just making the work itself&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Compensation Details&lt;/strong&gt;&lt;/p&gt;\n&lt;p class=&quot;p1&quot;&gt;At Gusto, we strive to provide rewards that empower employees to achieve their financial and personal goals. We offer competitive compensation packages with a strong emphasis on equity based compensation (ownership in Gusto). To learn more about Gusto’s compensation philosophy and benefits offerings please view our Total Rewards Approach page.&amp;nbsp;&lt;/p&gt;\n&lt;p class=&quot;p1&quot;&gt;Our cash compensation range for this role is $146,000/yr to $183,000/yr in Denver &amp;amp; most remote locations, and $177,000/yr to $222,000/yr in San Francisco, Seattle &amp;amp; New York. Final offer amounts are determined by multiple factors, including candidate experience and expertise, and may vary from the amounts listed above.&lt;/p&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Gusto has physical office spaces in Denver, San Francisco, and New York City. Employees who are based in those locations will be expected to work from the office on designated days approximately &lt;strong&gt;2-3 days &lt;/strong&gt;per week (or more depending on role). The same office expectations apply to all Symmetry roles, Gusto&#39;s subsidiary, whose physical office is in Scottsdale.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Note: The San Francisco office expectations encompass both the San Francisco and San Jose metro areas.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;When approved to work from a location other than a Gusto office, a secure, reliable, and consistent internet connection is required. This includes non-office days for hybrid employees.&lt;/p&gt;\n&lt;hr&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it&#39;s the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. We want to see our candidates perform to the best of their ability. If you require a medical or religious accommodation at any time throughout your candidate journey, please fill out &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSdEfl7Bp-Twz7LLlhGlha46CrxZ9Kacgakmarf3K2TbnaEgKQ/viewform&quot;&gt;this form&lt;/a&gt; and a member of our team will get in touch with you.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Gusto takes security and protection of your personal information very seriously. Please review our &lt;a href=&quot;https://gusto.com/about/careers/fraudulent-activity-disclaimer&quot;&gt;Fraudulent Activity Disclaimer&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;Personal information collected and processed as part of your Gusto application will be subject to&amp;nbsp;&lt;a href=&quot;https://gusto.com/about/careers/applicant-privacy-notice&quot; target=&quot;_blank&quot;&gt;Gusto&#39;s Applicant Privacy Notice&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 6963956
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "[Expression of Interest] Research Scientist/Engineer, Honesty",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4532887008",
    "job_posted_at_datetime_utc": "2026-01-15T18:51:00-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you'll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains. Note: The team is based in New York and so we have a preference for candidates who can be based in New York. For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model Create and maintain comprehensive honesty benchmarks and evaluation frameworks Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses Design and implement prompting pipelines to generate data that improves model accuracy and honesty Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims Create tools to help human evaluators efficiently assess model outputs for accuracy You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field Possess strong programming skills in Python Have industry experience with language model finetuning and classifier training Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy Care about AI safety and the accuracy and honesty of both current and future AI systems Have experience in data science or the creation and curation of datasets for finetuning LLMs An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs Strong candidates may also have: Published work on hallucination prevention, factual grounding, or knowledge integration in language models Experience with fact-grounding techniques Background in developing confidence estimation or calibration methods for ML models A track record of creating and maintaining factual knowledge bases Familiarity with RLHF specifically applied to improving model truthfulness Worked with crowd-sourcing platforms and human feedback collection systems Experience developing evaluations of model accuracy or hallucinations Join us in our mission to ensure advanced AI systems behave reliably and ethically while staying aligned with human values. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-expression-of-interest-research-scientist-engineer-honesty-new-york-city-ny-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4532887008",
    "title": "[Expression of Interest] Research Scientist/Engineer, Honesty",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA",
    "locations": [
      "New York City, NY; San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4532887008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:51:00-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&amp;nbsp;&lt;/h2&gt;\n&lt;p&gt;As a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you&#39;ll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: The team is based in New York and so we have a preference for candidates who can be based in New York. &lt;/em&gt;&lt;em&gt;For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model’s knowledge&lt;/li&gt;\n&lt;li&gt;Develop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model&lt;/li&gt;\n&lt;li&gt;Create and maintain comprehensive honesty benchmarks and evaluation frameworks&lt;/li&gt;\n&lt;li&gt;Implement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems&lt;/li&gt;\n&lt;li&gt;Design and deploy human feedback collection specifically for identifying and correcting miscalibrated responses&lt;/li&gt;\n&lt;li&gt;Design and implement prompting pipelines to generate data that improves model accuracy and honesty&lt;/li&gt;\n&lt;li&gt;Develop and test novel RL environments that reward truthful outputs and penalize fabricated claims&lt;/li&gt;\n&lt;li&gt;Create tools to help human evaluators efficiently assess model outputs for accuracy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have an MS/PhD in Computer Science, ML, or related field&lt;/li&gt;\n&lt;li&gt;Possess strong programming skills in Python&lt;/li&gt;\n&lt;li&gt;Have industry experience with language model finetuning and classifier training&lt;/li&gt;\n&lt;li&gt;Show proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy&lt;/li&gt;\n&lt;li&gt;Care about AI safety and the accuracy and honesty of both current and future AI systems&lt;/li&gt;\n&lt;li&gt;Have experience in data science or the creation and curation of datasets for finetuning LLMs&lt;/li&gt;\n&lt;li&gt;An understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Published work on hallucination prevention, factual grounding, or knowledge integration in language models&lt;/li&gt;\n&lt;li&gt;Experience with fact-grounding techniques&lt;/li&gt;\n&lt;li&gt;Background in developing confidence estimation or calibration methods for ML models&lt;/li&gt;\n&lt;li&gt;A track record of creating and maintaining factual knowledge bases&lt;/li&gt;\n&lt;li&gt;Familiarity with RLHF specifically applied to improving model truthfulness&lt;/li&gt;\n&lt;li&gt;Worked with crowd-sourcing platforms and human feedback collection systems&lt;/li&gt;\n&lt;li&gt;Experience developing evaluations of model accuracy or hallucinations&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Join us in our mission to ensure advanced AI systems behave reliably and ethically while staying aligned with human values.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4532887008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4520279008",
    "job_posted_at_datetime_utc": "2026-01-15T18:50:19-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you'll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You'll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior. Note: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year Responsibilities: Develop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines Use these to train models to have better alignment properties including honesty, character, and harmlessness Create and maintain evaluation frameworks to measure alignment properties in models Collaborate across teams to integrate alignment improvements into production models Develop processes to help automate and scale the work of the team You may be a good fit if you: Have an MS/PhD in Computer Science, ML, or related field, or equivalent experience Possess strong programming skills, especially in Python Have experience with ML model training and experimentation Have a track record of implementing ML research Demonstrate strong analytical skills for interpreting experimental results Have experience with ML metrics and evaluation frameworks Excel at turning research ideas into working code Can identify and resolve practical implementation challenges Strong candidates may also have: Experience with language model finetuning Background in AI alignment research Published work in ML or alignment Experience with synthetic data generation Familiarity with techniques like RLHF, constitutional AI, and reward modeling Track record of designing and implementing novel training approaches Experience with model behavior evaluation and improvement The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$350,000 - $500,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-expression-of-interest-research-scientist-engineer-alignment-finetuning-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4520279008",
    "title": "[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4520279008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:50:19-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you&#39;ll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You&#39;ll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;Note: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines&lt;/li&gt;\n&lt;li&gt;Use these to train models to have better alignment properties including honesty, character, and harmlessness&lt;/li&gt;\n&lt;li&gt;Create and maintain evaluation frameworks to measure alignment properties in models&lt;/li&gt;\n&lt;li&gt;Collaborate across teams to integrate alignment improvements into production models&lt;/li&gt;\n&lt;li&gt;Develop processes to help automate and scale the work of the team&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have an MS/PhD in Computer Science, ML, or related field, or equivalent experience&lt;/li&gt;\n&lt;li&gt;Possess strong programming skills, especially in Python&lt;/li&gt;\n&lt;li&gt;Have experience with ML model training and experimentation&lt;/li&gt;\n&lt;li&gt;Have a track record of implementing ML research&lt;/li&gt;\n&lt;li&gt;Demonstrate strong analytical skills for interpreting experimental results&lt;/li&gt;\n&lt;li&gt;Have experience with ML metrics and evaluation frameworks&lt;/li&gt;\n&lt;li&gt;Excel at turning research ideas into working code&lt;/li&gt;\n&lt;li&gt;Can identify and resolve practical implementation challenges&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with language model finetuning&lt;/li&gt;\n&lt;li&gt;Background in AI alignment research&lt;/li&gt;\n&lt;li&gt;Published work in ML or alignment&lt;/li&gt;\n&lt;li&gt;Experience with synthetic data generation&lt;/li&gt;\n&lt;li&gt;Familiarity with techniques like RLHF, constitutional AI, and reward modeling&lt;/li&gt;\n&lt;li&gt;Track record of designing and implementing novel training approaches&lt;/li&gt;\n&lt;li&gt;Experience with model behavior evaluation and improvement&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$350,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$500,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4520279008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "job_posted_at_datetime_utc": "2026-01-15T18:48:40-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We're seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you'll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology. As a founding member of our team, you'll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You'll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact. Responsibilities: Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications Develop and execute strategies to systematically improve model performance on scientific tasks Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery Collaborate with domain experts and partners to establish benchmarks and gather high-quality data Translate between biological domain knowledge and machine learning objectives You may be a good fit if you: Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models Have 5+ years of hands-on experience in life sciences R&D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems Are proficient in Python and familiar with modern ML development practices Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments Can work independently while maintaining strong collaboration with cross-functional teams Are results-oriented, with a bias towards flexibility and impact Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards Have experience managing data pipelines and working with large-scale biological datasets Strong candidates may have: Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience Published research or practical experience in scientific AI applications or long-horizon reasoning A history working on Reinforcement Learning and/or Pretraining Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing) Experience with modern machine learning techniques and model training methodologies Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools Experience in drug discovery, including computational chemistry or structure-based design Knowledge of regulatory requirements for therapeutic development or clinical research Contributions to open-source scientific software or databases This role offers a unique opportunity to shape how AI transforms biological research. You'll work with some of the world's best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you're excited about using your expertise to guide the development of transformative AI systems, we want to hear from you. Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$280,000 - $350,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-research-engineer-research-scientist-biology-life-sciences-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4924308008",
    "title": "Research Engineer / Research Scientist, Biology & Life Sciences",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4924308008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:48:40-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We&#39;re seeking an exceptional Research Engineer / Research Scientist to join our Life Science team at Anthropic. Our team is organized around the north star goal of accelerating progress in the life sciences, from early discovery through translation, by an order of magnitude. Our team likes to think across the whole model stack. In this role, you&#39;ll combine your deep expertise in biology with machine learning engineering to develop novel evaluation frameworks and training strategies that push the frontier of what AI can achieve in biology.&lt;/p&gt;\n&lt;p&gt;As a founding member of our team, you&#39;ll work at the intersection of cutting-edge AI and the biological sciences, developing rigorous methods to measure and improve model performance on complex scientific tasks. You&#39;ll collaborate closely with world-class researchers and engineers to build AI systems that can engage in all phases of research and development, while maintaining our commitment to safety and beneficial impact.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement evaluation methodologies for assessing AI model capabilities relevant to biological research and applications&lt;/li&gt;\n&lt;li&gt;Develop and execute strategies to systematically improve model performance on scientific tasks&lt;/li&gt;\n&lt;li&gt;Develop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery&lt;/li&gt;\n&lt;li&gt;Collaborate with domain experts and partners to establish benchmarks and gather high-quality data&lt;/li&gt;\n&lt;li&gt;Translate between biological domain knowledge and machine learning objectives&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 8+ years of machine learning experience, with demonstrated ability to train and evaluate large language models&lt;/li&gt;\n&lt;li&gt;Have 5+ years of hands-on experience in life sciences R&amp;amp;D, with deep expertise in areas such as molecular biology, drug discovery, or computational biology&lt;/li&gt;\n&lt;li&gt;Have a track record of bridging biological domain knowledge with computational approaches to solve real scientific problems&lt;/li&gt;\n&lt;li&gt;Are proficient in Python and familiar with modern ML development practices&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating ambiguity and developing solutions in rapidly evolving research environments&lt;/li&gt;\n&lt;li&gt;Can work independently while maintaining strong collaboration with cross-functional teams&lt;/li&gt;\n&lt;li&gt;Are results-oriented, with a bias towards flexibility and impact&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced research environment where you balance rigorous scientific standards with rapid iteration&lt;/li&gt;\n&lt;li&gt;Are passionate about using AI to accelerate scientific discovery while maintaining high ethical standards&lt;/li&gt;\n&lt;li&gt;Have experience managing data pipelines and working with large-scale biological datasets&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ph.D. in a biological science (molecular biology, biochemistry, computational biology), in Machine Learning, or in a related field, or equivalent industry experience&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in scientific AI applications or long-horizon reasoning&lt;/li&gt;\n&lt;li&gt;A history working on Reinforcement Learning and/or Pretraining&lt;/li&gt;\n&lt;li&gt;Knowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)&lt;/li&gt;\n&lt;li&gt;Experience with modern machine learning techniques and model training methodologies&lt;/li&gt;\n&lt;li&gt;Familiarity with biological databases (UniProt, GenBank, PDB) and computational biology tools&lt;/li&gt;\n&lt;li&gt;Experience in drug discovery, including computational chemistry or structure-based design&lt;/li&gt;\n&lt;li&gt;Knowledge of regulatory requirements for therapeutic development or clinical research&lt;/li&gt;\n&lt;li&gt;Contributions to open-source scientific software or databases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This role offers a unique opportunity to shape how AI transforms biological research. You&#39;ll work with some of the world&#39;s best AI researchers while tackling problems that matter deeply for human health and scientific understanding. If you&#39;re excited about using your expertise to guide the development of transformative AI systems, we want to hear from you.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$280,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$350,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4924308008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Machine Learning Engineer, Virtual Collaborator",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA; Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4946308008",
    "job_posted_at_datetime_utc": "2026-01-15T18:48:02-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role We are looking for a Machine Learning Engineer to help us train Claude specifically for virtual collaborator workflows. While Claude excels at general tasks, a lot of knowledge work requires targeted training on real organizational data and workflows. Your job will be to design and implement reinforcement learning environments that transform Claude into the best virtual collaborator, training on everything from navigating internal knowledge to creating financial models. Responsibilities: Designing and implementing reinforcement learning pipelines specifically targeted at virtual collaborator use cases (productivity, organizational navigation, vertical domains) Building and scaling our data creation platform for generating high-quality, open-ended tasks with domain experts and crowdworkers Integrating real organizational data to create authentic training environments Developing robust rubric-based evaluation systems that maintain quality while avoiding reward hacking Training Claude on advanced document manipulation, including understanding, enhancing, and co-creating Partnering directly with product teams to ensure training aligns with shipped features You may be a good fit if you: Are a very experienced Python programmer who can quickly produce reliable, high quality code that your teammates love using Have strong machine learning experience Thrive at the intersection of research and product, with a pragmatic approach to solving real-world problems Are comfortable with ambiguity and can balance research rigor with shipping deadlines Enjoy collaborating across multiple teams (data operations, model training, product) Can context-switch between research problems and product engineering tasks Care about making AI genuinely helpful for everyday enterprise workflows Strong candidates may also have experience with: Building human-in-the-loop training systems or crowdsourcing platforms Working with enterprise tools and APIs (Google Workspace, Microsoft Office, Slack, etc.) Developing evaluation frameworks for open-ended tasks Domain expertise in finance, legal, or healthcare workflows Creating scalable data pipelines with quality control mechanisms Reward modeling and preventing reward hacking in RL systems Translating product requirements into technical training objectives Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$500,000 - $850,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-staff-machine-learning-engineer-virtual-collaborator-new-york-city-ny-san-francisco-ca-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4946308008",
    "title": "Staff Machine Learning Engineer, Virtual Collaborator",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA; Seattle, WA",
    "locations": [
      "New York City, NY; San Francisco, CA; Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4946308008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:48:02-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;We are looking for a Machine Learning Engineer to help us train Claude specifically for virtual collaborator workflows. While Claude excels at general tasks, a lot of knowledge work requires targeted training on real organizational data and workflows. Your job will be to design and implement reinforcement learning environments that transform Claude into the best virtual collaborator, training on everything from navigating internal knowledge to creating financial models.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Designing and implementing reinforcement learning pipelines specifically targeted at virtual collaborator use cases (productivity, organizational navigation, vertical domains)&lt;/li&gt;\n&lt;li&gt;Building and scaling our data creation platform for generating high-quality, open-ended tasks with domain experts and crowdworkers Integrating real organizational data to create authentic training environments&lt;/li&gt;\n&lt;li&gt;Developing robust rubric-based evaluation systems that maintain quality while avoiding reward hacking&lt;/li&gt;\n&lt;li&gt;Training Claude on advanced document manipulation, including understanding, enhancing, and co-creating&lt;/li&gt;\n&lt;li&gt;Partnering directly with product teams to ensure training aligns with shipped features&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Are a very experienced Python programmer who can quickly produce reliable, high quality code that your teammates love using&lt;/li&gt;\n&lt;li&gt;Have strong machine learning experience&lt;/li&gt;\n&lt;li&gt;Thrive at the intersection of research and product, with a pragmatic approach to solving real-world problems&lt;/li&gt;\n&lt;li&gt;Are comfortable with ambiguity and can balance research rigor with shipping deadlines&lt;/li&gt;\n&lt;li&gt;Enjoy collaborating across multiple teams (data operations, model training, product)&lt;/li&gt;\n&lt;li&gt;Can context-switch between research problems and product engineering tasks&lt;/li&gt;\n&lt;li&gt;Care about making AI genuinely helpful for everyday enterprise workflows&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may also have experience with:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Building human-in-the-loop training systems or crowdsourcing platforms&lt;/li&gt;\n&lt;li&gt;Working with enterprise tools and APIs (Google Workspace, Microsoft Office, Slack, etc.)&lt;/li&gt;\n&lt;li&gt;Developing evaluation frameworks for open-ended tasks&lt;/li&gt;\n&lt;li&gt;Domain expertise in finance, legal, or healthcare workflows&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Creating scalable data pipelines with quality control mechanisms&lt;/li&gt;\n&lt;li&gt;Reward modeling and preventing reward hacking in RL systems&lt;/li&gt;\n&lt;li&gt;Translating product requirements into technical training objectives&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$500,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$850,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4946308008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Strategic Account Executive, Industries",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5055446008",
    "job_posted_at_datetime_utc": "2026-01-15T18:07:35-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Strategic Account Executive at Anthropic, you'll drive the adoption of safe, frontier AI by securing strategic deals with top enterprises across key industry verticals, unlocking new value streams throughout their business. You'll leverage your consultative sales expertise to propel revenue growth while becoming a trusted partner to customers, helping them embed and deploy AI while uncovering its full range of capabilities. In collaboration with GTM, product, and marketing teams, you'll continuously refine our value proposition, sales methodology, and market positioning to ensure differentiated value across key industry verticals. The ideal candidate will have a passion for developing industry-specific market segments, pinpointing high-potential opportunities within key industry verticals, and executing strategies to capture them. By driving deployment of Anthropic's emerging products, you will help enterprises obtain new capabilities while also advancing the ethical development of AI. Responsibilities: Win new business and drive revenue within a book of strategic industry accounts. Own the full sales cycle from prospecting to close, identifying and developing new opportunities across multiple business units and use cases within key industry verticals Navigate complex organizational structures and build consensus among diverse stakeholder groups. Develop multi-threaded relationships from individual contributors to C-suite executives across industry enterprises Design and execute innovative sales strategies to meet and exceed revenue quotas. Analyze your industry accounts' landscape, trends, and dynamics to translate high-level plans into targeted sales activities and campaigns Spearhead expansion by pinpointing new use cases and business units within key industry verticals. Collaborate cross-functionally to differentiate our offerings and sustain a competitive edge within your strategic industry accounts Own sophisticated deal cycles involving multiple stakeholders, technical evaluations, and complex procurement processes. Demonstrate resourcefulness when faced with challenges that defy easy solutions Build and maintain accurate pipeline forecasting while ensuring high forecast accuracy and consistency. Identify a robust set of business drivers behind all opportunities Inform product roadmaps and features by gathering customer feedback and conveying key industry market needs. Provide insights that strengthen our value proposition and enhance the customer experience within industry verticals Continuously refine the sales methodology by incorporating learnings into playbooks, templates, and best practices. Identify process improvements that optimize sales productivity and consistency across key industry verticals You may be a good fit if you: 10+ years of enterprise sales experience with a proven track record of closing complex deals with strategic accounts. Experience managing sophisticated sales cycles and securing deals with extended timelines and multiple stakeholders across key industry verticals Experience selling emerging technologies or complex solutions to large industry enterprises. Ability to navigate technical evaluations and translate complex capabilities into business value for industry-specific use cases Strong executive presence with demonstrated ability to engage C-suite executives and senior stakeholders. Experience presenting to boards and aligning solutions with strategic business initiatives within key industry verticals Exceptional relationship building skills with proven ability to develop multi-threaded relationships across large organizations. Experience building consensus among diverse stakeholder groups in industry environments Consultative sales approach with a focus on understanding customer business challenges and crafting tailored solutions. Ability to position yourself as a strategic advisor rather than a vendor within key industry verticals Strong cross-functional collaboration skills with an ability to mobilize internal resources including product, engineering, and partnership teams. Experience coordinating complex deals that require multiple internal stakeholders Resourcefulness and problem-solving abilities when faced with complex challenges. Demonstrated ability to navigate ambiguous situations and find creative solutions High level of organization and attention to detail with strong forecasting accuracy. Ability to manage multiple complex opportunities simultaneously Passion for AI and emerging technologies with enthusiasm for helping industry organizations transform through responsible AI deployment. Strong alignment with Anthropic's mission of developing safe, beneficial AI systems Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$360,000 - $435,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-strategic-account-executive-industries-new-york-city-ny-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5055446008",
    "title": "Strategic Account Executive, Industries",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; San Francisco, CA",
    "locations": [
      "New York City, NY; San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5055446008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:07:35-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Strategic Account Executive at Anthropic, you&#39;ll drive the adoption of safe, frontier AI by securing strategic deals with top enterprises across key industry verticals, unlocking new value streams throughout their business. You&#39;ll leverage your consultative sales expertise to propel revenue growth while becoming a trusted partner to customers, helping them embed and deploy AI while uncovering its full range of capabilities. In collaboration with GTM, product, and marketing teams, you&#39;ll continuously refine our value proposition, sales methodology, and market positioning to ensure differentiated value across key industry verticals.&lt;/p&gt;\n&lt;p&gt;The ideal candidate will have a passion for developing industry-specific market segments, pinpointing high-potential opportunities within key industry verticals, and executing strategies to capture them. By driving deployment of Anthropic&#39;s emerging products, you will help enterprises obtain new capabilities while also advancing the ethical development of AI.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Win new business and drive revenue within a book of strategic industry accounts. Own the full sales cycle from prospecting to close, identifying and developing new opportunities across multiple business units and use cases within key industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Navigate complex organizational structures and build consensus among diverse stakeholder groups. Develop multi-threaded relationships from individual contributors to C-suite executives across industry enterprises&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Design and execute innovative sales strategies to meet and exceed revenue quotas. Analyze your industry accounts&#39; landscape, trends, and dynamics to translate high-level plans into targeted sales activities and campaigns&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Spearhead expansion by pinpointing new use cases and business units within key industry verticals. Collaborate cross-functionally to differentiate our offerings and sustain a competitive edge within your strategic industry accounts&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Own sophisticated deal cycles involving multiple stakeholders, technical evaluations, and complex procurement processes. Demonstrate resourcefulness when faced with challenges that defy easy solutions&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Build and maintain accurate pipeline forecasting while ensuring high forecast accuracy and consistency. Identify a robust set of business drivers behind all opportunities&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Inform product roadmaps and features by gathering customer feedback and conveying key industry market needs. Provide insights that strengthen our value proposition and enhance the customer experience within industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Continuously refine the sales methodology by incorporating learnings into playbooks, templates, and best practices. Identify process improvements that optimize sales productivity and consistency across key industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;10+ years of enterprise sales experience with a proven track record of closing complex deals with strategic accounts. Experience managing sophisticated sales cycles and securing deals with extended timelines and multiple stakeholders across key industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience selling emerging technologies or complex solutions to large industry enterprises. Ability to navigate technical evaluations and translate complex capabilities into business value for industry-specific use cases&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong executive presence with demonstrated ability to engage C-suite executives and senior stakeholders. Experience presenting to boards and aligning solutions with strategic business initiatives within key industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Exceptional relationship building skills with proven ability to develop multi-threaded relationships across large organizations. Experience building consensus among diverse stakeholder groups in industry environments&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Consultative sales approach with a focus on understanding customer business challenges and crafting tailored solutions. Ability to position yourself as a strategic advisor rather than a vendor within key industry verticals&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong cross-functional collaboration skills with an ability to mobilize internal resources including product, engineering, and partnership teams. Experience coordinating complex deals that require multiple internal stakeholders&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Resourcefulness and problem-solving abilities when faced with complex challenges. Demonstrated ability to navigate ambiguous situations and find creative solutions&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;High level of organization and attention to detail with strong forecasting accuracy. Ability to manage multiple complex opportunities simultaneously&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Passion for AI and emerging technologies with enthusiasm for helping industry organizations transform through responsible AI deployment. Strong alignment with Anthropic&#39;s mission of developing safe, beneficial AI systems&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$360,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$435,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5055446008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Business Partner Analyst",
    "employer_name": "stripe",
    "job_city": "Chicago- New York City- San Francisco or Seattle",
    "job_apply_link": "https://stripe.com/jobs/search?gh_jid=5986232",
    "job_posted_at_datetime_utc": "2026-01-15T18:02:32-05:00",
    "job_description": "Help increase the GDP of the internet as part of our Operations team.",
    "id": "stripe-business-partner-analyst-chicago-new-york-city-san-francisco-or-seattle",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5986232",
    "title": "Business Partner Analyst",
    "company_name": "stripe",
    "company_slug": "stripe",
    "location": "Chicago- New York City- San Francisco or Seattle",
    "locations": [
      "Chicago- New York City- San Francisco or Seattle"
    ],
    "url": "https://stripe.com/jobs/search?gh_jid=5986232",
    "departments": [
      "4114 Product Management, Strategy & Analytics"
    ],
    "employment_type": null,
    "posted_at": "2026-01-15T18:02:32-05:00",
    "fetched_at": "2026-01-17T04:05:15.556Z",
    "description": "&lt;h2&gt;&lt;strong&gt;Who we are&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;em&gt;&lt;strong&gt;*Please note, this is a hybrid position out of one of our offices.&amp;nbsp;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;About Stripe&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Stripe is a financial infrastructure platform for businesses. Millions of companies - from the world’s largest enterprises to the most ambitious startups - use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone&#39;s reach while doing the most important work of your career.&lt;/span&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;About the team&lt;br&gt;&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;Strategy &amp;amp; Analytics (S&amp;amp;A) maximizes and accelerates Operations&#39; ability to make Stripe work for our users. We aspire to be the COOs &lt;em&gt;for&lt;/em&gt; Stripe Ops, working cross-functionally with global teams to help run the day-to-day business &lt;em&gt;and&lt;/em&gt; articulate and achieve the longer term, high effort, high value strategic priorities. We take a data-driven approach that combines strategy and analytics to help Ops leaders solve their most complex and most important issues while also driving the business planning and operational cadence end-to-end, from strategy to goal-setting to execution.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;What you’ll do&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;In this role, you’ll be the go-to expert for your business area. You’ll be hands-on and responsible for delivering critical insights, ensuring data driven decision making is at the core of what we do. You’ll also partner with leadership to drive business strategy, planning, goal-setting and performance tracking. You may also scope and lead mission critical projects and execute on strategic initiatives.&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Metrics &amp;amp; Insights: Wrangle large, highly complex datasets using SQL into actionable insights and become the data expert for your business area. Develop metrics and large-scale dashboards to track the health of our user-facing and internal teams. Perform analyses (using SQL &amp;amp; other analytical tools/languages), identify trends, conduct research, build models, all to deliver objective, critical insights that can inform leadership of opportunities, risks, and strategic priorities.&lt;/li&gt;\n&lt;li&gt;Communicate with executives: Create narratives and documents that tell the story of your business area to influence senior Operations leadership and Stripe executive team decision making&lt;/li&gt;\n&lt;li&gt;Stakeholder management: Influence and drive cross-functional change by partnering with stakeholders across a wide internal network of globally distributed teams, including Ops, Finance, Data Science, Product/Engineering, and more&lt;/li&gt;\n&lt;li&gt;Drive operational excellence: Design, optimize and drive operational reviews and rhythm of the business. Guide the planning and goal-setting process for your business area, as well as progress checks throughout the year. Bring and consistently apply a ROI lens to all operational decisions, so we can make better-informed trade-offs&lt;/li&gt;\n&lt;li data-stringify-indent=&quot;0&quot; data-stringify-border=&quot;0&quot;&gt;Support planning: support with forecasting/planning processes for your business area, including near/medium/long-term planning, to enable leadership to make strategic decisions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Who you are&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;We&#39;re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.&lt;/span&gt;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Minimum requirements&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;5+ years of prior experience in analytical and strategic roles in management consulting, Operations, Support, Risk&amp;nbsp; or Financial Services&lt;/li&gt;\n&lt;li&gt;Outstanding analytical ability, expert in SQL and understanding of data relationships&lt;/li&gt;\n&lt;li&gt;Outstanding communication, presentation skills &amp;amp; stakeholder management skills&lt;/li&gt;\n&lt;li&gt;Experience working in or with Operations, Support, Risk, Trust &amp;amp; Safety, Financial Crimes, or Financial Services&lt;/li&gt;\n&lt;li&gt;Expertise working cross-functionally and with globally distributed teams to drive business and operational goals using data&lt;/li&gt;\n&lt;li&gt;Ability to connect the big picture to minute details, toggling between them to set and operationalize strategy&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Preferred qualifications&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience working in fast-paced environments (e.g. high-growth internet or software company, management consulting)&lt;/li&gt;\n&lt;li&gt;Structured problem solving skills, combined with strong business acumen.&lt;/li&gt;\n&lt;li&gt;Experience with Tableau&lt;/li&gt;\n&lt;/ul&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5986232
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  }
]