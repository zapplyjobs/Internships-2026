[
  {
    "job_title": "",
    "employer_name": "AgZen",
    "job_city": "Cambridge",
    "job_state": "MA",
    "job_description": ".fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-mobile-site-gutter, 6vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (8 - 1)) ) / 8 ); display: grid; position: relative; grid-area: 1/1/-1/-1; grid-template-rows: repeat(12,minmax(24px, auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(8, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); row-gap: 11.0px; column-gap: 11.0px; overflow-x: hidden; overflow-x: clip; } @media (min-width: 768px) { .background-width--inset .fe-681e70c2a649507003c3aab5 { --inset-padding: calc(var(--sqs-site-gutter) * 2); } .fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-site-gutter, 4vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (24 - 1)) ) / 24 ); --inset-padding: 0vw; --row-height-scaling-factor: 0.0215; --container-width: min(var(--sqs-site-max-width, 1500px), calc(100vw - var(--sqs-site-gutter, 4vw) * 2 - var(--inset-padding) )); grid-template-rows: repeat(13,minmax(calc(var(--container-width) * var(--row-height-scaling-factor)), auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(24, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); } } .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/7/10; z-index: 1; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/2/26; z-index: 2; position: sticky; top: calc(0px + var(--header-fixed-top-offset, 0px)); } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } } .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 7/2/13/10; z-index: 2; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 2/2/7/26; z-index: 1; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } }",
    "job_apply_link": "https://www.agzen.com/jobs?gh_jid=4048593009",
    "job_posted_at_datetime_utc": "2025-10-21T00:25:19.000Z",
    "job_employment_type": "FULLTIME",
    "job_posted_at": "1h",
    "id": "agzen--cambridge",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Claude Experiences",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5062968008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Claude is used by millions of people every day through our web, mobile, and desktop applications. As these products scale, so does the complexity of coordinating across engineering teams and cross-functional partners. We need an experienced Technical Program Manager to drive critical initiatives across our product engineering organization. You'll be instrumental in coordinating high-complexity cross-team efforts, driving launch readiness, and ensuring seamless execution across platform and product teams. This role is critical as our products grow in scale and complexity. Responsibilities: Lead cross-team engineering initiatives, coordinating between platform, product, and infrastructure teams to deliver high-quality releases Drive program execution for major product features, ensuring alignment across engineering, legal, policy, and other cross-functional partners Partner with engineering leadership to improve development velocity, manage dependencies, and remove blockers Build and maintain relationships across engineering teams to understand technical requirements, constraints, and tradeoffs Create comprehensive program documentation including roadmaps, status reports, risk assessments, and communication plans Facilitate technical decision-making by bringing together stakeholders, driving consensus, and ensuring timely resolution of blocking issues Establish processes and frameworks for scaling product development and improving engineering excellence Drive launch readiness across teams, ensuring predictable and well-communicated releases You may be a good fit if you: Have several years of experience in technical program management, with a track record of successfully delivering complex, cross-functional programs Have experience with web, mobile, or client application development and the ability to engage meaningfully with frontend and backend engineers Have experience coordinating across multiple engineering teams and cross-functional partners (legal, policy, etc.) simultaneously Are highly organized and can manage multiple parallel workstreams effectively across distributed teams Thrive in unstructured environments with a knack for bringing order to chaos and creating clarity in ambiguous situations Have excellent written and verbal communication skills, with the ability to influence without authority Have a track record of building trust with technical teams and driving change through influence Are passionate about Anthropic's mission and interested in the challenges of bringing AI capabilities to users safely and reliably Have experience with high-growth products serving large user bases (preferred but not required) Deadline to apply: None, applications will be received on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-claude-experiences-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5062968008",
    "title": "Technical Program Manager, Claude Experiences",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5062968008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Claude is used by millions of people every day through our web, mobile, and desktop applications. As these products scale, so does the complexity of coordinating across engineering teams and cross-functional partners. We need an experienced Technical Program Manager to drive critical initiatives across our product engineering organization.&lt;/p&gt;\n&lt;p&gt;You&#39;ll be instrumental in coordinating high-complexity cross-team efforts, driving launch readiness, and ensuring seamless execution across platform and product teams. This role is critical as our products grow in scale and complexity.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead cross-team engineering initiatives, coordinating between platform, product, and infrastructure teams to deliver high-quality releases&lt;/li&gt;\n&lt;li&gt;Drive program execution for major product features, ensuring alignment across engineering, legal, policy, and other cross-functional partners&lt;/li&gt;\n&lt;li&gt;Partner with engineering leadership to improve development velocity, manage dependencies, and remove blockers&lt;/li&gt;\n&lt;li&gt;Build and maintain relationships across engineering teams to understand technical requirements, constraints, and tradeoffs&lt;/li&gt;\n&lt;li&gt;Create comprehensive program documentation including roadmaps, status reports, risk assessments, and communication plans&lt;/li&gt;\n&lt;li&gt;Facilitate technical decision-making by bringing together stakeholders, driving consensus, and ensuring timely resolution of blocking issues&lt;/li&gt;\n&lt;li&gt;Establish processes and frameworks for scaling product development and improving engineering excellence&lt;/li&gt;\n&lt;li&gt;Drive launch readiness across teams, ensuring predictable and well-communicated releases&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have several years of experience in technical program management, with a track record of successfully delivering complex, cross-functional programs&lt;/li&gt;\n&lt;li&gt;Have experience with web, mobile, or client application development and the ability to engage meaningfully with frontend and backend engineers&lt;/li&gt;\n&lt;li&gt;Have experience coordinating across multiple engineering teams and cross-functional partners (legal, policy, etc.) simultaneously&lt;/li&gt;\n&lt;li&gt;Are highly organized and can manage multiple parallel workstreams effectively across distributed teams&lt;/li&gt;\n&lt;li&gt;Thrive in unstructured environments with a knack for bringing order to chaos and creating clarity in ambiguous situations&lt;/li&gt;\n&lt;li&gt;Have excellent written and verbal communication skills, with the ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Have a track record of building trust with technical teams and driving change through influence&lt;/li&gt;\n&lt;li&gt;Are passionate about Anthropic&#39;s mission and interested in the challenges of bringing AI capabilities to users safely and reliably&lt;/li&gt;\n&lt;li&gt;Have experience with high-growth products serving large user bases (preferred but not required)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None, applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5062968008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Data Center Infrastructure",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5013743008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role You'll drive cross-functional execution of Anthropic's data center programs from construction through commissioning and day-to-day operations. Partnering with our Data Center and Compute teams, you'll own the program management that delivers buildings on time ready for production workloads. As we scale beyond our first sites, you'll focus on accelerating construction and deployment, building repeatable playbooks, and driving continuous improvement across our growing footprint. Responsibilities: Manage and develop the DC infrastructure TPM team; hire and build out the function as we scale Lead program reviews and executive communications on delivery status, risks, and blockers Drive construction-to-production execution across multiple sites, coordinating with partners, contractors, and internal teams Own overall schedule tracking, risk identification, and mitigation; creating clear visibility for leadership Align with energy and location strategy and support site selection and due diligence criteria to facilitate scaling well in advance of aggressive compute demand Manage long pole dependencies and long-lead time development & procurement across a dynamically changing global marketplace Partner with DC and Compute teams to drive handover criteria between site completion, equipment deployment, and operations Coordinate with Infrastructure, Security, and Compliance teams on evolving requirements; versioning, optimization, and expansion across sites Drive partner accountability on contractual milestones and commercial commitments Coordinate equipment delivery and manage vendor accountability on schedules; tracking production and shipping milestones while maintaining productive partnerships Build repeatable processes and playbooks that scale across multiple concurrent site deployments Travel (20%) to sites to validate progress and build contractor relationships You may be a good fit if you: Have 7+ years in data center construction, operations, or infrastructure program management at hyperscale or critical infrastructure companies Have management experience building and leading TPM or program management teams Have led multi-site infrastructure programs with compressed timelines and complex cross-functional dependencies among multiple partners and vendors Excel at aligning multiple partners, vendors, and internal engineering teams around shared deliverables Can bridge physical infrastructure and software/security teams Thrive in ambiguity and make decisions with incomplete information under schedule pressure Communicate complex program status clearly to executives Deadline to apply: None applications will be received on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$365,000 - $435,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-data-center-infrastructure-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5013743008",
    "title": "Technical Program Manager, Data Center Infrastructure",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5013743008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You&#39;ll drive cross-functional execution of Anthropic&#39;s data center programs from construction through commissioning and day-to-day operations. Partnering with our Data Center and Compute teams, you&#39;ll own the program management that delivers buildings on time ready for production workloads. As we scale beyond our first sites, you&#39;ll focus on accelerating construction and deployment, building repeatable playbooks, and driving continuous improvement across our growing footprint.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Manage and develop the DC infrastructure TPM team; hire and build out the function as we scale&lt;/li&gt;\n&lt;li&gt;Lead program reviews and executive communications on delivery status, risks, and blockers&lt;/li&gt;\n&lt;li&gt;Drive construction-to-production execution across multiple sites, coordinating with partners, contractors, and internal teams&lt;/li&gt;\n&lt;li&gt;Own overall schedule tracking, risk identification, and mitigation; creating clear visibility for leadership&lt;/li&gt;\n&lt;li&gt;Align with energy and location strategy and support site selection and due diligence criteria to facilitate scaling well in advance of aggressive compute demand&lt;/li&gt;\n&lt;li&gt;Manage long pole dependencies and long-lead time development &amp;amp; procurement across a dynamically changing global marketplace&lt;/li&gt;\n&lt;li&gt;Partner with DC and Compute teams to drive handover criteria between site completion, equipment deployment, and operations&lt;/li&gt;\n&lt;li&gt;Coordinate with Infrastructure, Security, and Compliance teams on evolving requirements; versioning, optimization, and expansion across sites&lt;/li&gt;\n&lt;li&gt;Drive partner accountability on contractual milestones and commercial commitments&lt;/li&gt;\n&lt;li&gt;Coordinate equipment delivery and manage vendor accountability on schedules; tracking production and shipping milestones while maintaining productive partnerships&lt;/li&gt;\n&lt;li&gt;Build repeatable processes and playbooks that scale across multiple concurrent site deployments&lt;/li&gt;\n&lt;li&gt;Travel (20%) to sites to validate progress and build contractor relationships&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 7+ years in data center construction, operations, or infrastructure program management at hyperscale or critical infrastructure companies&lt;/li&gt;\n&lt;li&gt;Have management experience building and leading TPM or program management teams&lt;/li&gt;\n&lt;li&gt;Have led multi-site infrastructure programs with compressed timelines and complex cross-functional dependencies among multiple partners and vendors&lt;/li&gt;\n&lt;li&gt;Excel at aligning multiple partners, vendors, and internal engineering teams around shared deliverables&lt;/li&gt;\n&lt;li&gt;Can bridge physical infrastructure and software/security teams&lt;/li&gt;\n&lt;li&gt;Thrive in ambiguity and make decisions with incomplete information under schedule pressure&lt;/li&gt;\n&lt;li&gt;Communicate complex program status clearly to executives&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$365,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$435,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5013743008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Inference",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4913784008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About Anthropic Anthropic is an AI safety and research company working to build reliable, interpretable, and steerable AI systems. We aim to make AI safe and beneficial for our customers and society as a whole. Our interdisciplinary team brings expertise from ML, physics, policy, business, and product development. About the Role As a Technical Program Manager for Inference, you'll be the critical bridge between our inference systems and the broader organization. You'll drive strategic initiatives around inference infrastructure adoption, capacity management, and deployment processes while ensuring seamless coordination across research, engineering, and product teams. This role is essential for scaling our inference infrastructure to meet growing demand while maintaining operational excellence. Responsibilities: Systems Integration & Coordination: Lead cross-functional initiatives for new infrastructure integration, establishing clear ownership, timelines, and communication channels between teams. Drive end-to-end planning for major infrastructure transitions including platform modernization and new tech adoption. Capacity Management: Develop and maintain processes for inference capacity planning and optimization. Partner with engineering teams to track utilization metrics, identify bottlenecks, and coordinate with capacity teams on resource allocation and model deprecation strategies. Deployment Excellence: Establish and enforce governance for deployment processes, defining clear policies for self-service versus managed deployments. Create and maintain service level agreements for different deployment types and ensure smooth launches across teams. Strategic Planning: Own and prioritize the inference deployment roadmap, working closely with engineering leadership to prioritize initiatives and manage dependencies. Provide visibility into upcoming changes and their organizational impact. Stakeholder Communication: Build strong relationships across research, engineering, and product teams to understand requirements and constraints. Translate technical complexities into clear updates for leadership and ensure alignment on priorities and timelines. Process Improvement: Identify inefficiencies in current workflows and drive systematic improvements. Establish metrics and dashboards to track infrastructure health, capacity utilization, and deployment success rates. You may be a good fit if you: Have several years of experience in technical program management, with proven success delivering complex infrastructure programs, preferably in ML/AI systems or large-scale distributed systems Have deep technical understanding of inference systems, or cloud infrastructure - enough to engage substantively with engineers and identify technical risks Excel at creating structure and processes in ambiguous environments, bringing clarity to complex cross-team initiatives Have strong stakeholder management skills and can build trust with both technical and non-technical partners Are comfortable navigating competing priorities and using data to drive technical decisions Have experience with infrastructure scaling initiatives, hardware integrations, or deployment governance Thrive in fast-paced environments and can balance strategic planning with tactical execution Are passionate about AI infrastructure and understand the unique challenges of deploying and scaling large language models Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-inference-san-francisco-ca-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4913784008",
    "title": "Technical Program Manager, Inference",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4913784008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is an AI safety and research company working to build reliable, interpretable, and steerable AI systems. We aim to make AI safe and beneficial for our customers and society as a whole. Our interdisciplinary team brings expertise from ML, physics, policy, business, and product development.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;About the Role&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Technical Program Manager for Inference, you&#39;ll be the critical bridge between our inference systems and the broader organization. You&#39;ll drive strategic initiatives around inference infrastructure adoption, capacity management, and deployment processes while ensuring seamless coordination across research, engineering, and product teams. This role is essential for scaling our inference infrastructure to meet growing demand while maintaining operational excellence.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&amp;nbsp;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Systems Integration &amp;amp; Coordination&lt;/strong&gt;: Lead cross-functional initiatives for new infrastructure integration, establishing clear ownership, timelines, and communication channels between teams. Drive end-to-end planning for major infrastructure transitions including platform modernization and new tech adoption.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Capacity Management:&lt;/strong&gt; Develop and maintain processes for inference capacity planning and optimization. Partner with engineering teams to track utilization metrics, identify bottlenecks, and coordinate with capacity teams on resource allocation and model deprecation strategies.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Deployment Excellence:&lt;/strong&gt; Establish and enforce governance for deployment processes, defining clear policies for self-service versus managed deployments. Create and maintain service level agreements for different deployment types and ensure smooth launches across teams.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Strategic Planning:&lt;/strong&gt; Own and prioritize the inference deployment roadmap, working closely with engineering leadership to prioritize initiatives and manage dependencies. Provide visibility into upcoming changes and their organizational impact.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stakeholder Communication:&lt;/strong&gt; Build strong relationships across research, engineering, and product teams to understand requirements and constraints. Translate technical complexities into clear updates for leadership and ensure alignment on priorities and timelines.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Process Improvement:&lt;/strong&gt; Identify inefficiencies in current workflows and drive systematic improvements. Establish metrics and dashboards to track infrastructure health, capacity utilization, and deployment success rates.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have several years of experience in technical program management, with proven success delivering complex infrastructure programs, preferably in ML/AI systems or large-scale distributed systems&lt;/li&gt;\n&lt;li&gt;Have deep technical understanding of inference systems, or cloud infrastructure - enough to engage substantively with engineers and identify technical risks&lt;/li&gt;\n&lt;li&gt;Excel at creating structure and processes in ambiguous environments, bringing clarity to complex cross-team initiatives&lt;/li&gt;\n&lt;li&gt;Have strong stakeholder management skills and can build trust with both technical and non-technical partners&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating competing priorities and using data to drive technical decisions&lt;/li&gt;\n&lt;li&gt;Have experience with infrastructure scaling initiatives, hardware integrations, or deployment governance&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced environments and can balance strategic planning with tactical execution&lt;/li&gt;\n&lt;li&gt;Are passionate about AI infrastructure and understand the unique challenges of deploying and scaling large language models&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4913784008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Launches",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5062960008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a Technical Program Manager for Product, you'll drive the programs that bring Anthropic’s AI capabilities to the world. You’ll work closely with research teams to understand new model capabilities, then orchestrate across engineering, product, infrastructure, and go-to-market teams to ensure we launch reliably and at pace. This role is essential in orchestrating the cross-functional effort required to launch successfully as Anthropic continues to scale. This role offers unique challenges in coordinating high-stakes technical programs while maintaining the quality and reliability our customers expect. This position requires deep technical fluency, the ability to earn trust with researchers and engineers, and a talent for driving alignment across teams with different priorities and working styles. Responsibilities: Lead end-to-end program management for model and product launches, coordinating between research, engineering, product, infrastructure, and partnership teams Drive cross-functional alignment and decision-making across workstreams, ensuring teams are unblocked and launches stay on track Partner closely with Research PMs and engineering leads to sequence work, manage dependencies, and navigate technical tradeoffs Track and communicate program status, risks, and dependencies to leadership and stakeholders Build strong relationships with technical stakeholders, earning trust through deep engagement with the details Coordinate with research teams to understand upcoming model capabilities and prepare launch plans accordingly Navigate tradeoffs between speed, quality, and scope, helping teams make informed decisions under pressure Develop and improve launch processes, playbooks, and operational frameworks that scale with our growing complexity Create and maintain documentation of launch processes, decision logs, and cross-functional dependencies You may be a good fit if you: Have several years of experience in technical program management, with a track record of successfully delivering complex, cross-functional programs Possess deep technical knowledge that allows you to engage meaningfully with ML researchers and engineers Have experience managing programs with significant external dependencies and multiple stakeholder groups Excel at translating between technical teams and stakeholders, making complex tradeoffs understandable Can thrive in ambiguous situations, bringing structure to complex technical challenges Have strong organizational skills and can manage multiple parallel workstreams effectively Are comfortable operating at a fast pace where priorities shift and new challenges emerge quickly Have excellent written and verbal communication skills, with the ability to influence without authority Build trust quickly and maintain strong relationships even under pressure Are passionate about Anthropic's mission and interested in the challenges of bringing frontier AI capabilities to users safely Deadline to apply: None, applications will be received on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-launches-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5062960008",
    "title": "Technical Program Manager, Launches",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5062960008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Technical Program Manager for Product, you&#39;ll drive the programs that bring Anthropic’s AI capabilities to the world. You’ll work closely with research teams to understand new model capabilities, then orchestrate across engineering, product, infrastructure, and go-to-market teams to ensure we launch reliably and at pace. This role is essential in orchestrating the cross-functional effort required to launch successfully as Anthropic continues to scale.&lt;/p&gt;\n&lt;p&gt;This role offers unique challenges in coordinating high-stakes technical programs while maintaining the quality and reliability our customers expect. This position requires deep technical fluency, the ability to earn trust with researchers and engineers, and a talent for driving alignment across teams with different priorities and working styles.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead end-to-end program management for model and product launches, coordinating between research, engineering, product, infrastructure, and partnership teams&lt;/li&gt;\n&lt;li&gt;Drive cross-functional alignment and decision-making across workstreams, ensuring teams are unblocked and launches stay on track&lt;/li&gt;\n&lt;li&gt;Partner closely with Research PMs and engineering leads to sequence work, manage dependencies, and navigate technical tradeoffs&lt;/li&gt;\n&lt;li&gt;Track and communicate program status, risks, and dependencies to leadership and stakeholders&lt;/li&gt;\n&lt;li&gt;Build strong relationships with technical stakeholders, earning trust through deep engagement with the details&lt;/li&gt;\n&lt;li&gt;Coordinate with research teams to understand upcoming model capabilities and prepare launch plans accordingly&lt;/li&gt;\n&lt;li&gt;Navigate tradeoffs between speed, quality, and scope, helping teams make informed decisions under pressure&lt;/li&gt;\n&lt;li&gt;Develop and improve launch processes, playbooks, and operational frameworks that scale with our growing complexity&lt;/li&gt;\n&lt;li&gt;Create and maintain documentation of launch processes, decision logs, and cross-functional dependencies&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have several years of experience in technical program management, with a track record of successfully delivering complex, cross-functional programs&lt;/li&gt;\n&lt;li&gt;Possess deep technical knowledge that allows you to engage meaningfully with ML researchers and engineers&lt;/li&gt;\n&lt;li&gt;Have experience managing programs with significant external dependencies and multiple stakeholder groups&lt;/li&gt;\n&lt;li&gt;Excel at translating between technical teams and stakeholders, making complex tradeoffs understandable&lt;/li&gt;\n&lt;li&gt;Can thrive in ambiguous situations, bringing structure to complex technical challenges&lt;/li&gt;\n&lt;li&gt;Have strong organizational skills and can manage multiple parallel workstreams effectively&lt;/li&gt;\n&lt;li&gt;Are comfortable operating at a fast pace where priorities shift and new challenges emerge quickly&lt;/li&gt;\n&lt;li&gt;Have excellent written and verbal communication skills, with the ability to influence without authority&lt;/li&gt;\n&lt;li&gt;Build trust quickly and maintain strong relationships even under pressure&lt;/li&gt;\n&lt;li&gt;Are passionate about Anthropic&#39;s mission and interested in the challenges of bringing frontier AI capabilities to users safely&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None, applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5062960008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Model Evaluations",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5018714008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a Technical Program Manager for model evaluations, you'll own end-to-end coordination of our evaluation ecosystem— building a feedback loop from shaping eval strategy during early model development through launch execution. You'll be the critical bridge between Research, Product, Marketing, and Engineering teams. This role sits at the intersection of frontier AI research and product launches. Evals are an important part of how we measure whether our models meet the bar—for capability, safety, and competitive positioning. Beyond launch coordination, you'll help scale our evals ecosystem: from early-stage model evals for RL environments, to the systems and infrastructure on which evals run, to tooling that enables the whole pipeline. A strong TPM in this space can immediately reduce chaos during launches while also driving systemic improvements that compound over time. Key Responsibilities: Launch Coordination Standardize how evaluation results are generated, documented, compared across model versions, and communicated to stakeholders Own end-to-end eval readiness for model launches—tracking which evals are ready, which need scores on past models, and which meet the bar for marketing materials Establish and enforce clear criteria for eval inclusion: scores on historical models, state-of-the-art performance, and competitor comparisons Coordinate between research teams, marketing, and product to consolidate eval status into a single source of truth Maintain a high bar: ensure reported statistics reflect model capabilities in an honest, accurate, and transparent way Ecosystem Development Get involved early in model development cycles, helping shape eval plans for RL environments Partner with research and infrastructure teams to improve underlying evals infrastructure—eval-syncer reliability, results storage and querying, automation capabilities Drive prioritization of eval tooling enhancements based on researcher needs Identify patterns across launches and drive systemic fixes rather than point solutions Work with PMs and researchers to improve and implement high priority evals launches Maintain and prioritize the eval roadmap—working with cross-functional teams to identify which new evals are needed for upcoming launches and product requirements Implement an operating model that reflects an evals environment with increasing complexity Process & Systems Build lightweight but rigorous tracking systems—moving key information into structured formats that enable better decision-making Create eval dashboards that provide real-time visibility into training progress on hero evals, enabling earlier intervention when scores look concerning Document eval processes, requirements, and lessons learned to build institutional knowledge Coordinate compute allocation for large-scale evals with infrastructure teams You May Be a Good Fit If You: Have 5+ years of technical program management experience with a track record of bringing order to chaotic, high-stakes coordination problems Possess scientific depth and a very high quality bar for data Have experience with ML/AI evaluation methodologies, benchmarking, or research quality assurance Have a background in research operations, scientific publishing, or data quality management Have previous experience as data analyst, data scientist, or software engineer Can build trust with research teams by understanding their work deeply enough to add value beyond coordination Are skilled at cross-functional coordination involving research, product, marketing, and engineering—navigating competing priorities and driving alignment Have working familiarity with data analysis tools (SQL, Python, or similar) for querying eval results and building dashboards Have familiarity with LLM capabilities and limitations and experience working with AI research teams Excel at written and verbal communication, translating technical nuance for marketing stakeholders while maintaining precision Thrive in unstructured environments with a bias toward action and a knack for creating clarity in ambiguous situations Have extremely high ownership and attention to detail Deadline to apply: None, applications will be received on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-model-evaluations-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5018714008",
    "title": "Technical Program Manager, Model Evaluations",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5018714008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a Technical Program Manager for model evaluations, you&#39;ll own end-to-end coordination of our evaluation ecosystem— building a feedback loop from shaping eval strategy during early model development through launch execution. You&#39;ll be the critical bridge between Research, Product, Marketing, and Engineering teams.&lt;/p&gt;\n&lt;p&gt;This role sits at the intersection of frontier AI research and product launches. Evals are an important part of how we measure whether our models meet the bar—for capability, safety, and competitive positioning. Beyond launch coordination, you&#39;ll help scale our evals ecosystem: from early-stage model evals for RL environments, to the systems and infrastructure on which evals run, to tooling that enables the whole pipeline. A strong TPM in this space can immediately reduce chaos during launches while also driving systemic improvements that compound over time.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Key Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;Launch Coordination&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Standardize how evaluation results are generated, documented, compared across model versions, and communicated to stakeholders&lt;/li&gt;\n&lt;li&gt;Own end-to-end eval readiness for model launches—tracking which evals are ready, which need scores on past models, and which meet the bar for marketing materials&lt;/li&gt;\n&lt;li&gt;Establish and enforce clear criteria for eval inclusion: scores on historical models, state-of-the-art performance, and competitor comparisons&lt;/li&gt;\n&lt;li&gt;Coordinate between research teams, marketing, and product to consolidate eval status into a single source of truth&lt;/li&gt;\n&lt;li&gt;Maintain a high bar: ensure reported statistics reflect model capabilities in an honest, accurate, and transparent way&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Ecosystem Development&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Get involved early in model development cycles, helping shape eval plans for RL environments&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Partner with research and infrastructure teams to improve underlying evals infrastructure—eval-syncer reliability, results storage and querying, automation capabilities&lt;/li&gt;\n&lt;li&gt;Drive prioritization of eval tooling enhancements based on researcher needs&lt;/li&gt;\n&lt;li&gt;Identify patterns across launches and drive systemic fixes rather than point solutions&lt;/li&gt;\n&lt;li&gt;Work with PMs and researchers to improve and implement high priority evals launches&lt;/li&gt;\n&lt;li&gt;Maintain and prioritize the eval roadmap—working with cross-functional teams to identify which new evals are needed for upcoming launches and product requirements&lt;/li&gt;\n&lt;li&gt;Implement an operating model that reflects an evals environment with increasing complexity&amp;nbsp;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 class=&quot;heading&quot;&gt;&lt;strong&gt;Process &amp;amp; Systems&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Build lightweight but rigorous tracking systems—moving key information into structured formats that enable better decision-making&lt;/li&gt;\n&lt;li&gt;Create eval dashboards that provide real-time visibility into training progress on hero evals, enabling earlier intervention when scores look concerning&lt;/li&gt;\n&lt;li&gt;Document eval processes, requirements, and lessons learned to build institutional knowledge&lt;/li&gt;\n&lt;li&gt;Coordinate compute allocation for large-scale evals with infrastructure teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You May Be a Good Fit If You:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5+ years of technical program management experience with a track record of bringing order to chaotic, high-stakes coordination problems&lt;/li&gt;\n&lt;li&gt;Possess scientific depth and a very high quality bar for data&lt;/li&gt;\n&lt;li&gt;Have experience with ML/AI evaluation methodologies, benchmarking, or research quality assurance&lt;/li&gt;\n&lt;li&gt;Have a background in research operations, scientific publishing, or data quality management&lt;/li&gt;\n&lt;li&gt;Have previous experience as data analyst, data scientist, or software engineer&lt;/li&gt;\n&lt;li&gt;Can build trust with research teams by understanding their work deeply enough to add value beyond coordination&lt;/li&gt;\n&lt;li&gt;Are skilled at cross-functional coordination involving research, product, marketing, and engineering—navigating competing priorities and driving alignment&lt;/li&gt;\n&lt;li&gt;Have working familiarity with data analysis tools (SQL, Python, or similar) for querying eval results and building dashboards&lt;/li&gt;\n&lt;li&gt;Have familiarity with LLM capabilities and limitations and experience working with AI research teams&lt;/li&gt;\n&lt;li&gt;Excel at written and verbal communication, translating technical nuance for marketing stakeholders while maintaining precision&lt;/li&gt;\n&lt;li&gt;Thrive in unstructured environments with a bias toward action and a knack for creating clarity in ambiguous situations&lt;/li&gt;\n&lt;li&gt;Have extremely high ownership and attention to detail&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None, applications will be received on a rolling basis.&lt;/p&gt;\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5018714008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Safeguards",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4960417008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a Technical Program Manager for Safeguards focused on model launches, you'll be the critical bridge between Research, Inference, Product, and Safety teams during our highest-stakes model and product releases. You'll drive end-to-end execution of Safeguards deployment for model and product launches, ensuring our safety classifiers are properly configured, deployed, tested, and scaled across all platforms while balancing capacity constraints, performance requirements, and user experience considerations. Responsibilities: Own end-to-end safeguards readiness for model launches - Drive all safeguards deployment activities from pre-launch planning through post-launch stabilization, ensuring classifier systems are properly configured, tested, and scaled for each new model release Coordinate complex cross-platform deployments - Manage classifier rollouts across platforms, each with distinct infrastructure constraints, capacity requirements, and deployment timelines Make real-time technical trade-off decisions - Balance competing constraints around classifier capacity, latency impacts, false positive rates, and robustness requirements during fast-moving launch cycles with aggressive timelines Drive capacity planning and performance optimization - Partner with Inference teams to model compute requirements, optimize classifier configurations (batch sizes, mesh topologies, chip allocation), and ensure we stay within overhead budgets while meeting safety requirements Lead launch day war room coordination - Serve as primary safeguards point of contact during launches, coordinating monitoring, troubleshooting classifier issues, and driving go/no-go calls on deployment decisions Build detailed execution plans and run-of-show - Create comprehensive launch checklists covering classifier configurations, monitoring thresholds, alerting setup, rollback procedures, and cross-team dependencies Partner with product teams on co-launch coordination - Ensure new product surfaces have appropriate safeguards protections configured, tested, and deployed; whether launching independently or alongside new models Monitor and respond to false positive patterns - Track flag rates across customer segments, identify problematic patterns, coordinate with research teams on classifier retraining priorities, and manage exemption processes for enterprise customers Manage transition to business-as-usual operations - Once launches stabilize, coordinate handoff of ongoing monitoring and optimization work to sustaining engineering teams, then move to the next model or product launch as needed Maintain technical documentation - Document classifier deployment configurations, capacity estimates, performance benchmarks, and lessons learned to build institutional knowledge You may be a good fit if you: Have deep technical program management experience in ML/AI systems - Several years coordinating complex deployments involving model inference, distributed systems, and real-time production services at scale Have experience with AI safety or Trust & Safety - Familiar with concepts like false positive/false negative trade-offs, adversarial robustness, content moderation systems, or similar safety-critical technical systems Can navigate high-ambiguity technical challenges - Synthesize incomplete information from multiple engineering teams, identify critical path blockers, and drive decisions when faced with competing technical constraints and tight deadlines Excel at rapid decision-making under pressure - Comfortable making high-stakes trade-off decisions with incomplete information during time-critical launch windows, balancing safety requirements against capacity, latency, and user experience constraints Are skilled at cross-functional coordination in complex technical environments - Proven track record managing programs spanning research, infrastructure, safety, security, and product teams, navigating competing priorities and driving alignment Can communicate technical concepts clearly across varying levels of seniority - Equally comfortable explaining classifier handoff latency to product managers, debating capacity trade-offs with infrastructure teams, and briefing executives on launch readiness Are comfortable with on-call and launch coverage - Willing to provide real-time support during launch windows (including early morning/late evening as needed) and maintain availability for time-sensitive decisions Deadline to apply: None. Applications will be reviewed on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-safeguards-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4960417008",
    "title": "Technical Program Manager, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4960417008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;As a Technical Program Manager for Safeguards focused on model launches, you&#39;ll be the critical bridge between Research, Inference, Product, and Safety teams during our highest-stakes model and product releases. You&#39;ll drive end-to-end execution of Safeguards deployment for model and product launches, ensuring our safety classifiers are properly configured, deployed, tested, and scaled across all platforms while balancing capacity constraints, performance requirements, and user experience considerations.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Own end-to-end safeguards readiness for model launches - Drive all safeguards deployment activities from pre-launch planning through post-launch stabilization, ensuring classifier systems are properly configured, tested, and scaled for each new model release&lt;/li&gt;\n&lt;li&gt;Coordinate complex cross-platform deployments - Manage classifier rollouts across platforms, each with distinct infrastructure constraints, capacity requirements, and deployment timelines&lt;/li&gt;\n&lt;li&gt;Make real-time technical trade-off decisions - Balance competing constraints around classifier capacity, latency impacts, false positive rates, and robustness requirements during fast-moving launch cycles with aggressive timelines&lt;/li&gt;\n&lt;li&gt;Drive capacity planning and performance optimization - Partner with Inference teams to model compute requirements, optimize classifier configurations (batch sizes, mesh topologies, chip allocation), and ensure we stay within overhead budgets while meeting safety requirements&lt;/li&gt;\n&lt;li&gt;Lead launch day war room coordination - Serve as primary safeguards point of contact during launches, coordinating monitoring, troubleshooting classifier issues, and driving go/no-go calls on deployment decisions&lt;/li&gt;\n&lt;li&gt;Build detailed execution plans and run-of-show - Create comprehensive launch checklists covering classifier configurations, monitoring thresholds, alerting setup, rollback procedures, and cross-team dependencies&lt;/li&gt;\n&lt;li&gt;Partner with product teams on co-launch coordination - Ensure new product surfaces have appropriate safeguards protections configured, tested, and deployed; whether launching independently or alongside new models&lt;/li&gt;\n&lt;li&gt;Monitor and respond to false positive patterns - Track flag rates across customer segments, identify problematic patterns, coordinate with research teams on classifier retraining priorities, and manage exemption processes for enterprise customers&lt;/li&gt;\n&lt;li&gt;Manage transition to business-as-usual operations - Once launches stabilize, coordinate handoff of ongoing monitoring and optimization work to sustaining engineering teams, then move to the next model or product launch as needed&lt;/li&gt;\n&lt;li&gt;Maintain technical documentation - Document classifier deployment configurations, capacity estimates, performance benchmarks, and lessons learned to build institutional knowledge&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have deep technical program management experience in ML/AI systems - Several years coordinating complex deployments involving model inference, distributed systems, and real-time production services at scale&lt;/li&gt;\n&lt;li&gt;Have experience with AI safety or Trust &amp;amp; Safety - Familiar with concepts like false positive/false negative trade-offs, adversarial robustness, content moderation systems, or similar safety-critical technical systems&lt;/li&gt;\n&lt;li&gt;Can navigate high-ambiguity technical challenges - Synthesize incomplete information from multiple engineering teams, identify critical path blockers, and drive decisions when faced with competing technical constraints and tight deadlines&lt;/li&gt;\n&lt;li&gt;Excel at rapid decision-making under pressure - Comfortable making high-stakes trade-off decisions with incomplete information during time-critical launch windows, balancing safety requirements against capacity, latency, and user experience constraints&lt;/li&gt;\n&lt;li&gt;Are skilled at cross-functional coordination in complex technical environments - Proven track record managing programs spanning research, infrastructure, safety, security, and product teams, navigating competing priorities and driving alignment&lt;/li&gt;\n&lt;li&gt;Can communicate technical concepts clearly across varying levels of seniority - Equally comfortable explaining classifier handoff latency to product managers, debating capacity trade-offs with infrastructure teams, and briefing executives on launch readiness&lt;/li&gt;\n&lt;li&gt;Are comfortable with on-call and launch coverage - Willing to provide real-time support during launch windows (including early morning/late evening as needed) and maintain availability for time-sensitive decisions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&amp;nbsp;&lt;/strong&gt;None. Applications will be reviewed on a rolling basis.&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4960417008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Security",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4989788008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Role As a Technical Program Manager for Security, you'll drive execution of high-stakes programs that span security engineering, infrastructure, and cross-functional teams across Anthropic. You'll be responsible for the strategy, planning, and execution of technical security programs that enable Anthropic to meet its Responsible Scaling Policy (RSP) commitments while building towards a security posture that scales with our rapid growth. This role sits at the intersection of Security Engineering, Security Compliance, Infrastructure, Product, Research, Policy, and more. This role demands someone who thrives in ambiguity, makes well-reasoned decisions under pressure, and can translate complex security requirements into executable programs with compressed timelines. Responsibilities: Own end-to-end security program execution for RSP security readiness– Drive security workstreams from requirements interpretation through implementation, coordinating across Security Engineering, Infrastructure, Research, and Compliance teams to ensure we meet RSP commitments on aggressive timelines Lead infrastructure security programs – Manage programs like cluster hardening, service boundary enforcement, and security observability that protect our most sensitive assets including model weights and training infrastructure Coordinate complex multi-team deployments – Manage security control rollouts and migrations, like endpoint hardening and egress reduction that require careful change management across engineering organizations Make real-time technical trade-off decisions – Balance competing constraints between security controls, research velocity, and operational feasibility during fast-moving program cycles Build program structure for emerging security domains – Create program charters, establish roles and timelines, develop communication strategies, and define success metrics for nascent security initiatives Partner with third-party partners – Manage security aspects of infrastructure partnerships, including contract requirements, relationship management, and security assurance processes Lead stakeholder communication and executive reporting – Prepare regular status updates, deliver company-wide communications, lead program reviews, and ensure leadership has visibility into critical security milestones, blockers, and risks You may be a good fit if you: Have experience driving cross-functional projects, building longer-running programs, and interfacing with technical and non-technical stakeholders. Have experience executing technical programs that require systems and engineering-level knowledge. Have a deep interest in and/or a willingness to learn about cybersecurity or regulatory compliance. Have experience leveraging LLMs to automate workflows, improve operational efficiency, and develop novel solutions for complex technical and organizational challenges. Have experience reporting on complex programs through data-driven benchmarks, including writing SQL queries. Have strong interpersonal skills that enable you to influence without authority, build cross-organizational support, cooperation and action around security initiatives, policies and procedures. Have a track record for being able to successfully organize, implement and manage complex programs and projects. Are used to working through trade-offs, balancing competing priorities, and having your mind changed. Deadline to apply: None, applications will be received on a rolling basis. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$290,000 - $365,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-security-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4989788008",
    "title": "Technical Program Manager, Security",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4989788008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;\n&lt;h2&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;As a Technical Program Manager for Security, you&#39;ll drive execution of high-stakes programs that span security engineering, infrastructure, and cross-functional teams across Anthropic. You&#39;ll be responsible for the strategy, planning, and execution of technical security programs that enable Anthropic to meet its &lt;a href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot;&gt;Responsible Scaling Policy&lt;/a&gt; (RSP) commitments while building towards a security posture that scales with our rapid growth.&lt;/p&gt;\n&lt;p&gt;This role sits at the intersection of Security Engineering, Security Compliance, Infrastructure, Product, Research, Policy, and more. This role demands someone who thrives in ambiguity, makes well-reasoned decisions under pressure, and can translate complex security requirements into executable programs with compressed timelines.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Own end-to-end security program execution for RSP security readiness&lt;/strong&gt;– Drive security workstreams from requirements interpretation through implementation, coordinating across Security Engineering, Infrastructure, Research, and Compliance teams to ensure we meet RSP commitments on aggressive timelines&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Lead infrastructure security programs&amp;nbsp;&lt;/strong&gt;– Manage programs like cluster hardening, service boundary enforcement, and security observability that protect our most sensitive assets including model weights and training infrastructure&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Coordinate complex multi-team deployments &lt;/strong&gt;– Manage security control rollouts and migrations, like endpoint hardening and egress reduction that require careful change management across engineering organizations&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Make real-time technical trade-off decisions &lt;/strong&gt;– Balance competing constraints between security controls, research velocity, and operational feasibility during fast-moving program cycles&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Build program structure for emerging security domains &lt;/strong&gt;– Create program charters, establish roles and timelines, develop communication strategies, and define success metrics for nascent security initiatives&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Partner with third-party partners &lt;/strong&gt;– Manage security aspects of infrastructure partnerships, including contract requirements, relationship management, and security assurance processes&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Lead stakeholder communication and executive reporting &lt;/strong&gt;– Prepare regular status updates, deliver company-wide communications, lead program reviews, and ensure leadership has visibility into critical security milestones, blockers, and risks&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&amp;nbsp;&lt;strong&gt;You may be a good fit if you: &lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have experience driving cross-functional projects, building longer-running programs, and interfacing with technical and non-technical stakeholders.&lt;/li&gt;\n&lt;li&gt;Have experience executing technical programs that require systems and engineering-level knowledge.&lt;/li&gt;\n&lt;li&gt;Have a deep interest in and/or a willingness to learn about cybersecurity or regulatory compliance.&lt;/li&gt;\n&lt;li&gt;Have experience leveraging LLMs to automate workflows, improve operational efficiency, and develop novel solutions for complex technical and organizational challenges.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Have experience reporting on complex programs through data-driven benchmarks, including writing SQL queries.&lt;/li&gt;\n&lt;li&gt;Have strong interpersonal skills that enable you to influence without authority, build cross-organizational support, cooperation and action around security initiatives, policies and procedures.&lt;/li&gt;\n&lt;li&gt;Have a track record for being able to successfully organize, implement and manage complex programs and projects.&lt;/li&gt;\n&lt;li&gt;Are used to working through trade-offs, balancing competing priorities, and having your mind changed.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None, applications will be received on a rolling basis.&lt;/p&gt;\n&lt;/div&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$290,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$365,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4989788008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Recruiter, Specialized",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4935314008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: Anthropic is looking for a talented Technical Recruiter to partner with our Core Tech teams. In this pivotal role, you will be instrumental in shaping the future of our organization by identifying, engaging, and hiring the best and brightest minds across a range of disciplines. As we continue to push the boundaries of AI research and development, we need a passionate recruiter who can help us build a world-class team dedicated to creating safe and beneficial AI systems. Responsibilities: Develop and execute strategic recruiting plans to identify, source, and hire highly qualified candidates, with a focus on Machine Learning and AI talent Partner with hiring managers and interviewers to understand hiring needs, team matching, required skills and qualifications Enhance and implement recruiting processes and programs while maintaining an inclusive and high talent bar, such as developing targeted outreach campaigns, building connections with industry leaders, and removing any unfair biases from the hiring process Collaborate with leadership and cross-functional partners to understand organizational needs and map out long-term talent acquisition strategies that balance priorities across all technical teams Enhance Anthropic's employer brand within the research and science community to showcase our mission, culture, and values to candidates Stay up-to-date on recruiting best practices, emerging sourcing techniques, interview innovations, and workplace trends You may be a good fit if you: Have 5+ years of experience in full life cycle recruiting supporting core technical teams Have a passion for AI's potential to positively impact the world and realistic assessment of its risks and limitations Are experimental and are open to new, creative recruiting ideas, or have experience working with hiring managers who are open to non-traditional talent strategies Thrive in fast-paced, dynamic environments and enjoy juggling multiple priorities Possess strong technical aptitude with the ability to understand and evaluate technical qualifications Have enthusiasm for deeply understanding the needs of engineers and innovating on recruiting processes to make them more tailored to the world of AI Have excellent organizational skills and attention to detail, as well as a proactive mindset and ability to operate with autonomy Have experience partnering with engineers and hiring talent that work on GenAI and LLMs Have a proven track record of scaling and building diverse and high-performing teams in a fast-paced, high-growth startup environment Strong candidates may also: Bring a deep interest in AI safety Have experience partnering with engineers and hiring talent that work on GenAI and LLMs Have experience with academic recruitment and research communities The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$175,000 - $295,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-recruiter-specialized-san-francisco-ca-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4935314008",
    "title": "Technical Recruiter, Specialized",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | Seattle, WA",
    "locations": [
      "San Francisco, CA | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4935314008",
    "departments": [
      "People"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is looking for a talented Technical Recruiter to partner with our Core Tech teams. In this pivotal role, you will be instrumental in shaping the future of our organization by identifying, engaging, and hiring the best and brightest minds across a range of disciplines. As we continue to push the boundaries of AI research and development, we need a passionate recruiter who can help us build a world-class team dedicated to creating safe and beneficial AI systems.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and execute strategic recruiting plans to identify, source, and hire highly qualified candidates, with a focus on Machine Learning and AI talent&lt;/li&gt;\n&lt;li&gt;Partner with hiring managers and interviewers to understand hiring needs, team matching, required skills and qualifications&lt;/li&gt;\n&lt;li&gt;Enhance and implement recruiting processes and programs while maintaining an inclusive and high talent bar, such as developing targeted outreach campaigns, building connections with industry leaders, and removing any unfair biases from the hiring process&lt;/li&gt;\n&lt;li&gt;Collaborate with leadership and cross-functional partners to understand organizational needs and map out long-term talent acquisition strategies that balance priorities across all technical teams&lt;/li&gt;\n&lt;li&gt;Enhance Anthropic&#39;s employer brand within the research and science community to showcase our mission, culture, and values to candidates&lt;/li&gt;\n&lt;li&gt;Stay up-to-date on recruiting best practices, emerging sourcing techniques, interview innovations, and workplace trends&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5+ years of experience in full life cycle recruiting supporting core technical teams&lt;/li&gt;\n&lt;li&gt;Have a passion for AI&#39;s potential to positively impact the world and realistic assessment of its risks and limitations&lt;/li&gt;\n&lt;li&gt;Are experimental and are open to new, creative recruiting ideas, or have experience working with hiring managers who are open to non-traditional talent strategies&lt;/li&gt;\n&lt;li&gt;Thrive in fast-paced, dynamic environments and enjoy juggling multiple priorities&lt;/li&gt;\n&lt;li&gt;Possess strong technical aptitude with the ability to understand and evaluate technical qualifications&lt;/li&gt;\n&lt;li&gt;Have enthusiasm for deeply understanding the needs of engineers and innovating on recruiting processes to make them more tailored to the world of AI&lt;/li&gt;\n&lt;li&gt;Have excellent organizational skills and attention to detail, as well as a proactive mindset and ability to operate with autonomy&lt;/li&gt;\n&lt;li&gt;Have experience partnering with engineers and hiring talent that work on GenAI and LLMs&lt;/li&gt;\n&lt;li&gt;Have a proven track record of scaling and building diverse and high-performing teams in a fast-paced, high-growth startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Bring a deep interest in AI safety&lt;/li&gt;\n&lt;li&gt;Have experience partnering with engineers and hiring talent that work on GenAI and LLMs&lt;/li&gt;\n&lt;li&gt;Have experience with academic recruitment and research communities&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$175,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$295,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4935314008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Technical Revenue Accountant",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4990162008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role We are looking for a Technical Revenue Accounting professional to join our Accounting Team. In this role, you will execute complex ASC 606 technical evaluations, draft comprehensive revenue accounting memos, and provide strategic accounting guidance on new product revenue recognition treatments and go-to-market initiatives. You will work cross-functionally across the organization and solve complex problems on a regular basis! If you are looking for an opportunity to make a significant impact on the financial infrastructure of an innovative company, come join us in our mission to build cutting-edge, safe AI. Responsibilities: Author detailed ASC 606 technical accounting memos analyzing complex revenue recognition scenarios and providing accounting conclusions Evaluate and establish revenue recognition treatment for new product offerings, including performance obligation identification, SSP evaluation, and contract modification assessments Advise business stakeholders on revenue accounting implications of new go-to-market strategies, pricing models, and unique commercial arrangements Review revenue contracts and prepare technical accounting documentation, including ASC 606 checklists and position papers to ensure revenue recognition compliance Lead technical research initiatives on emerging revenue recognition issues and present authoritative findings to senior management Develop and maintain comprehensive revenue recognition policies, procedures, and technical guidance documentation Translate complex technical accounting requirements into actionable business guidance for non-accounting stakeholders Prepare for revenue-related month end close activities and flux analysis Build and maintain relationships with cross-functional stakeholders to drive effective collaboration Participate in and contribute to process improvement and system implementation projects You may be a good fit if you: Have 10+ years of progressive accounting experience, with extensive expertise in ASC 606 implementation and complex revenue recognition scenarios Have demonstrated experience drafting technical accounting memos, position papers, and revenue recognition assessments Have strong knowledge of ASC 606 with experience in performance obligation analysis, contract modification accounting, and variable consideration treatment Ability to articulate complex accounting positions clearly, and proactively conduct technical accounting research to identify emerging revenue recognition challenges Have hands-on experience with revenue recognition tools (e.g., NetSuite ARM, Oracle Fusion, Workday Financial Management, Zuora RevPro) Have proven project management skills with ability to drive results Have a demonstrated ability to thrive in fast-paced, ambiguous environments Strong candidates may have: A Bachelor's degree in Accounting or Finance; CPA preferred with demonstrated technical accounting expertise Experience with technical accounting advisory work, including revenue recognition consulting or implementation experience Experience working with consumption-based and subscription-based revenue models Knowledge of AI/ML, SaaS and technology sector revenue recognition complexities The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$190,000 - $230,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-revenue-accountant-san-francisco-ca-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4990162008",
    "title": "Technical Revenue Accountant",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4990162008",
    "departments": [
      "Finance"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for a Technical Revenue Accounting professional to join our Accounting Team. In this role, you will execute complex ASC 606 technical evaluations, draft comprehensive revenue accounting memos, and provide strategic accounting guidance on new product revenue recognition treatments and go-to-market initiatives. You will work cross-functionally across the organization and solve complex problems on a regular basis! If you are looking for an opportunity to make a significant impact on the financial infrastructure of an innovative company, come join us in our mission to build cutting-edge, safe AI.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Author detailed ASC 606 technical accounting memos analyzing complex revenue recognition scenarios and providing accounting conclusions&lt;/li&gt;\n&lt;li&gt;Evaluate and establish revenue recognition treatment for new product offerings, including performance obligation identification, SSP evaluation, and contract modification assessments&lt;/li&gt;\n&lt;li&gt;Advise business stakeholders on revenue accounting implications of new go-to-market strategies, pricing models, and unique commercial arrangements&lt;/li&gt;\n&lt;li&gt;Review revenue contracts and prepare technical accounting documentation, including ASC 606 checklists and position papers to ensure revenue recognition compliance&lt;/li&gt;\n&lt;li&gt;Lead technical research initiatives on emerging revenue recognition issues and present authoritative findings to senior management&lt;/li&gt;\n&lt;li&gt;Develop and maintain comprehensive revenue recognition policies, procedures, and technical guidance documentation&lt;/li&gt;\n&lt;li&gt;Translate complex technical accounting requirements into actionable business guidance for non-accounting stakeholders&lt;/li&gt;\n&lt;li&gt;Prepare for revenue-related month end close activities and flux analysis&lt;/li&gt;\n&lt;li&gt;Build and maintain relationships with cross-functional stakeholders to drive effective collaboration&lt;/li&gt;\n&lt;li&gt;Participate in and contribute to process improvement and system implementation projects&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 10+ years of progressive accounting experience, with extensive expertise in ASC 606 implementation and complex revenue recognition scenarios&lt;/li&gt;\n&lt;li&gt;Have demonstrated experience drafting technical accounting memos, position papers, and revenue recognition assessments&lt;/li&gt;\n&lt;li&gt;Have strong knowledge of ASC 606 with experience in performance obligation analysis, contract modification accounting, and variable consideration treatment&lt;/li&gt;\n&lt;li&gt;Ability to articulate complex accounting positions clearly, and proactively conduct technical accounting research to identify emerging revenue recognition challenges&lt;/li&gt;\n&lt;li&gt;Have hands-on experience with revenue recognition tools (e.g., NetSuite ARM, Oracle Fusion, Workday Financial Management, Zuora RevPro)&lt;/li&gt;\n&lt;li&gt;Have proven project management skills with ability to drive results&lt;/li&gt;\n&lt;li&gt;Have a demonstrated ability to thrive in fast-paced, ambiguous environments&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;A Bachelor&#39;s degree in Accounting or Finance; CPA preferred with demonstrated technical accounting expertise&lt;/li&gt;\n&lt;li&gt;Experience with technical accounting advisory work, including revenue recognition consulting or implementation experience&lt;/li&gt;\n&lt;li&gt;Experience working with consumption-based and subscription-based revenue models&lt;/li&gt;\n&lt;li&gt;Knowledge of AI/ML, SaaS and technology sector revenue recognition complexities&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$190,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$230,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4990162008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]