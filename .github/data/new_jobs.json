[
  {
    "job_title": "",
    "employer_name": "AgZen",
    "job_city": "Cambridge",
    "job_state": "MA",
    "job_description": ".fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-mobile-site-gutter, 6vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (8 - 1)) ) / 8 ); display: grid; position: relative; grid-area: 1/1/-1/-1; grid-template-rows: repeat(12,minmax(24px, auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(8, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); row-gap: 11.0px; column-gap: 11.0px; overflow-x: hidden; overflow-x: clip; } @media (min-width: 768px) { .background-width--inset .fe-681e70c2a649507003c3aab5 { --inset-padding: calc(var(--sqs-site-gutter) * 2); } .fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-site-gutter, 4vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (24 - 1)) ) / 24 ); --inset-padding: 0vw; --row-height-scaling-factor: 0.0215; --container-width: min(var(--sqs-site-max-width, 1500px), calc(100vw - var(--sqs-site-gutter, 4vw) * 2 - var(--inset-padding) )); grid-template-rows: repeat(13,minmax(calc(var(--container-width) * var(--row-height-scaling-factor)), auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(24, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); } } .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/7/10; z-index: 1; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/2/26; z-index: 2; position: sticky; top: calc(0px + var(--header-fixed-top-offset, 0px)); } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } } .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 7/2/13/10; z-index: 2; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 2/2/7/26; z-index: 1; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } }",
    "job_apply_link": "https://www.agzen.com/jobs?gh_jid=4048593009",
    "job_posted_at_datetime_utc": "2025-10-21T00:25:19.000Z",
    "job_employment_type": "FULLTIME",
    "job_posted_at": "1h",
    "id": "agzen--cambridge",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Recruiter, Sales & GTM",
    "employer_name": "airtable",
    "job_city": "San Francisco, CA; Remote - US",
    "job_apply_link": "https://job-boards.greenhouse.io/airtable/jobs/8369363002",
    "job_posted_at_datetime_utc": "2026-01-14T15:44:48-05:00",
    "job_description": "Airtable is the no-code app platform that empowers people closest to the work to accelerate their most critical business processes. More than 500,000 organizations, including 80% of the Fortune 100, rely on Airtable to transform how work gets done.Building a remarkable team is one of our top priorities as we continue to scale, and weâ€™re looking for a Senior Recruiter to help drive hiring across our Sales and broader Go-to-Market (GTM) teams. As we continue to grow, youâ€™ll be responsible for hiring top sales talent and partnering closely with business leaders to proactively address hiring needs. This is a high-impact opportunity to shape the future of our sales organization, work in a fast-paced environment, and make a direct contribution to Airtableâ€™s growth trajectory. What you'll do Own full-cycle recruiting for all revenue-generating roles, with a focus on Strategic Account Executives and other high-impact sales positions Partner with sales and business leaders to forecast hiring needs, proactively address attrition risks, and ensure we maintain 100% capacity across Strategic AE roles Source, screen, and manage a high-volume pipeline of candidates in a fast-moving environment, balancing multiple open requisitions and a steady cadence of screens Drive strong offer acceptance rates through deep market knowledge, compelling candidate engagement, and exceptional closing skills Provide consistent reporting with accurate, up-to-date pipeline data and clear communication of progress and blockers to cross-functional stakeholders Deliver a positive, high-touch experience for candidates and stakeholders, maintaining strong communication and urgency throughout the process Who you are 6+ years of sales or GTM recruiting experience, with at least 3 years focused on revenue-generating roles Proven success recruiting for enterprise or strategic sales roles, ideally in a high-growth SaaS or tech company Deep understanding of the AE/Sales market and the ability to assess sales talent effectively Experience managing multiple competing priorities and high-volume sourcing in competitive, niche talent markets Comfortable managing a high volume of requisitions and screens simultaneously while maintaining quality and attention to detail Strong reporting skills with the ability to communicate progress, metrics, and challenges to cross-functional stakeholders Familiarity with sales methodologies such as MEDDIC, Challenger, Force Management, or similar frameworks Excellent candidate engagement and closing skills, with a track record of high offer acceptance rates Agency experience or experience as a first/only recruiter is a plus You operate with urgency, adaptability, and a partnership mindset. You genuinely enjoy this type of work and want to build a career in Sales recruiting Airtable is an equal opportunity employer. We embrace diversity and strive to create a workplace where everyone has an equal opportunity to thrive. We welcome people of different backgrounds, experiences, abilities, and perspectives. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any characteristic protected by applicable federal and state laws, regulations and ordinances. Learn more about your EEO rights as an applicant. VEVRAA-Federal Contractor If you have a medical condition, disability, or religious belief/practice which inhibits your ability to participate in any part of the application or interview process, please complete our Accommodations Request Form and let us know how we may assist you. Airtable is committed to participating in the interactive process and providing reasonable accommodations to qualified applicants. #LI-remote Compensation awarded to successful candidates will vary based on their work location, relevant skills, and experience. Our total compensation package also includes the opportunity to receive benefits, restricted stock units, and may include incentive compensation. To learn more about our comprehensive benefit offerings, please check out Life at Airtable.For work locations in the San Francisco Bay Area, Seattle, New York City, and Los Angeles, the base salary range for this role is:$164,000 - $213,700 USDFor all other work locations (including remote), the base salary range for this role is:$148,000 - $192,600 USDPlease see our Privacy Notice for details regarding Airtableâ€™s collection and use of personal information relating to the application and recruitment process by clicking here. ðŸ”’ Stay Safe from Job ScamsAll official Airtable communication will come from an @airtable.com email address. We will never ask you to share sensitive information or purchase equipment during the hiring process. If in doubt, contact us at hr@airtable.com. Learn more about avoiding job scams here.",
    "id": "airtable-recruiter-sales-gtm-san-francisco-ca-remote-us",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "8369363002",
    "title": "Recruiter, Sales & GTM",
    "company_name": "airtable",
    "company_slug": "airtable",
    "location": "San Francisco, CA; Remote - US",
    "locations": [
      "San Francisco, CA; Remote - US"
    ],
    "url": "https://job-boards.greenhouse.io/airtable/jobs/8369363002",
    "departments": [
      "Recruiting"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T15:44:48-05:00",
    "fetched_at": "2026-01-17T04:05:19.329Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;p&gt;Airtable is the no-code app platform that empowers people closest to the work to accelerate their most critical business processes. More than 500,000 organizations, including 80% of the Fortune 100, rely on Airtable to transform how work gets done.&lt;/p&gt;&lt;/div&gt;&lt;p&gt;Building a remarkable team is one of our top priorities as we continue to scale, and weâ€™re looking for a Senior Recruiter to help drive hiring across our Sales and broader Go-to-Market (GTM) teams. As we continue to grow, youâ€™ll be responsible for hiring top sales talent and partnering closely with business leaders to proactively address hiring needs. This is a high-impact opportunity to shape the future of our sales organization, work in a fast-paced environment, and make a direct contribution to Airtableâ€™s growth trajectory.&lt;/p&gt;\n&lt;h1&gt;&lt;strong&gt;What you&#39;ll do&lt;/strong&gt;&lt;/h1&gt;\n&lt;ul&gt;\n&lt;li&gt;Own full-cycle recruiting for all revenue-generating roles, with a focus on Strategic Account Executives and other high-impact sales positions&lt;/li&gt;\n&lt;li&gt;Partner with sales and business leaders to forecast hiring needs, proactively address attrition risks, and ensure we maintain 100% capacity across Strategic AE roles&lt;/li&gt;\n&lt;li&gt;Source, screen, and manage a high-volume pipeline of candidates in a fast-moving environment, balancing multiple open requisitions and a steady cadence of screens&lt;/li&gt;\n&lt;li&gt;Drive strong offer acceptance rates through deep market knowledge, compelling candidate engagement, and exceptional closing skills&lt;/li&gt;\n&lt;li&gt;Provide consistent reporting with accurate, up-to-date pipeline data and clear communication of progress and blockers to cross-functional stakeholders&lt;/li&gt;\n&lt;li&gt;Deliver a positive, high-touch experience for candidates and stakeholders, maintaining strong communication and urgency throughout the process&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h1&gt;&lt;strong&gt;Who you are&lt;/strong&gt;&lt;/h1&gt;\n&lt;ul&gt;\n&lt;li&gt;6+ years of sales or GTM recruiting experience, with at least 3 years focused on revenue-generating roles&lt;/li&gt;\n&lt;li&gt;Proven success recruiting for enterprise or strategic sales roles, ideally in a high-growth SaaS or tech company&lt;/li&gt;\n&lt;li&gt;Deep understanding of the AE/Sales market and the ability to assess sales talent effectively&lt;/li&gt;\n&lt;li&gt;Experience managing multiple competing priorities and high-volume sourcing in competitive, niche talent markets&lt;/li&gt;\n&lt;li&gt;Comfortable managing a high volume of requisitions and screens simultaneously while maintaining quality and attention to detail&lt;/li&gt;\n&lt;li&gt;Strong reporting skills with the ability to communicate progress, metrics, and challenges to cross-functional stakeholders&lt;/li&gt;\n&lt;li&gt;Familiarity with sales methodologies such as MEDDIC, Challenger, Force Management, or similar frameworks&lt;/li&gt;\n&lt;li&gt;Excellent candidate engagement and closing skills, with a track record of high offer acceptance rates&lt;/li&gt;\n&lt;li&gt;Agency experience or experience as a first/only recruiter is a plus&lt;/li&gt;\n&lt;li&gt;You operate with urgency, adaptability, and a partnership mindset. You genuinely enjoy this type of work and want to build a career in Sales recruiting&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Airtable is an equal opportunity employer. We embrace diversity and strive to create a workplace where everyone has an equal opportunity to thrive. We welcome people of different backgrounds, experiences, abilities, and perspectives. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any characteristic protected by applicable federal and state laws, regulations and ordinances. Learn more about your &lt;/span&gt;&lt;a href=&quot;https://drive.google.com/file/d/1jAj2by1bto5g8Xqn9hWNAwPOMGNd_fM6/view?usp=sharing&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;EEO rights as an applicant&lt;/span&gt;&lt;/a&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;VEVRAA-Federal Contractor&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;If you have a medical condition, disability, or religious belief/practice which inhibits your ability to participate in any part of the application or interview process, please complete our &lt;/span&gt;&lt;a href=&quot;https://airtable.com/shrq13fCV8h1sx2t8&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Accommodations Request Form&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;and let us know how we may assist you. Airtable is committed to participating in the interactive process and providing reasonable accommodations to qualified applicants.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400; font-size: 8pt; color: rgb(255, 255, 255);&quot;&gt;#LI-remote&lt;/span&gt;&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;hr&gt;\n&lt;p&gt;Compensation awarded to successful candidates will vary based on their work location, relevant skills, and experience.&lt;/p&gt;\n&lt;p&gt;&lt;span data-slate-node=&quot;text&quot;&gt;&lt;span data-slate-leaf=&quot;true&quot;&gt;&lt;span data-slate-string=&quot;true&quot;&gt;Our total compensation package also includes the opportunity to receive benefits, restricted stock units, and may include incentive compensation.&lt;span class=&quot;Apple-converted-space&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span data-slate-node=&quot;text&quot;&gt;&lt;span data-slate-leaf=&quot;true&quot;&gt;&lt;span data-slate-string=&quot;true&quot;&gt;To learn more about our comprehensive benefit offerings, please check out&lt;span class=&quot;Apple-converted-space&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a class=&quot;slate-link selected&quot; href=&quot;https://airtable.com/careers/life-at-airtable&quot; data-slate-node=&quot;element&quot; data-slate-inline=&quot;true&quot;&gt;&lt;span data-slate-node=&quot;text&quot;&gt;&lt;span data-slate-leaf=&quot;true&quot;&gt;&lt;span data-slate-string=&quot;true&quot;&gt;Life at Airtable&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span data-slate-node=&quot;text&quot; data-slate-fragment=&quot;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&quot;&gt;&lt;span data-slate-leaf=&quot;true&quot;&gt;&lt;span data-slate-string=&quot;true&quot;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;For work locations in the San Francisco Bay Area, Seattle, New York City, and Los Angeles, the base salary range for this role is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$164,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$213,700 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;title&quot;&gt;For all other work locations (including remote), the base salary range for this role is:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$148,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$192,600 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;p&gt;Please see our Privacy Notice for details regarding Airtableâ€™s collection and use of personal information relating to the application and recruitment process by clicking&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.airtable.com/company/personnel-privacy-notice&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://drive.google.com/file/d/1fKEf0G59m8RT2ZaOJyxoqQ3kW3oUaxhZ/view&quot; data-sk=&quot;tooltip_parent&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;ðŸ”’ &lt;strong&gt;Stay Safe from Job Scams&lt;/strong&gt;&lt;br&gt;All official Airtable communication will come from an &lt;strong&gt;@airtable.com&lt;/strong&gt; email address. We will never ask you to share sensitive information or purchase equipment during the hiring process. If in doubt, contact us at &lt;a href=&quot;mailto:hr@airtable.com&quot;&gt;hr@airtable.com&lt;/a&gt;. Learn more about avoiding job scams &lt;a href=&quot;https://consumer.ftc.gov/consumer-alerts/2022/05/want-work-home-spot-scams-first&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 8369363002
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Biological Safety Research Scientist",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5066977008",
    "job_posted_at_datetime_utc": "2026-01-14T15:30:37-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems. About the Role We are looking for biological scientists to help build safety and oversight mechanisms for our AI systems. As a Safeguards Biological Safety Research Scientist, you will apply your technical skills to design and develop our safety systems which detect harmful behaviors and to prevent misuse by sophisticated threat actors. You will be at the forefront of defining what responsible AI safety looks like in the biological domain, working across research, policy, and engineering to translate complex biosecurity concepts into concrete technical safeguards. This is a unique opportunity to shape how frontier AI models handle dual-use biological knowledgeâ€”balancing the tremendous potential of AI to accelerate legitimate life sciences research while preventing misuse by sophisticated threat actors. In this role, you will: Design and execute capability evaluations (\"evals\") to assess the capabilities of new models Collaborate closely with internal and external threat modeling experts to develop training data for our safety systems, and with ML engineers to train these safety systems, optimizing for both robustness against adversarial attacks and low false-positive rates for legitimate researchers Analyze safety system performance in traffic, identifying gaps and proposing improvements Develop rigorous stress-testing of our safeguards against evolving threats and product surfaces Partner with Research, Product, and Policy teams to ensure biological safety is embedded throughout the model development lifecycle Contribute to external communications, including model cards, blog posts, and policy documents related to biological safety Monitor emerging technologies for their potential to contribute to new risks and new mitigation strategies, and strategically address these You may be a good fit if you have A PhD in molecular biology, virology, microbiology, biochemistry, systems or computational biology, or a related life sciences field, OR equivalent professional experience Extensive experience in scientific computing and data analysis, with proficiency in programming (Python preferred) Deep expertise in modern biology, including both \"reading\" (e.g. high-throughput measurement, functional assays) and \"writing\" (gene synthesis, genome editing, strain construction, protein engineering) techniques in biology Familiarity with dual-use research concerns, select agent regulations, and biosecurity frameworks (e.g., Biological Weapons Convention, Australia Group guidelines) Strong analytical and writing skills, with the ability to navigate ambiguity and explain complex technical concepts to non-technical stakeholders Have a passion for learning new skills and an ability to rapidly adapt to changing techniques and technologies Comfort working in a fast-paced environment where priorities may shift as AI capabilities evolve Preferred Qualifications Background in AI/ML systems, particularly experience with large language models Experience in developing ML for biological systems Extensive experience in complex projects with multiple stakeholders The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$300,000 - $320,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-biological-safety-research-scientist-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5066977008",
    "title": "Biological Safety Research Scientist",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5066977008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T15:30:37-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&amp;nbsp;&lt;/h2&gt;\n&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for biological scientists to help build safety and oversight mechanisms for our AI systems. As a Safeguards Biological Safety Research Scientist, you will apply your technical skills to design and develop our safety systems which detect harmful behaviors and to prevent misuse by sophisticated threat actors. You will be at the forefront of defining what responsible AI safety looks like in the biological domain, working across research, policy, and engineering to translate complex biosecurity concepts into concrete technical safeguards. This is a unique opportunity to shape how frontier AI models handle dual-use biological knowledgeâ€”balancing the tremendous potential of AI to accelerate legitimate life sciences research while preventing misuse by sophisticated threat actors.&lt;/p&gt;\n&lt;p&gt;In this role, you will:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and execute capability evaluations (&quot;evals&quot;) to assess the capabilities of new models&lt;/li&gt;\n&lt;li&gt;Collaborate closely with internal and external threat modeling experts to develop training data for our safety systems, and with ML engineers to train these safety systems, optimizing for both robustness against adversarial attacks and low false-positive rates for legitimate researchers&lt;/li&gt;\n&lt;li&gt;Analyze safety system performance in traffic, identifying gaps and proposing improvements&lt;/li&gt;\n&lt;li&gt;Develop rigorous stress-testing of our safeguards against evolving threats and product surfaces&lt;/li&gt;\n&lt;li&gt;Partner with Research, Product, and Policy teams to ensure biological safety is embedded throughout the model development lifecycle&lt;/li&gt;\n&lt;li&gt;Contribute to external communications, including model cards, blog posts, and policy documents related to biological safety&lt;/li&gt;\n&lt;li&gt;Monitor emerging technologies for their potential to contribute to new risks and new mitigation strategies, and strategically address these&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;A PhD in molecular biology, virology, microbiology, biochemistry, systems or computational biology, or a related life sciences field, OR equivalent professional experience&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Extensive experience in scientific computing and data analysis, with proficiency in programming (Python preferred)&lt;/li&gt;\n&lt;li&gt;Deep expertise in modern biology, including both &quot;reading&quot; (e.g. high-throughput measurement, functional assays) and &quot;writing&quot; (gene synthesis, genome editing, strain construction, protein engineering) techniques in biology&lt;/li&gt;\n&lt;li&gt;Familiarity with dual-use research concerns, select agent regulations, and biosecurity frameworks (e.g., Biological Weapons Convention, Australia Group guidelines)&lt;/li&gt;\n&lt;li&gt;Strong analytical and writing skills, with the ability to navigate ambiguity and explain complex technical concepts to non-technical stakeholders&lt;/li&gt;\n&lt;li&gt;Have a passion for learning new skills and an ability to rapidly adapt to changing techniques and technologies&lt;/li&gt;\n&lt;li&gt;Comfort working in a fast-paced environment where priorities may shift as AI capabilities evolve&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Preferred Qualifications&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Background in AI/ML systems, particularly experience with large language models&lt;/li&gt;\n&lt;li&gt;Experience in developing ML for biological systems&lt;/li&gt;\n&lt;li&gt;Extensive experience in complex projects with multiple stakeholders&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$300,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$320,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5066977008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Health and Life Science Policy Lead",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA; Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5070787008",
    "job_posted_at_datetime_utc": "2026-01-14T15:28:15-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About The Role As a member of the product public policy team, you will build Anthropic's healthcare and life sciences policy strategy from the ground up. This role will translate emerging regulations into product opportunities, turn our technical advantages into competitive differentiation, and shape regulatory frameworks to support our mission and enable responsible health AI development and deployment. The role will also engage deeply with our product, GTM, and other cross functional teams. In this role you will: Build/maintain relationships with key US health agencies (FDA, CMS, HHS) and international counterparts Shape Anthropicâ€™s positions on key health policy issues impacting product (e.g., software regulation, reimbursement, explainability) Translate emerging health AI policies and frameworks into specific product opportunities, focusing on ethical and responsible use of AI for health Work closely with product teams to support responsible product development, bringing policy considerations directly into product decisions/pipeline Monitor global regulatory developments and drive policy consultation responses Work with product, go-to-market and cross functional teams to position Anthropic product choices as industry standard You may be a good fit if you: 8-12 years healthcare and/or life science regulatory policy (government and industry) Strong relationships with key health regulatory stakeholders (e.g., FDA, CMS, ONC) Track record tangibly shaping health policy/regulatory frameworks Experience working with health tech product teams (development, deployment) Excellent communicator with strong ability to translate technical AI concepts to regulators and regulatory requirements to product teams Ability to navigate fast-paced, hypergrowth company with autonomy and initiative Technical fluency in LLMs, health technology, and product development The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$295,000 - $345,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-health-and-life-science-policy-lead-san-francisco-ca-washington-dc",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5070787008",
    "title": "Health and Life Science Policy Lead",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA; Washington, DC",
    "locations": [
      "San Francisco, CA; Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5070787008",
    "departments": [
      "AI Policy & Societal Impacts"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T15:28:15-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About The Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a member of the product public policy team, you will build Anthropic&#39;s healthcare and life sciences policy strategy from the ground up. This role will translate emerging regulations into product opportunities, turn our technical advantages into competitive differentiation, and shape regulatory frameworks to support our mission and enable responsible health AI development and deployment. The role will also engage deeply with our product, GTM, and other cross functional teams.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;In this role you will:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Build/maintain relationships with key US health agencies (FDA, CMS, HHS) and international counterparts&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Shape Anthropicâ€™s positions on key health policy issues impacting product (e.g., software regulation, reimbursement, explainability)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Translate emerging health AI policies and frameworks into specific product opportunities, focusing on ethical and responsible use of AI for health&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Work closely with product teams to support responsible product development, bringing policy considerations directly into product decisions/pipeline&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Monitor global regulatory developments and drive policy consultation responses&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Work with product, go-to-market and cross functional teams to position Anthropic product choices as industry standard&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;8-12 years healthcare and/or life science regulatory policy (government and industry)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong relationships with key health regulatory stakeholders (e.g., FDA, CMS, ONC)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Track record tangibly shaping health policy/regulatory frameworks&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience working with health tech product teams (development, deployment)&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Excellent communicator with strong ability to translate technical AI concepts to regulators and regulatory requirements to product teams&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Ability to navigate fast-paced, hypergrowth company with autonomy and initiative&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Technical fluency in LLMs, health technology, and product development&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$295,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$345,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5070787008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Policy Manager, Frontier Risk",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5067283008",
    "job_posted_at_datetime_utc": "2026-01-14T15:21:21-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role: As the Product Policy Manager for Product Risk, you will play a crucial role in setting and executing the Safeguards teamâ€™s approach to assessing product launches for safety risks and working with cross functional stakeholders to drive appropriate safety mitigations. You'll work closely with a suite of cross-functional teams, within and outside of Safeguards, including, product, legal, public policy, and engineering teams to understand upcoming features, anticipate potential misuses or unintended consequences, and craft policies that balance innovation with responsibility. Your work will be essential in maintaining Anthropic's commitment to safe and beneficial AI as we continue to expand our product capabilities. IMPORTANT CONTEXT ON THIS ROLE: In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature. Responsibilities: Develop and maintain risk assessment frameworks to identify and evaluate potential safety risks associated with new product features and functionality Conduct comprehensive product safety reviews, covering technical and non technical harms, to inform product launch and safety mitigation strategies Collaborate closely with a variety of stakeholders including product and engineering teams and the broader Safeguards team to leverage deep policy, enforcement, and engineering expertise Analyze the potential for misuse, unintended consequences, and harmful outputs of new model and product capabilities Leverage SME risk assessments to inform overall product safety recommendations Design and run bespoke evaluations for products that require tailored assessment Craft policy recommendations that strike a balance between enabling innovation and ensuring responsible AI deployment Work with the Safeguards enforcement team to develop clear guidelines for implementing new policies related to product features Lead agentic product policy development, incorporating internal and external feedback Stay current on industry trends and emerging risks in AI development to proactively address potential issues Contribute to regular reports on product policy risks and mitigations for senior leadership You might thrive in this role if you: Have a strong technical background while also feeling equally comfortable explaining highly technical concepts to non-technical stakeholders Understand safety policies and safety considerations associated with a wide range of product surfaces Are adept at prioritizing where, and how, to focus resources for safety mitigations in a high volume launch process Have conducted risk evaluations of novel products in fast moving organizations Demonstrated expertise collaborating with product and engineering teams to integrate safety considerations into product development Have familiarity with AI ethics, responsible AI principles, and current debates surrounding AI safety and governance Have the ability to think creatively about potential misuses of technology and develop innovative solutions to mitigate risks Have shown strong project management skills with the ability to drive policy development processes from ideation to implementation The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$245,000 - $285,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-policy-manager-frontier-risk-remote-friendly-travel-required-san-francisco-ca-washington-dc",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5067283008",
    "title": "Product Policy Manager, Frontier Risk",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5067283008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T15:21:21-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role:&lt;/h2&gt;\n&lt;p&gt;As the Product Policy Manager for Product Risk, you will play a crucial role in setting and executing the Safeguards teamâ€™s approach to assessing product launches for safety risks and working with cross functional stakeholders to drive appropriate safety mitigations. You&#39;ll work closely with a suite of cross-functional teams, within and outside of Safeguards, including, product, legal, public policy, and engineering teams to understand upcoming features, anticipate potential misuses or unintended consequences, and craft policies that balance innovation with responsibility. Your work will be essential in maintaining Anthropic&#39;s commitment to safe and beneficial AI as we continue to expand our product capabilities.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;IMPORTANT CONTEXT ON THIS ROLE:&lt;/strong&gt; In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and maintain risk assessment frameworks to identify and evaluate potential safety risks associated with new product features and functionality&lt;/li&gt;\n&lt;li&gt;Conduct comprehensive product safety reviews, covering technical and non technical harms, to inform product launch and safety mitigation strategies&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Collaborate closely with a variety of stakeholders including product and engineering teams and the broader Safeguards team to leverage deep policy, enforcement, and engineering expertise&lt;/li&gt;\n&lt;li&gt;Analyze the potential for misuse, unintended consequences, and harmful outputs of new model and product capabilities&lt;/li&gt;\n&lt;li&gt;Leverage SME risk assessments to inform overall product safety recommendations&lt;/li&gt;\n&lt;li&gt;Design and run bespoke evaluations for products that require tailored assessment&lt;/li&gt;\n&lt;li&gt;Craft policy recommendations that strike a balance between enabling innovation and ensuring responsible AI deployment&lt;/li&gt;\n&lt;li&gt;Work with the Safeguards enforcement team to develop clear guidelines for implementing new policies related to product features&lt;/li&gt;\n&lt;li&gt;Lead agentic product policy development, incorporating internal and external feedback&lt;/li&gt;\n&lt;li&gt;Stay current on industry trends and emerging risks in AI development to proactively address potential issues&lt;/li&gt;\n&lt;li&gt;Contribute to regular reports on product policy risks and mitigations for senior leadership&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You might thrive in this role if you&lt;strong&gt;:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a strong technical background while also feeling equally comfortable explaining highly technical concepts to non-technical stakeholders&lt;/li&gt;\n&lt;li&gt;Understand safety policies and safety considerations associated with a wide range of product surfaces&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Are adept at prioritizing where, and how, to focus resources for safety mitigations in a high volume launch process&lt;/li&gt;\n&lt;li&gt;Have conducted risk evaluations of novel products in fast moving organizations&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Demonstrated expertise collaborating with product and engineering teams to integrate safety considerations into product development&lt;/li&gt;\n&lt;li&gt;Have familiarity with AI ethics, responsible AI principles, and current debates surrounding AI safety and governance&lt;/li&gt;\n&lt;li&gt;Have the ability to think creatively about potential misuses of technology and develop innovative solutions to mitigate risks&lt;/li&gt;\n&lt;li&gt;Have shown strong project management skills with the ability to drive policy development processes from ideation to implementation&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$245,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$285,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5067283008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Staff Product Designer",
    "employer_name": "stripe",
    "job_city": "US ",
    "job_apply_link": "https://stripe.com/jobs/search?gh_jid=7536458",
    "job_posted_at_datetime_utc": "2026-01-14T14:57:39-05:00",
    "job_description": "Help increase the GDP of the internet as part of our Design team.",
    "id": "stripe-staff-product-designer-us",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7536458",
    "title": "Staff Product Designer",
    "company_name": "stripe",
    "company_slug": "stripe",
    "location": "US ",
    "locations": [
      "US "
    ],
    "url": "https://stripe.com/jobs/search?gh_jid=7536458",
    "departments": [
      "8811 Product Design"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T14:57:39-05:00",
    "fetched_at": "2026-01-17T04:05:15.557Z",
    "description": "&lt;h2&gt;&lt;strong&gt;Who we are&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;About Stripe&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;Stripe is a financial infrastructure platform for businesses. Millions of companiesâ€”from the worldâ€™s largest enterprises to the most ambitious startupsâ€”use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyoneâ€™s reach while doing the most important work of your career.&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;About the team&lt;/strong&gt;&lt;/h3&gt;\n&lt;p&gt;The Product Design team is made up of several groups that define, create, and deliver all user-facing aspects of Stripeâ€™s products. Product Designers work directly with Engineers, Product Managers, Data Scientists, and Marketers, as strategic partners, in each product area.&amp;nbsp; In close collaboration with product teams, they shape user experiences, then translate them into high-quality designs that can be tested, shipped, and refined. Designers are responsible for building elegant, functional products that users loveâ€”and want to tell others about.&lt;/p&gt;\n&lt;p&gt;We are looking to hire a wide variety of Product Designers to partner with teams across: Payments, Revenue &amp;amp; Finance, Seller Experiences, Connect, Dashboard experiences, Billing, Terminal, and more!&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;Team Matching: exact team matching for one of the sub-teams will begin during final stages. Please note we may also consider you for different orgs based on your experience, location, interests, etc.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;What youâ€™ll do&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;You will work closely with a specific part of the business, leading the end to end work, collaborating closely with other designers to set a high bar for craft and quality experience.&amp;nbsp; Each of our roles are a mix of product strategy, new and existing feature development, and an opportunity to understand the needs of various user segments to design and build solutions that will help more people get started and run their businesses successfully on Stripe.&amp;nbsp;&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Deliver high-quality, user-centered designs that evolve core surfaces and elevate the overall user experience&lt;/li&gt;\n&lt;li&gt;Design, prototype, and test thoughtful, intuitive experiences that make complicated flows feel simple and clear.&lt;/li&gt;\n&lt;li&gt;Collaborate with designers, PMs, and engineers to define both long-term strategy and near-term tactics&lt;/li&gt;\n&lt;li&gt;Craft high-quality UIs that set the bar for design excellence at Stripe&lt;/li&gt;\n&lt;li&gt;Share work regularly in design reviews and actively contribute to a strong culture of feedback and iteration&lt;/li&gt;\n&lt;li&gt;Collaborate with UX Research to inform and validate design decisions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Who you are&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Weâ€™re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.&lt;/p&gt;\n&lt;h3&gt;&lt;strong&gt;Minimum requirements&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of relevant product design experience at a product-driven tech company&lt;/li&gt;\n&lt;li&gt;A portfolio that demonstrates strong design fundamentals and polished UI craft&lt;/li&gt;\n&lt;li&gt;Experience partnering closely with cross-functional teams to shape product direction&lt;/li&gt;\n&lt;li&gt;Ability to balance user needs, business goals, and multiple stakeholder inputs&lt;/li&gt;\n&lt;li&gt;Skilled at communicating design decisions and rationale across disciplines&lt;/li&gt;\n&lt;li&gt;Experience working horizontally across product areas on ambiguous and complex problems&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Strong ability to influence teams and product direction&lt;/li&gt;\n&lt;li&gt;Confident presenting work to company leadership and skilled at communicating design decisions through a clear and compelling story&lt;/li&gt;\n&lt;/ul&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7536458
    },
    "job_posted_at": "1h",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Technical Program Manager, Security - Detection & Response",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5066957008",
    "job_posted_at_datetime_utc": "2026-01-14T14:42:30-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role As a Staff Technical Program Manager for Security â€“ Detection & Response, you will define and execute company critical security programs that protect Anthropic's most sensitive assets, people, and infrastructure. You will lead strategic initiatives spanning insider risk, security observability, threat detection, and incident response programs that are essential to Anthropic's ability to meet its Responsible Scaling Policy (RSP) commitments and maintain the trust of our stakeholders. This is a senior level TPM role requiring executive presence, strategic vision, and the ability to drive transformational programs across Security Engineering, Infrastructure, Research, and cross-functional partners. You will be responsible for building the programmatic foundations of Anthropic's detection and response capabilities while mentoring senior TPMs and shaping the future of security program management at the company. This role sits within the Security TPM team, aligned to the Detection & Response security organization, and reports to the Security TPM Lead. Responsibilities: Own the strategic portfolio for Detection & Response programs: Define and drive the strategy, roadmap, and execution of insider risk, observability, and threat detection initiatives that are critical to company security posture and RSP compliance Lead company wide security programs with executive impact: Manage programs that span multiple organizations, require significant change management, and directly affect Anthropic's ability to detect, investigate, and respond to security threats Build and scale detection and response program infrastructure: Develop program charters, governance frameworks, success metrics, and communication strategies for nascent and evolving security domains Partner with Security Engineering to drive technical program strategy for security observability: Define requirements and coordinate implementation of security telemetry, logging, and monitoring capabilities across Anthropic's infrastructure Lead insider risk program execution: Develop and manage programs that address insider threat detection, investigation workflows, and prevention controls while balancing privacy, legal, and operational considerations Collaborate with senior leadership and executives: Communicate program vision, risks, and progress with executive presence; influence strategic priorities and secure alignment across Security, Infrastructure, Legal, and Research leadership Mentor and develop senior TPMs: Provide strategic guidance and coaching to TPMs across the Security team, building a culture of excellence and developing future leaders Coordinate incident investigation and response efforts: Lead cross-functional coordination during security incidents, ensuring effective communication, stakeholder alignment, and post-incident improvements Partner on AI-driven security innovation: Collaborate with teams exploring agentic AI applications in security workflows, helping translate emerging capabilities into executable programs You May Be a Good Fit If You Have: 15+ years of experience in the cybersecurity field, with at least 5+ years leading large-scale Security Engineering programs, encompassing a broad understanding of cyber threats, defense mechanisms, and the cybersecurity landscape Technical expertise in detection and response technologies including Splunk, Detection Engineering, Detection as Code, Infrastructure as Code, and Security Operations Technical background in cybersecurity methodologies with focus on threat intelligence, detection, response, and prevention Familiarity working on detection capabilities for AI Lab organizations Proven experience as a Technical Program Manager or similar role in a cybersecurity or technology-focused environment, with a track record of leading complex, company-wide programs to successful completion Executive communication skills with demonstrated ability to influence decisions at the senior leadership and C-suite level Experience leading incident investigation efforts and effectively coordinating communications across technical and non-technical stakeholders Ability to manage highly ambiguous problems and navigate challenges to achieve program objectives in a fast-paced, evolving environment Strong collaboration skills with proven ability to partner across diverse technical stakeholders including Security Engineering, Infrastructure, Legal, HR, and Research teams Strong Candidates May Also Have: Experience building insider risk or insider threat programs from the ground up Background in security operations center (SOC) leadership or detection engineering management Experience with security programs in AI/ML research environments Familiarity with compliance frameworks (SOC 2, ISO 27001, FedRAMP) and their intersection with detection and response capabilities Prior technical experience as a security engineer, detection engineer, or incident responder Experience with security aspects of cloud infrastructure and distributed systems Deadline to Apply: None, applications will be received on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$365,000 - $435,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-technical-program-manager-security-detection-response-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5066957008",
    "title": "Technical Program Manager, Security - Detection & Response",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5066957008",
    "departments": [
      "Technical Program Management "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T14:42:30-05:00",
    "fetched_at": "2026-01-17T04:05:13.933Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;About the Role&lt;/h2&gt;\n&lt;p&gt;As a Staff Technical Program Manager for Security â€“ Detection &amp;amp; Response, you will define and execute company critical security programs that protect Anthropic&#39;s most sensitive assets, people, and infrastructure. You will lead strategic initiatives spanning insider risk, security observability, threat detection, and incident response programs that are essential to Anthropic&#39;s ability to meet its &lt;a class=&quot;text-accent-secondary-100 underline&quot; href=&quot;https://www.anthropic.com/news/anthropics-responsible-scaling-policy&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;Responsible Scaling Policy (RSP)&lt;/u&gt;&lt;/a&gt; commitments and maintain the trust of our stakeholders.&lt;/p&gt;\n&lt;p&gt;This is a senior level TPM role requiring executive presence, strategic vision, and the ability to drive transformational programs across Security Engineering, Infrastructure, Research, and cross-functional partners. You will be responsible for building the programmatic foundations of Anthropic&#39;s detection and response capabilities while mentoring senior TPMs and shaping the future of security program management at the company.&lt;/p&gt;\n&lt;p&gt;This role sits within the Security TPM team, aligned to the Detection &amp;amp; Response security organization, and reports to the Security TPM Lead.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Own the strategic portfolio for Detection &amp;amp; Response programs&lt;/strong&gt;: Define and drive the strategy, roadmap, and execution of insider risk, observability, and threat detection initiatives that are critical to company security posture and RSP compliance&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Lead company wide security programs with executive impact&lt;/strong&gt;: Manage programs that span multiple organizations, require significant change management, and directly affect Anthropic&#39;s ability to detect, investigate, and respond to security threats&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Build and scale detection and response program infrastructure&lt;/strong&gt;: Develop program charters, governance frameworks, success metrics, and communication strategies for nascent and evolving security domains&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Partner with Security Engineering to drive technical program strategy for security observability:&lt;/strong&gt; Define requirements and coordinate implementation of security telemetry, logging, and monitoring capabilities across Anthropic&#39;s infrastructure&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Lead insider risk program execution&lt;/strong&gt;: Develop and manage programs that address insider threat detection, investigation workflows, and prevention controls while balancing privacy, legal, and operational considerations&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Collaborate with senior leadership and executives&lt;/strong&gt;:&amp;nbsp; Communicate program vision, risks, and progress with executive presence; influence strategic priorities and secure alignment across Security, Infrastructure, Legal, and Research leadership&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Mentor and develop senior TPMs&lt;/strong&gt;: Provide strategic guidance and coaching to TPMs across the Security team, building a culture of excellence and developing future leaders&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Coordinate incident investigation and response efforts&lt;/strong&gt;: Lead cross-functional coordination during security incidents, ensuring effective communication, stakeholder alignment, and post-incident improvements&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Partner on AI-driven security innovation&lt;/strong&gt;: Collaborate with teams exploring agentic AI applications in security workflows, helping translate emerging capabilities into executable programs&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;You May Be a Good Fit If You Have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;15+ years of experience in the cybersecurity field, with at least 5+ years leading large-scale Security Engineering programs, encompassing a broad understanding of cyber threats, defense mechanisms, and the cybersecurity landscape&lt;/li&gt;\n&lt;li&gt;Technical expertise in detection and response technologies including Splunk, Detection Engineering, Detection as Code, Infrastructure as Code, and Security Operations&lt;/li&gt;\n&lt;li&gt;Technical background in cybersecurity methodologies with focus on threat intelligence, detection, response, and prevention&lt;/li&gt;\n&lt;li&gt;Familiarity working on detection capabilities for AI Lab organizations&lt;/li&gt;\n&lt;li&gt;Proven experience as a Technical Program Manager or similar role in a cybersecurity or technology-focused environment, with a track record of leading complex, company-wide programs to successful completion&lt;/li&gt;\n&lt;li&gt;Executive communication skills with demonstrated ability to influence decisions at the senior leadership and C-suite level&lt;/li&gt;\n&lt;li&gt;Experience leading incident investigation efforts and effectively coordinating communications across technical and non-technical stakeholders&lt;/li&gt;\n&lt;li&gt;Ability to manage highly ambiguous problems and navigate challenges to achieve program objectives in a fast-paced, evolving environment&lt;/li&gt;\n&lt;li&gt;Strong collaboration skills with proven ability to partner across diverse technical stakeholders including Security Engineering, Infrastructure, Legal, HR, and Research teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;Strong Candidates May Also Have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience building insider risk or insider threat programs from the ground up&lt;/li&gt;\n&lt;li&gt;Background in security operations center (SOC) leadership or detection engineering management&lt;/li&gt;\n&lt;li&gt;Experience with security programs in AI/ML research environments&lt;/li&gt;\n&lt;li&gt;Familiarity with compliance frameworks (SOC 2, ISO 27001, FedRAMP) and their intersection with detection and response capabilities&lt;/li&gt;\n&lt;li&gt;Prior technical experience as a security engineer, detection engineer, or incident responder&lt;/li&gt;\n&lt;li&gt;Experience with security aspects of cloud infrastructure and distributed systems&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to Apply:&lt;/strong&gt; None, applications will be received on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$365,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$435,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5066957008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Software Engineer, Cybersecurity Products",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA; Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5063007008",
    "job_posted_at_datetime_utc": "2026-01-14T14:42:05-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We're looking for engineers to join a new effort building AI-powered products and capabilities for cybersecurity. You'll work across the stack to prototype new ideas and build from the ground up. This role sits at the intersection of research, product, and go-to-market. You'll work closely with research teams to develop new model capabilities for security applications, prototype and iterate quickly to validate ideas, and engage directly with customers and partners to inform what we build. The right candidate has the technical depth to engage with research, the product instincts to know what's worth building, and the drive to move fast. Responsibilities Prototype and build new AI-powered products for cybersecurity Iterate quickly based on customer feedback and what you learn Collaborate with research teams to identify and develop new model capabilities for security applications Engage directly with customers and partners to understand workflows and inform product direction You may be a good fit if you: Have 7+ years of experience as a software engineer Experience developing cybersecurity products Enjoy fast iteration and are energized by prototyping new ideas Have strong product instincts and enjoy defining what to build, not just how to build it Are comfortable working closely with research and go-to-market teams Have strong communication skills and can work effectively across functions Strong candidates may also have: Experience in incident response, reverse engineering, network analysis, penetration testing, or similar fields Experience working with AI/ML models and building products on top of them Experience building agentic applications Deadline to apply: None. Applications will be reviewed on a rolling basis.The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$320,000 - $405,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-software-engineer-cybersecurity-products-san-francisco-ca-new-york-city-ny-seattle-wa-washington-dc",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5063007008",
    "title": "Software Engineer, Cybersecurity Products",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA; Washington, DC",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA; Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5063007008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T14:42:05-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We&#39;re looking for engineers to join a new effort building AI-powered products and capabilities for cybersecurity. You&#39;ll work across the stack to prototype new ideas and build from the ground up.&lt;/p&gt;\n&lt;p&gt;This role sits at the intersection of research, product, and go-to-market. You&#39;ll work closely with research teams to develop new model capabilities for security applications, prototype and iterate quickly to validate ideas, and engage directly with customers and partners to inform what we build. The right candidate has the technical depth to engage with research, the product instincts to know what&#39;s worth building, and the drive to move fast.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Responsibilities&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Prototype and build new AI-powered products for cybersecurity&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Iterate quickly based on customer feedback and what you learn&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Collaborate with research teams to identify and develop new model capabilities for security applications&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Engage directly with customers and partners to understand workflows and inform product direction&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Have 7+ years of experience as a software engineer&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience developing cybersecurity products&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Enjoy fast iteration and are energized by prototyping new ideas&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have strong product instincts and enjoy defining what to build, not just how to build it&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Are comfortable working closely with research and go-to-market teams&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Have strong communication skills and can work effectively across functions&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Strong candidates may also have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;Experience in incident response, reverse engineering, network analysis, penetration testing, or similar fields&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience working with AI/ML models and building products on top of them&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience building agentic applications&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Deadline to apply:&lt;/strong&gt; None. Applications will be reviewed on a rolling basis.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$320,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$405,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5063007008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "External Policy & Partnerships Manager, Safeguards",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5067287008",
    "job_posted_at_datetime_utc": "2026-01-14T14:04:30-05:00",
    "job_description": "About Anthropic Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As an External Policy & Partnerships Manager on the Safeguards Outreach & Partnerships team, you will own how Anthropic communicates its safety policies to the outside world and how we work with external partners to strengthen our approach. This includes maintaining and evolving our Usage Policy and other external-facing policy documents, supporting enterprise customer relationships alongside our Sales/Go-to-Market and Legal teams, driving transparency efforts like model cards and public reporting, and building external partnerships that inform our policy development and safety practices. You'll serve as a bridge between internal policy development and external stakeholdersâ€”translating nuanced safety decisions into clear, consistent language for users, customers, and regulators. Commercial teams will see you as a key partner navigating customer questions about our policies, detection systems, and enforcement practices. You'll manage expert relationships that inform our policies and interventions, coordinate research partnerships that establish best practices in AI safety, and oversee vendor relationships that power key safety features. This is a role for someone who can operate across legal, policy, partnership, and commercial contexts while maintaining a clear through-line on Anthropic's safety commitments. *Important context for this role: In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature. Responsibilities: External Policy Own and coordinate updates to external policy documents, including the Usage Policy, Supported Regions Policy, and Safeguards-related elements of our Terms of Service Coordinate cross-functional review processes for policy updates and external content, working across Legal, Policy, Communications, and Product teams Be the first point of contact for policy interpretation and application questions, working with subject matter experts as needed Work with internal policy SMEs to translate complex policies and decisions into clear external-facing language Drive Safeguards contributions to external reporting efforts, including model cards, transparency reports, and Help Center content Meet regulatory obligations around transparency and reporting, including for the EU AI Act and other emerging requirements Work with Policy teams to track regulatory developments that may impact external policy language and reporting requirements Collaborate with Engineering and Enforcement teams to translate policy into workflows or automated processes Customer & Commercial Relationships Partner with Sales/Go-to-Market and Legal teams to support enterprise customer relationships, including liaising with customers on Safeguards policies and procedures Support customer negotiations involving Safeguards-related terms, consulting with policy owners to ensure consistency Develop scalable resources (FAQs, one-pagers, decision trees) to support recurring policy questions from cross-functional teams External Partnerships Build and maintain expert relationships across civil society, academia, and government that inform policy development and evaluation frameworks Coordinate research partnerships and expert consultations across Safeguards topic areas Manage vendor relationships for safety tools and interventions, including contract negotiation and ongoing coordination You may be a good fit if you have: 6+ years in policy, compliance, or trust & safety roles, ideally at a technology company A track record of drafting or maintaining external-facing policy documents (e.g., acceptable use policies, terms of service, community guidelines) Experience supporting commercial or legal teams on policy-related customer questions Track record of building relationships with civil society organizations, academic institutions, or government bodies Strong writing skills with the ability to translate technical or nuanced concepts into clear, accessible language Background working cross-functionally across legal, policy, product, engineering, and communications teams Vendor management experience, including contract negotiation and ongoing coordination Familiarity with AI safety, user trust, or platform policy issues Comfort with ambiguity and the ability to make judgment calls on novel policy questions History of contributing to transparency or public reporting efforts (model cards, transparency reports, regulatory filings) The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$245,000 - $285,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any linksâ€”visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-external-policy-partnerships-manager-safeguards-remote-friendly-travel-required-san-francisco-ca-washington-dc",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5067287008",
    "title": "External Policy & Partnerships Manager, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5067287008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T14:04:30-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropicâ€™s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As an External Policy &amp;amp; Partnerships Manager on the Safeguards Outreach &amp;amp; Partnerships team, you will own how Anthropic communicates its safety policies to the outside world and how we work with external partners to strengthen our approach. This includes maintaining and evolving our Usage Policy and other external-facing policy documents, supporting enterprise customer relationships alongside our Sales/Go-to-Market and Legal teams, driving transparency efforts like model cards and public reporting, and building external partnerships that inform our policy development and safety practices.&lt;/p&gt;\n&lt;p&gt;You&#39;ll serve as a bridge between internal policy development and external stakeholdersâ€”translating nuanced safety decisions into clear, consistent language for users, customers, and regulators. Commercial teams will see you as a key partner navigating customer questions about our policies, detection systems, and enforcement practices. You&#39;ll manage expert relationships that inform our policies and interventions, coordinate research partnerships that establish best practices in AI safety, and oversee vendor relationships that power key safety features.&lt;/p&gt;\n&lt;p&gt;This is a role for someone who can operate across legal, policy, partnership, and commercial contexts while maintaining a clear through-line on Anthropic&#39;s safety commitments.&lt;/p&gt;\n&lt;p&gt;&lt;em&gt;*Important context for this role: In this position you may be exposed to and engage with explicit content spanning a range of topics, including those of a sexual, violent, or psychologically disturbing nature.&lt;/em&gt;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;strong&gt;External Policy&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Own and coordinate updates to external policy documents, including the Usage Policy, Supported Regions Policy, and Safeguards-related elements of our Terms of Service&lt;/li&gt;\n&lt;li&gt;Coordinate cross-functional review processes for policy updates and external content, working across Legal, Policy, Communications, and Product teams&lt;/li&gt;\n&lt;li&gt;Be the first point of contact for policy interpretation and application questions, working with subject matter experts as needed&lt;/li&gt;\n&lt;li&gt;Work with internal policy SMEs to translate complex policies and decisions into clear external-facing language&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Drive Safeguards contributions to external reporting efforts, including model cards, transparency reports, and Help Center content&lt;/li&gt;\n&lt;li&gt;Meet regulatory obligations around transparency and reporting, including for the EU AI Act and other emerging requirements&lt;/li&gt;\n&lt;li&gt;Work with Policy teams to track regulatory developments that may impact external policy language and reporting requirements&lt;/li&gt;\n&lt;li&gt;Collaborate with Engineering and Enforcement teams to translate policy into workflows or automated processes&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;Customer &amp;amp; Commercial Relationships&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Partner with Sales/Go-to-Market and Legal teams to support enterprise customer relationships, including liaising with customers on Safeguards policies and procedures&lt;/li&gt;\n&lt;li&gt;Support customer negotiations involving Safeguards-related terms, consulting with policy owners to ensure consistency&lt;/li&gt;\n&lt;li&gt;Develop scalable resources (FAQs, one-pagers, decision trees) to support recurring policy questions from cross-functional teams&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3&gt;&lt;strong&gt;External Partnerships&lt;/strong&gt;&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;Build and maintain expert relationships across civil society, academia, and government that inform policy development and evaluation frameworks&lt;/li&gt;\n&lt;li&gt;Coordinate research partnerships and expert consultations across Safeguards topic areas&lt;/li&gt;\n&lt;li&gt;Manage vendor relationships for safety tools and interventions, including contract negotiation and ongoing coordination&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;6+ years in policy, compliance, or trust &amp;amp; safety roles, ideally at a technology company&lt;/li&gt;\n&lt;li&gt;A track record of drafting or maintaining external-facing policy documents (e.g., acceptable use policies, terms of service, community guidelines)&lt;/li&gt;\n&lt;li&gt;Experience supporting commercial or legal teams on policy-related customer questions&lt;/li&gt;\n&lt;li&gt;Track record of building relationships with civil society organizations, academic institutions, or government bodies&lt;/li&gt;\n&lt;li&gt;Strong writing skills with the ability to translate technical or nuanced concepts into clear, accessible language&lt;/li&gt;\n&lt;li&gt;Background working cross-functionally across legal, policy, product, engineering, and communications teams&lt;/li&gt;\n&lt;li&gt;Vendor management experience, including contract negotiation and ongoing coordination&lt;/li&gt;\n&lt;li&gt;Familiarity with AI safety, user trust, or platform policy issues&lt;/li&gt;\n&lt;li&gt;Comfort with ambiguity and the ability to make judgment calls on novel policy questions&lt;/li&gt;\n&lt;li&gt;History of contributing to transparency or public reporting efforts (model cards, transparency reports, regulatory filings)&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the roleâ€™s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$245,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$285,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any linksâ€”visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact â€” advancing our long-term goals of steerable, trustworthy AI â€” rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5067287008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Tools Administration Lead",
    "employer_name": "gusto",
    "job_city": "Denver, CO;Chicago, IL;Las Vegas, NV;Phoenix, AZ;San Francisco, CA;New York, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/gusto/jobs/7522739",
    "job_posted_at_datetime_utc": "2026-01-14T13:51:03-05:00",
    "job_description": "About Gusto At Gusto, we're on a mission to grow the small business economy. We handle the hard stuffâ€”like payroll, health insurance, 401(k)s, and HRâ€”so owners can focus on their craft and customers. With teams in Denver, San Francisco, and New York, weâ€™re proud to support more than 400,000 small businesses across the country, and weâ€™re building a workplace that represents and celebrates the customers we serve. Learn more about our Total Rewards philosophy. About the Role: This role requires a deep understanding of contact center operations, quality programs, customer survey best practices, and strong program management skills, ideally within an agile/scrum environment. You will collaborate closely across a broad scope of teams including Planning, Scheduling, and Intraday Management WFM teams, as well as CX leadership, operations teams, and technology partners, to drive efficiency, improve agent and customer experience, and ensure optimal experiences for our quality and CIP tools. About the Team: As a Tools Administration Lead for Quality and Customer Interactions Platform (CIP), you will be a key leader within the Workforce and CX organizations as a whole, reporting to the Head of Strategy and Tool Administration. You will be responsible for leading and executing strategic programs focused on optimizing our Quality and CIP programs, primarily leveraging Salesforce, Qualtrics, and internal quality tools. Hereâ€™s what youâ€™ll do day-to-day: Lead and manage complex programs and projects related to quality and CIP, including Salesforce contact management, Qualtrics administration and best practices, upgrades, integrations, and process improvements, directly supporting the needs of our overall CX organization. Define program scope, objectives, processes, and key deliverables in alignment with business goals and CX strategy, in close collaboration with the overall CX organization. Develop detailed project plans, timelines, and resource allocation strategies, ensuring on-time and within-budget delivery for initiatives impacting the CX organization. Facilitate agile ceremonies (e.g., sprint planning, daily stand-ups, sprint reviews, retrospectives) for Quality and CIP initiatives, promoting agile principles and practices within and alongside CX teams. Collaborate with cross-functional teams, including CX Operations, Planning, Scheduling, Intraday Management, Technology, Quality, and Analytics, to gather requirements, manage dependencies, and ensure successful program execution that directly benefits the CX organization. Identify, assess, and mitigate program risks and issues, proactively developing and implementing solutions that address challenges faced by the Quality, Routing, WFM, and CX teams.. Develop and maintain comprehensive program documentation, including project plans, risk logs, communication plans, and status reports, specifically tailored to Quality, Routing, WFM, and CX initiatives. Communicate program progress, risks, and key decisions to stakeholders at all levels, ensuring clear and consistent updates to the Quality, Routing, WFM, and CX teams. Drive continuous improvement in Quality and CIP processes and program management methodologies within the CX organization, actively seeking input and collaboration from the broader CX teams. Proactively uses data to find trends, drive decisions, and ensure we are delivering the best possible experience for internal stakeholders and customers. Contribute to the development and delivery of training materials related to Quality and CIP programs and processes, ensuring relevance and accessibility for the CX organization. Hereâ€™s what we're looking for: 7-10+ years of progressive experience in program management, planning, tools administration, and/or strategy, with a significant focus on workforce management within a contact center environment, including direct support of Quality, contact routing, and survey administration. Deep understanding of contact center operations, Quality methodologies, survey best practices, and contact routing across multiple channels. Proven experience managing projects related to Quality and survey tooling, upgrades, or significant process improvements that directly impact CX teams. Strong program management skills, including planning, execution, risk management, and stakeholder communication, with a focus on collaborating effectively with CX professionals. Experience working in an agile/scrum environment and a solid understanding of agile principles and practices, with the ability to apply them to CX-related projects. Excellent analytical and problem-solving skills with the ability to interpret data and make informed decisions related to workforce optimization for Quality, surveys, and CIP implementation. Strong communication, collaboration, and interpersonal skills, with the ability to influence and build relationships across diverse teams, including many different teams within CX.. Ability to manage multiple priorities and work effectively in a fast-paced, dynamic environment, supporting the diverse needs of the CX organization. Proficiency in project management tools (e.g., Jira, Asana, NotionAI). Knowledge of Quality systems, Salesforce, and Qualtrics is a plus, but not required. Our cash compensation amount for this role is $94,285/yr to $122,571/yr in Denver & most major metro locations, and $114,695/yr to $149,104/yr for San Francisco & New York. Final offer amounts are determined by multiple factors including candidate location, experience and expertise and may vary from the amounts listed above. Gusto has physical office spaces in Denver, San Francisco, and New York City. Employees who are based in those locations will be expected to work from the office on designated days approximately 2-3 days per week (or more depending on role). The same office expectations apply to all Symmetry roles, Gusto's subsidiary, whose physical office is in Scottsdale. Note: The San Francisco office expectations encompass both the San Francisco and San Jose metro areas. When approved to work from a location other than a Gusto office, a secure, reliable, and consistent internet connection is required. This includes non-office days for hybrid employees. Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto. Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. We want to see our candidates perform to the best of their ability. If you require a medical or religious accommodation at any time throughout your candidate journey, please fill out this form and a member of our team will get in touch with you. Gusto takes security and protection of your personal information very seriously. Please review our Fraudulent Activity Disclaimer. Personal information collected and processed as part of your Gusto application will be subject to Gusto's Applicant Privacy Notice.",
    "id": "gusto-tools-administration-lead-denver-co-chicago-il-las-vegas-nv-phoenix-az-san-francisco-ca-new-york-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "7522739",
    "title": "Tools Administration Lead",
    "company_name": "gusto",
    "company_slug": "gusto",
    "location": "Denver, CO;Chicago, IL;Las Vegas, NV;Phoenix, AZ;San Francisco, CA;New York, NY",
    "locations": [
      "Denver, CO;Chicago, IL;Las Vegas, NV;Phoenix, AZ;San Francisco, CA;New York, NY"
    ],
    "url": "https://job-boards.greenhouse.io/gusto/jobs/7522739",
    "departments": [
      "Customer Experience"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:51:03-05:00",
    "fetched_at": "2026-01-17T04:05:36.415Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;p style=&quot;line-height: 1.2;&quot;&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr&gt;\n&lt;p&gt;&lt;strong&gt;About Gusto&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;At Gusto, we&#39;re on a mission to grow the small business economy. We handle the hard stuffâ€”like payroll, health insurance, 401(k)s, and HRâ€”so owners can focus on their craft and customers. With teams in Denver, San Francisco, and New York, weâ€™re proud to support more than 400,000 small businesses across the country, and weâ€™re building a workplace that represents and celebrates the customers we serve. Learn more about our &lt;/span&gt;&lt;a href=&quot;https://gusto.com/about/careers/total-rewards&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Total Rewards philosophy&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;About the Role:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;This role requires a deep understanding of contact center operations, quality programs, customer survey best practices, and strong program management skills, ideally within an agile/scrum environment. You will collaborate closely across a broad scope of teams including Planning, Scheduling, and Intraday Management WFM teams, as well as CX leadership, operations teams, and technology partners, to drive efficiency, improve agent and customer experience, and ensure optimal experiences for our quality and CIP tools.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;About the Team:&lt;/strong&gt;&lt;/p&gt;\n&lt;p&gt;As a Tools Administration Lead for Quality and Customer Interactions Platform (CIP), you will be a key leader within the Workforce and CX organizations as a whole, reporting to the Head of Strategy and Tool Administration. You will be responsible for leading and executing strategic programs focused on optimizing our Quality and CIP programs, primarily leveraging Salesforce, Qualtrics, and internal quality tools.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Hereâ€™s what youâ€™ll do day-to-day:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead and manage complex programs and projects related to quality and CIP, including Salesforce contact management, Qualtrics administration and best practices, upgrades, integrations, and process improvements, directly supporting the needs of our overall CX organization.&lt;/li&gt;\n&lt;li&gt;Define program scope, objectives, processes, and key deliverables in alignment with business goals and CX strategy, in close collaboration with the overall CX organization.&lt;/li&gt;\n&lt;li&gt;Develop detailed project plans, timelines, and resource allocation strategies, ensuring on-time and within-budget delivery for initiatives impacting the CX organization.&lt;/li&gt;\n&lt;li&gt;Facilitate agile ceremonies (e.g., sprint planning, daily stand-ups, sprint reviews, retrospectives) for Quality and CIP initiatives, promoting agile principles and practices within and alongside CX teams.&lt;/li&gt;\n&lt;li&gt;Collaborate with cross-functional teams, including CX Operations, Planning, Scheduling, Intraday Management, Technology, Quality, and Analytics, to gather requirements, manage dependencies, and ensure successful program execution that directly benefits the CX organization.&lt;/li&gt;\n&lt;li&gt;Identify, assess, and mitigate program risks and issues, proactively developing and implementing solutions that address challenges faced by the Quality, Routing, WFM, and CX teams..&lt;/li&gt;\n&lt;li&gt;Develop and maintain comprehensive program documentation, including project plans, risk logs, communication plans, and status reports, specifically tailored to Quality, Routing, WFM, and CX&amp;nbsp; initiatives.&lt;/li&gt;\n&lt;li&gt;Communicate program progress, risks, and key decisions to stakeholders at all levels, ensuring clear and consistent updates to the Quality, Routing, WFM, and CX teams.&lt;/li&gt;\n&lt;li&gt;Drive continuous improvement in Quality and CIP processes and program management methodologies within the CX organization, actively seeking input and collaboration from the broader CX teams.&lt;/li&gt;\n&lt;li&gt;Proactively uses data to find trends, drive decisions, and ensure we are delivering the best possible experience for internal stakeholders and customers.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Contribute to the development and delivery of training materials related to Quality and CIP programs and processes, ensuring relevance and accessibility for the CX organization.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Hereâ€™s what we&#39;re looking for:&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;7-10+ years of progressive experience in program management, planning, tools administration, and/or strategy, with a significant focus on workforce management within a contact center environment, including direct support of Quality, contact routing, and survey administration.&lt;/li&gt;\n&lt;li&gt;Deep understanding of contact center operations, Quality methodologies, survey best practices, and contact routing across multiple channels.&lt;/li&gt;\n&lt;li&gt;Proven experience managing projects related to Quality and survey tooling, upgrades, or significant process improvements that directly impact CX teams.&lt;/li&gt;\n&lt;li&gt;Strong program management skills, including planning, execution, risk management, and stakeholder communication, with a focus on collaborating effectively with CX professionals.&lt;/li&gt;\n&lt;li&gt;Experience working in an agile/scrum environment and a solid understanding of agile principles and practices, with the ability to apply them to CX-related projects.&lt;/li&gt;\n&lt;li&gt;Excellent analytical and problem-solving skills with the ability to interpret data and make informed decisions related to workforce optimization for Quality, surveys, and CIP implementation.&lt;/li&gt;\n&lt;li&gt;Strong communication, collaboration, and interpersonal skills, with the ability to influence and build relationships across diverse teams, including many different teams within CX..&lt;/li&gt;\n&lt;li&gt;Ability to manage multiple priorities and work effectively in a fast-paced, dynamic environment, supporting the diverse needs of the CX organization.&lt;/li&gt;\n&lt;li&gt;Proficiency in project management tools (e.g., Jira, Asana, NotionAI).&lt;/li&gt;\n&lt;li&gt;Knowledge of Quality systems, Salesforce, and Qualtrics is a plus, but not required.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Our cash compensation amount for this role is $94,285/yr to $122,571/yr in Denver &amp;amp; most major metro locations, and $114,695/yr to $149,104/yr for San Francisco &amp;amp; New York. Final offer amounts are determined by multiple factors including candidate location, experience and expertise and may vary from the amounts listed above.&lt;/p&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;hr&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Gusto has physical office spaces in Denver, San Francisco, and New York City. Employees who are based in those locations will be expected to work from the office on designated days approximately &lt;strong&gt;2-3 days &lt;/strong&gt;per week (or more depending on role). The same office expectations apply to all Symmetry roles, Gusto&#39;s subsidiary, whose physical office is in Scottsdale.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Note: The San Francisco office expectations encompass both the San Francisco and San Jose metro areas.&amp;nbsp;&lt;/p&gt;\n&lt;p&gt;When approved to work from a location other than a Gusto office, a secure, reliable, and consistent internet connection is required. This includes non-office days for hybrid employees.&lt;/p&gt;\n&lt;hr&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it&#39;s the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Gusto.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Gusto is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Gusto considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Gusto is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. We want to see our candidates perform to the best of their ability. If you require a medical or religious accommodation at any time throughout your candidate journey, please fill out &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSdEfl7Bp-Twz7LLlhGlha46CrxZ9Kacgakmarf3K2TbnaEgKQ/viewform&quot;&gt;this form&lt;/a&gt; and a member of our team will get in touch with you.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;Gusto takes security and protection of your personal information very seriously. Please review our &lt;a href=&quot;https://gusto.com/about/careers/fraudulent-activity-disclaimer&quot;&gt;Fraudulent Activity Disclaimer&lt;/a&gt;.&lt;/p&gt;\n&lt;p&gt;Personal information collected and processed as part of your Gusto application will be subject to&amp;nbsp;&lt;a href=&quot;https://gusto.com/about/careers/applicant-privacy-notice&quot; target=&quot;_blank&quot;&gt;Gusto&#39;s Applicant Privacy Notice&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 7522739
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]