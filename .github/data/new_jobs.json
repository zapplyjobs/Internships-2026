[
  {
    "job_title": "",
    "employer_name": "AgZen",
    "job_city": "Cambridge",
    "job_state": "MA",
    "job_description": ".fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-mobile-site-gutter, 6vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (8 - 1)) ) / 8 ); display: grid; position: relative; grid-area: 1/1/-1/-1; grid-template-rows: repeat(12,minmax(24px, auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(8, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); row-gap: 11.0px; column-gap: 11.0px; overflow-x: hidden; overflow-x: clip; } @media (min-width: 768px) { .background-width--inset .fe-681e70c2a649507003c3aab5 { --inset-padding: calc(var(--sqs-site-gutter) * 2); } .fe-681e70c2a649507003c3aab5 { --grid-gutter: calc(var(--sqs-site-gutter, 4vw) - 11.0px); --cell-max-width: calc( ( var(--sqs-site-max-width, 1500px) - (11.0px * (24 - 1)) ) / 24 ); --inset-padding: 0vw; --row-height-scaling-factor: 0.0215; --container-width: min(var(--sqs-site-max-width, 1500px), calc(100vw - var(--sqs-site-gutter, 4vw) * 2 - var(--inset-padding) )); grid-template-rows: repeat(13,minmax(calc(var(--container-width) * var(--row-height-scaling-factor)), auto)); grid-template-columns: minmax(var(--grid-gutter), 1fr) repeat(24, minmax(0, var(--cell-max-width))) minmax(var(--grid-gutter), 1fr); } } .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/7/10; z-index: 1; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_2339 { grid-area: 1/2/2/26; z-index: 2; position: sticky; top: calc(0px + var(--header-fixed-top-offset, 0px)); } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_2339 .sqs-block-alignment-wrapper { align-items: flex-start; } } .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 7/2/13/10; z-index: 2; @media (max-width: 767px) { } } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } @media (min-width: 768px) { .fe-block-yui_3_17_2_1_1746825311996_3059 { grid-area: 2/2/7/26; z-index: 1; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block { justify-content: flex-start; } .fe-block-yui_3_17_2_1_1746825311996_3059 .sqs-block-alignment-wrapper { align-items: flex-start; } }",
    "job_apply_link": "https://www.agzen.com/jobs?gh_jid=4048593009",
    "job_posted_at_datetime_utc": "2025-10-21T00:25:19.000Z",
    "job_employment_type": "FULLTIME",
    "job_posted_at": "1h",
    "id": "agzen--cambridge",
    "description_platform": "generic",
    "description_success": true
  },
  {
    "job_title": "Policy Manager, Chemical Weapons and High Yield Explosives",
    "employer_name": "anthropic",
    "job_city": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5066951008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.Responsibilities: Design and implement evaluation methodologies for assessing AI model capabilities relevant to chemical weapons, explosives synthesis, and energetic materials Develop and execute strategies to identify and mitigate potential C/E misuse in model outputs Create C/E threat models, including precursor identification, synthesis routes, and weaponization techniques Review and analyze traffic to identify potential policy violations related to C/E content Collaborate with software engineers to develop and refine detection systems and automated enforcement tools for C/E threats Conduct rapid response to escalations involving dangerous C/E queries Collaborate across teams to establish safety benchmarks and develop appropriate model guardrails Translate C/E domain knowledge into actionable safety requirements Develop approaches to assess C/E model knowledge boundaries for dual-use chemical information Monitor emerging threats in the C/E landscape to inform policy development You may be a good fit if you: Have a Ph.D. in Chemistry, Chemical Engineering, or a related field with focus on energetic materials, explosives, and/or chemical weapons Have 5-8+ years of experience in chemical weapons and/or explosives defense, with deep expertise in energetic materials, chemical weapon agents, or related areas Have knowledge of high yield explosives application to radiological dispersal devices (dirty bombs) and related radiological weapons Have a track record of translating specialized technical knowledge into actionable safety policies or guidelines Are comfortable navigating ambiguity and developing solutions for novel safety challenges Can work independently while maintaining strong collaboration with cross-functional teams including engineering, enforcement, and research Thrive in a fast-paced environment where you balance rigorous scientific standards with rapid threat response Are passionate about preventing misuse of dangerous technical knowledge while enabling beneficial applications Strong candidates may have: Experience with both chemical weapons and high yield explosives defense Experience working with defense, intelligence, or nonproliferation organizations (e.g., OPCW, IAEA, national labs, defense contractors) Published research or practical experience in explosives characterization, chemical weapons detection, or related security applications Knowledge of international chemical weapons conventions (CWC) and controlled substances regulations Demonstrated ability to communicate complex technical concepts to non-specialist audiences Experience with chemical databases (PubChem, Reaxys, SciFinder) and computational chemistry tools Understanding of radiological materials and their interaction with explosive dispersal mechanisms Familiarity with dual-use C/E research concerns and responsible disclosure practices This role offers a unique opportunity to shape how AI systems handle sensitive chemical and explosives information. You'll work with leading AI safety researchers while tackling critical problems in preventing catastrophic misuse. If you're excited about using your expertise to ensure AI systems remain safe and beneficial, we want to hear from you.The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$245,000 - $285,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-policy-manager-chemical-weapons-and-high-yield-explosives-remote-friendly-travel-required-san-francisco-ca-washington-dc",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5066951008",
    "title": "Policy Manager, Chemical Weapons and High Yield Explosives",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC",
    "locations": [
      "Remote-Friendly (Travel-Required) | San Francisco, CA | Washington, DC"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5066951008",
    "departments": [
      "Safeguards (Trust & Safety) "
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and implement evaluation methodologies for assessing AI model capabilities relevant to chemical weapons, explosives synthesis, and energetic materials&lt;/li&gt;\n&lt;li&gt;Develop and execute strategies to identify and mitigate potential C/E misuse in model outputs&lt;/li&gt;\n&lt;li&gt;Create C/E threat models, including precursor identification, synthesis routes, and weaponization techniques&lt;/li&gt;\n&lt;li&gt;Review and analyze traffic to identify potential policy violations related to C/E content&lt;/li&gt;\n&lt;li&gt;Collaborate with software engineers to develop and refine detection systems and automated enforcement tools for C/E threats&lt;/li&gt;\n&lt;li&gt;Conduct rapid response to escalations involving dangerous C/E queries&lt;/li&gt;\n&lt;li&gt;Collaborate across teams to establish safety benchmarks and develop appropriate model guardrails&lt;/li&gt;\n&lt;li&gt;Translate C/E domain knowledge into actionable safety requirements&lt;/li&gt;\n&lt;li&gt;Develop approaches to assess C/E model knowledge boundaries for dual-use chemical information&lt;/li&gt;\n&lt;li&gt;Monitor emerging threats in the C/E landscape to inform policy development&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have a Ph.D. in Chemistry, Chemical Engineering, or a related field with focus on energetic materials, explosives, and/or chemical weapons&lt;/li&gt;\n&lt;li&gt;Have 5-8+ years of experience in chemical weapons and/or explosives defense, with deep expertise in energetic materials, chemical weapon agents, or related areas&lt;/li&gt;\n&lt;li&gt;Have knowledge of high yield explosives application to radiological dispersal devices (dirty bombs) and related radiological weapons&lt;/li&gt;\n&lt;li&gt;Have a track record of translating specialized technical knowledge into actionable safety policies or guidelines&lt;/li&gt;\n&lt;li&gt;Are comfortable navigating ambiguity and developing solutions for novel safety challenges&lt;/li&gt;\n&lt;li&gt;Can work independently while maintaining strong collaboration with cross-functional teams including engineering, enforcement, and research&lt;/li&gt;\n&lt;li&gt;Thrive in a fast-paced environment where you balance rigorous scientific standards with rapid threat response&lt;/li&gt;\n&lt;li&gt;Are passionate about preventing misuse of dangerous technical knowledge while enabling beneficial applications&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with both chemical weapons and high yield explosives defense&lt;/li&gt;\n&lt;li&gt;Experience working with defense, intelligence, or nonproliferation organizations (e.g., OPCW, IAEA, national labs, defense contractors)&lt;/li&gt;\n&lt;li&gt;Published research or practical experience in explosives characterization, chemical weapons detection, or related security applications&lt;/li&gt;\n&lt;li&gt;Knowledge of international chemical weapons conventions (CWC) and controlled substances regulations&lt;/li&gt;\n&lt;li&gt;Demonstrated ability to communicate complex technical concepts to non-specialist audiences&lt;/li&gt;\n&lt;li&gt;Experience with chemical databases (PubChem, Reaxys, SciFinder) and computational chemistry tools&lt;/li&gt;\n&lt;li&gt;Understanding of radiological materials and their interaction with explosive dispersal mechanisms&lt;/li&gt;\n&lt;li&gt;Familiarity with dual-use C/E research concerns and responsible disclosure practices&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;This role offers a unique opportunity to shape how AI systems handle sensitive chemical and explosives information. You&#39;ll work with leading AI safety researchers while tackling critical problems in preventing catastrophic misuse. If you&#39;re excited about using your expertise to ensure AI systems remain safe and beneficial, we want to hear from you.&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$245,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$285,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5066951008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Portfolio Activation Manager",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4985873008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Portfolio Activation Manager on Anthropic's Private Equity team, you'll build and scale programs that drive AI adoption across private equity portfolio companies. Working closely with Tier 1 PE firms, you'll design and execute scaled enablement programs—webinar series, onboarding cohorts, and hands-on workshops—that activate hundreds of portfolio companies with minimal human touch time. You'll partner with Value Creation and Operating Partner teams at PE firms to understand portfolio needs, then build automated, repeatable programs that drive bottom-up adoption of Claude products (Claude for Work, Claude Code, and API). This isn't a 1:1 customer success role—it's about designing systems and infrastructure that scale across entire portfolios, turning initial interest into active customers and engaged users. This is a new role and function at Anthropic. You'll take the foundation that our Commercial and PE GTM leaders have built and turn it into a repeatable playbook. You should be passionate about building at the intersection of program design, automation, and executive stakeholder management. Responsibilities: Design and execute scaled activation programs (webinars, onboarding cohorts, office hours, executive events) that reach hundreds of portfolio companies across multiple PE firms Develop portfolio-specific commercial strategies including preferred pricing models, contract terms, and growth initiatives aligned with PE firm objectives Own portfolio activation metrics including new customer acquisition, ARR growth, and product engagement across Claude for Work, Claude Code, and API Manage relationships with PE firm Operating Partners and Value Creation teams, delivering monthly business reviews and quarterly adoption reports Create enablement content, documentation, and training to help portfolio companies effectively utilize Claude products, and enable Account Executives to navigate PE portfolio dynamics Gather product feedback from portfolio companies and represent their needs to inform Anthropic's product roadmap and PE-specific features Plan and execute portfolio-focused events, campaigns, and promotions including on-site executive summits and virtual programming Coordinate with Account Executives to route qualified leads from portfolio companies and ensure smooth handoffs Track and report on key metrics to measure the success and ROI of portfolio activation initiatives Continuously refine programs based on data, feedback, and portfolio company outcomes, building a repeatable playbook that scales across firms You may be a good fit if you: Have 5-7 years of experience in B2B SaaS program management, partnerships, sales enablement, revenue operations, or customer education with a proven track record of building scaled programs Possess strong automation skills and systems thinking—you're comfortable building workflows and infrastructure that eliminate manual work Have experience presenting to and managing relationships with senior executives (VP+ level), translating technical concepts into business value Demonstrate a track record of moving fast in ambiguous environments and launching programs quickly with imperfect information Are comfortable working with technical products and developer tools—you don't need to code, but you should understand AI concepts well enough to explain them clearly Show self-sufficiency and resourcefulness—you can pull together content, coordinate across teams, and execute without constant oversight Possess analytical orientation toward metrics and a bias toward measuring what matters (pipeline, revenue, adoption) vs. vanity metrics Have exceptional communication and relationship-building skills with both technical and business audiences Can thrive in a fast-paced environment and adapt to changing priorities Are passionate about the positive impact that AI can have for businesses and society as a whole Strong candidates may have: Direct experience working with private equity firms, portfolio companies, or leading partnership programs at a major technology company Existing relationships with PE Operating Partners, Value Creation teams, or portfolio company executives Experience developing commercial terms, pricing strategies, or partnership agreements Background in developer tools, infrastructure, or technical B2B products Prior sales operations, revenue operations, or sales enablement experience with a focus on enabling sales teams on complex technical products Familiarity with large language models and their applications in areas like code modernization, software development, and business automation Technical background in computer science, software engineering, or related field MBA or advanced degree in relevant discipline The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$200,000 - $260,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-portfolio-activation-manager-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4985873008",
    "title": "Portfolio Activation Manager",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4985873008",
    "departments": [
      "Sales"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a Portfolio Activation Manager on Anthropic&#39;s Private Equity team, you&#39;ll build and scale programs that drive AI adoption across private equity portfolio companies. Working closely with Tier 1 PE firms, you&#39;ll design and execute scaled enablement programs—webinar series, onboarding cohorts, and hands-on workshops—that activate hundreds of portfolio companies with minimal human touch time.&lt;/p&gt;\n&lt;p&gt;You&#39;ll partner with Value Creation and Operating Partner teams at PE firms to understand portfolio needs, then build automated, repeatable programs that drive bottom-up adoption of Claude products (Claude for Work, Claude Code, and API). This isn&#39;t a 1:1 customer success role—it&#39;s about designing systems and infrastructure that scale across entire portfolios, turning initial interest into active customers and engaged users.&lt;/p&gt;\n&lt;p&gt;This is a new role and function at Anthropic. You&#39;ll take the foundation that our Commercial and PE GTM leaders have built and turn it into a repeatable playbook. You should be passionate about building at the intersection of program design, automation, and executive stakeholder management.&lt;/p&gt;\n&lt;h2&gt;Responsibilities:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design and execute scaled activation programs (webinars, onboarding cohorts, office hours, executive events) that reach hundreds of portfolio companies across multiple PE firms&lt;/li&gt;\n&lt;li&gt;Develop portfolio-specific commercial strategies including preferred pricing models, contract terms, and growth initiatives aligned with PE firm objectives&lt;/li&gt;\n&lt;li&gt;Own portfolio activation metrics including new customer acquisition, ARR growth, and product engagement across Claude for Work, Claude Code, and API&lt;/li&gt;\n&lt;li&gt;Manage relationships with PE firm Operating Partners and Value Creation teams, delivering monthly business reviews and quarterly adoption reports&lt;/li&gt;\n&lt;li&gt;Create enablement content, documentation, and training to help portfolio companies effectively utilize Claude products, and enable Account Executives to navigate PE portfolio dynamics&lt;/li&gt;\n&lt;li&gt;Gather product feedback from portfolio companies and represent their needs to inform Anthropic&#39;s product roadmap and PE-specific features&lt;/li&gt;\n&lt;li&gt;Plan and execute portfolio-focused events, campaigns, and promotions including on-site executive summits and virtual programming&lt;/li&gt;\n&lt;li&gt;Coordinate with Account Executives to route qualified leads from portfolio companies and ensure smooth handoffs&lt;/li&gt;\n&lt;li&gt;Track and report on key metrics to measure the success and ROI of portfolio activation initiatives&lt;/li&gt;\n&lt;li&gt;Continuously refine programs based on data, feedback, and portfolio company outcomes, building a repeatable playbook that scales across firms&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have 5-7 years of experience in B2B SaaS program management, partnerships, sales enablement, revenue operations, or customer education with a proven track record of building scaled programs&lt;/li&gt;\n&lt;li&gt;Possess strong automation skills and systems thinking—you&#39;re comfortable building workflows and infrastructure that eliminate manual work&lt;/li&gt;\n&lt;li&gt;Have experience presenting to and managing relationships with senior executives (VP+ level), translating technical concepts into business value&lt;/li&gt;\n&lt;li&gt;Demonstrate a track record of moving fast in ambiguous environments and launching programs quickly with imperfect information&lt;/li&gt;\n&lt;li&gt;Are comfortable working with technical products and developer tools—you don&#39;t need to code, but you should understand AI concepts well enough to explain them clearly&lt;/li&gt;\n&lt;li&gt;Show self-sufficiency and resourcefulness—you can pull together content, coordinate across teams, and execute without constant oversight&lt;/li&gt;\n&lt;li&gt;Possess analytical orientation toward metrics and a bias toward measuring what matters (pipeline, revenue, adoption) vs. vanity metrics&lt;/li&gt;\n&lt;li&gt;Have exceptional communication and relationship-building skills with both technical and business audiences&lt;/li&gt;\n&lt;li&gt;Can thrive in a fast-paced environment and adapt to changing priorities&lt;/li&gt;\n&lt;li&gt;Are passionate about the positive impact that AI can have for businesses and society as a whole&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Direct experience working with private equity firms, portfolio companies, or leading partnership programs at a major technology company&lt;/li&gt;\n&lt;li&gt;Existing relationships with PE Operating Partners, Value Creation teams, or portfolio company executives&lt;/li&gt;\n&lt;li&gt;Experience developing commercial terms, pricing strategies, or partnership agreements&lt;/li&gt;\n&lt;li&gt;Background in developer tools, infrastructure, or technical B2B products&lt;/li&gt;\n&lt;li&gt;Prior sales operations, revenue operations, or sales enablement experience with a focus on enabling sales teams on complex technical products&lt;/li&gt;\n&lt;li&gt;Familiarity with large language models and their applications in areas like code modernization, software development, and business automation&lt;/li&gt;\n&lt;li&gt;Technical background in computer science, software engineering, or related field&lt;/li&gt;\n&lt;li&gt;MBA or advanced degree in relevant discipline&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$200,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$260,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4985873008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Privacy Counsel",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4980527008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Anthropic is seeking a Privacy Counsel to join our Legal team. The ideal candidate will have a strong background in counseling complex privacy issues, with a proven track record of building robust processes and programs to address complex privacy and data protection issues in a global context. This is a unique opportunity to join a dynamic and growing team, where you will have the chance to shape the company's privacy and data protection strategy and compliance program. If you are a collaborative, results-driven professional with a passion for privacy and a desire to make a real impact, we would love to hear from you. Responsibilities: Develop and implement comprehensive privacy strategies that align with the technology, product, and services Anthropic is building and our overall company goals Provide expert legal advice and guidance on privacy and data protection law (including state and federal privacy and consumer protection laws, GDPR and other international privacy laws) Work with cross-functional teams to design and implement privacy-by-design principles in product development, particularly in the realm of general purpose AI models and systems Collaborate with frontier counsel and product counsel to integrate privacy considerations into model development and product planning Maintain relationships with key regulators and stay abreast of emerging legal and regulatory developments in the global privacy landscape Collaborate closely with our privacy program team on the maintenance and maturation of our global privacy compliance program, governance framework, accountability documentation, internal and external policies and related training You may be a good fit if you have: A JD and active membership in at least one U.S. state bar (California preferred) At least 8 years of global privacy and data protection legal experience, preferably in hyper-growth global technology environments Deep subject matter expertise in privacy and data protection law and its practical application in a global context Extensive experience advising on privacy, data protection, and direct marketing laws, regulations, and guidance Strong understanding of the interplay between privacy, security, and AI, and the ability to provide strategic guidance in these areas Excellent leadership skills and the ability to drive projects forward in a fast-paced, hands-on environment Exceptional communication and stakeholder management skills, with the ability to build strong relationships with regulators, internal teams, and external partners A proven ability to think strategically and translate complex legal concepts into practical business solutions Strong candidates may have: Experience with privacy regulations in other international jurisdictions, enabling them to support the organization's global data protection compliance efforts Experience with privacy-enhancing technologies and their implementation in a business setting Knowledge and experience with AI-specific regulations and their interplay with privacy frameworks A network of contacts within the data protection community, allowing them to stay informed about best practices and share knowledge with peers Role-specific policy: For this role, we expect all staff to be able to work from our San Francisco office at least 3 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of timeThe annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$265,000 - $320,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-privacy-counsel-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4980527008",
    "title": "Privacy Counsel",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4980527008",
    "departments": [
      "Legal"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is seeking a Privacy Counsel to join our Legal team. The ideal candidate will have a strong background in counseling complex privacy issues, with a proven track record of building robust processes and programs to address complex privacy and data protection issues in a global context. This is a unique opportunity to join a dynamic and growing team, where you will have the chance to shape the company&#39;s privacy and data protection strategy and compliance program. If you are a collaborative, results-driven professional with a passion for privacy and a desire to make a real impact, we would love to hear from you.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Develop and implement comprehensive privacy strategies that align with the technology, product, and services Anthropic is building and our overall company goals&lt;/li&gt;\n&lt;li&gt;Provide expert legal advice and guidance on privacy and data protection law (including state and federal privacy and consumer protection laws, GDPR and other international privacy laws)&lt;/li&gt;\n&lt;li&gt;Work with cross-functional teams to design and implement privacy-by-design principles in product development, particularly in the realm of general purpose AI models and systems&lt;/li&gt;\n&lt;li&gt;Collaborate with frontier counsel and product counsel to integrate privacy considerations into model development and product planning&lt;/li&gt;\n&lt;li&gt;Maintain relationships with key regulators and stay abreast of emerging legal and regulatory developments in the global privacy landscape&lt;/li&gt;\n&lt;li&gt;Collaborate closely with our privacy program team on the maintenance and maturation of our global privacy compliance program, governance framework, accountability documentation, internal and external policies and related training&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;A JD and active membership in at least one U.S. state bar (California preferred)&lt;/li&gt;\n&lt;li&gt;At least 8 years of global privacy and data protection legal experience, preferably in hyper-growth global technology environments&lt;/li&gt;\n&lt;li&gt;Deep subject matter expertise in privacy and data protection law and its practical application in a global context&lt;/li&gt;\n&lt;li&gt;Extensive experience advising on privacy, data protection, and direct marketing laws, regulations, and guidance&lt;/li&gt;\n&lt;li&gt;Strong understanding of the interplay between privacy, security, and AI, and the ability to provide strategic guidance in these areas&lt;/li&gt;\n&lt;li&gt;Excellent leadership skills and the ability to drive projects forward in a fast-paced, hands-on environment&lt;/li&gt;\n&lt;li&gt;Exceptional communication and stakeholder management skills, with the ability to build strong relationships with regulators, internal teams, and external partners&lt;/li&gt;\n&lt;li&gt;A proven ability to think strategically and translate complex legal concepts into practical business solutions&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience with privacy regulations in other international jurisdictions, enabling them to support the organization&#39;s global data protection compliance efforts&lt;/li&gt;\n&lt;li&gt;Experience with privacy-enhancing technologies and their implementation in a business setting&lt;/li&gt;\n&lt;li&gt;Knowledge and experience with AI-specific regulations and their interplay with privacy frameworks&lt;/li&gt;\n&lt;li&gt;A network of contacts within the data protection community, allowing them to stay informed about best practices and share knowledge with peers&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;strong&gt;Role-specific policy:&amp;nbsp;&lt;/strong&gt;For this role, we expect all staff to be able to work from our San Francisco office at least 3 days a week, though we encourage you to apply even if you might need some flexibility for an interim period of time&lt;/p&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$265,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$320,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4980527008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Privacy Research Engineer, Safeguards",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4949108008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role We are looking for researchers to help mitigate the risks that come with building AI systems. One of these risks is the potential for models to interact with private user data. In this role, you'll design and implement privacy-preserving techniques, audit our current techniques, and set the direction for how Anthropic handles privacy more broadly. Responsibilities: Lead our privacy analysis of frontier models, carefully auditing the use of data and ensuring safety throughout the process Develop privacy-first training algorithms and techniques Develop evaluation and auditing techniques to measure the privacy of training algorithms Work with a small, senior team of engineers and researchers to enact a forward-looking privacy policy Advocate on behalf of our users to ensure responsible handling of all data You may be a good fit if you have: Experience working on privacy-preserving machine learning A track record of shipping products and features inside a fast-moving environment Strong coding skills in Python and familiarity with ML frameworks like PyTorch or JAX. Deep familiarity with large language models, how they work, and how they are trained Have experience working with privacy-preserving techniques (e.g., differential privacy and how it is different from k-anonymity, l-diversity, and t-closeness) Experience supporting fast-paced startup engineering teams Demonstrated success in bringing clarity and ownership to ambiguous technical problems Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics Strong candidates may also: Have published papers on the topic of privacy-preserving ML at top academic venues Prior experience training large language models (e.g., collecting training datasets, pre-training models, post-training models via fine-tuning and RL, running evaluations on trained models) Prior experience developing tooling to support privacy-preserving ML (e.g., differential privacy in TF-Privacy or Opacus) The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$320,000 - $485,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-privacy-research-engineer-safeguards-san-francisco-ca",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4949108008",
    "title": "Privacy Research Engineer, Safeguards",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA",
    "locations": [
      "San Francisco, CA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4949108008",
    "departments": [
      "AI Research & Engineering"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We are looking for researchers to help mitigate the risks that come with building AI systems. One of these risks is the potential for models to interact with private user data. In this role, you&#39;ll design and implement privacy-preserving techniques, audit our current techniques, and set the direction for how Anthropic handles privacy more broadly.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Lead our privacy analysis of frontier models, carefully auditing the use of data and ensuring safety throughout the process&lt;/li&gt;\n&lt;li&gt;Develop privacy-first training algorithms and techniques&lt;/li&gt;\n&lt;li&gt;Develop evaluation and auditing techniques to measure the privacy of training algorithms&lt;/li&gt;\n&lt;li&gt;Work with a small, senior team of engineers and researchers to enact a forward-looking privacy policy&lt;/li&gt;\n&lt;li&gt;Advocate on behalf of our users to ensure responsible handling of all data&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience working on privacy-preserving machine learning&lt;/li&gt;\n&lt;li&gt;A track record of shipping products and features inside a fast-moving environment&lt;/li&gt;\n&lt;li&gt;Strong coding skills in Python and familiarity with ML frameworks like PyTorch or JAX.&lt;/li&gt;\n&lt;li&gt;Deep familiarity with large language models, how they work, and how they are trained&lt;/li&gt;\n&lt;li&gt;Have experience working with privacy-preserving techniques (e.g., differential privacy and how it is different from k-anonymity, l-diversity, and t-closeness)&lt;/li&gt;\n&lt;li&gt;Experience supporting fast-paced startup engineering teams&lt;/li&gt;\n&lt;li&gt;Demonstrated success in bringing clarity and ownership to ambiguous technical problems&lt;/li&gt;\n&lt;li&gt;Proven ability to lead cross-functional security initiatives and navigate complex organizational dynamics&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;Strong candidates may also:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Have published papers on the topic of privacy-preserving ML at top academic venues&lt;/li&gt;\n&lt;li&gt;Prior experience training large language models (e.g., collecting training datasets, pre-training models, post-training models via fine-tuning and RL, running evaluations on trained models)&lt;/li&gt;\n&lt;li&gt;Prior experience developing tooling to support privacy-preserving ML (e.g., differential privacy in TF-Privacy or Opacus)&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$320,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$485,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4949108008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Designer, Claude Code ",
    "employer_name": "anthropic",
    "job_city": "New York City, NY; Remote-Friendly (Travel Required) | San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5025976008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role In the Product Designer, Claude Code role, you'll: Design for agentic workflows across surfaces. Own the experience of Claude Code across terminal, IDE extensions, web, and Slack. Design how Claude communicates progress, requests permissions, handles failures, and coordinates multi-step autonomous work. Invent new interaction patterns. Claude Code is intentionally low-level and unopinionated—a power tool for sophisticated users. Design conventions that respect developer expertise while making complex agentic behaviors feel intuitive and trustworthy. Prototype in code. This is a developer tool. You'll work directly with terminal interfaces, understand CLI constraints, and build functional prototypes. The best ideas will come from hands-on exploration, not just mockups. Ship fast and iterate. Claude Code moves quickly—new capabilities ship constantly as models improve. You'll need to design, test, and refine in tight cycles, often on critical-path work for major launches. Work fluidly across the team. Partner with engineering, research, and product without needing clear handoffs or defined lanes. Jump into problems wherever you're useful—whether that's pairing with an engineer on implementation details, exploring a new model capability with a researcher, or pressure-testing an idea with users directly. Raise the bar on craft. Obsess over the details that make power tools feel right: information density, speed, keyboard-first interaction, clear feedback loops, minimal friction. Why this role matters: Claude Code started as a research project and became one of Anthropic's most successful products, generating over $1B in annualized revenue within six months of launch. It redefined how developers work, and we're just getting started. This is genuinely new territory. We're designing the future of coding — Claude working autonomously on tasks, making decisions, asking for input when needed, and coordinating with humans throughout. The interaction patterns for this don't exist yet. We need to invent them. The product is expanding fast: from terminal to VS Code and JetBrains IDEs, to web, to Slack. Each surface brings new design challenges. And the underlying models keep getting more capable, which means the design problems keep evolving. We need designers who can move as fast as the technology—people who are excited by the ambiguity, not frustrated by it. You might be a great fit if: You live at the intersection of code and design. You genuinely enjoy developer tools and tinker with new things for fun. This role will shape how developers experience agentic coding—not just at Anthropic, but across the industry.. You're a tinkerer and explorer. You try new tools before anyone asks you to. You have opinions about terminal emulators and keyboard shortcuts. You're energized by where AI is headed—and want to be part of figuring out what comes next. Bonus points: Experience designing for command-line interfaces, IDEs or other dev tools Contributions to open source projects or developer tools Understanding of how LLMs work and their current capabilities/limitations A GitHub profile, personal site, or side projects that show what you build when no one's asking The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$260,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-designer-claude-code-new-york-city-ny-remote-friendly-travel-required-san-francisco-ca-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5025976008",
    "title": "Product Designer, Claude Code ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "New York City, NY; Remote-Friendly (Travel Required) | San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "New York City, NY; Remote-Friendly (Travel Required) | San Francisco, CA; San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5025976008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;In the Product Designer, Claude Code role, you&#39;ll:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Design for agentic workflows across surfaces.&lt;/strong&gt; Own the experience of Claude Code across terminal, IDE extensions, web, and Slack. Design how Claude communicates progress, requests permissions, handles failures, and coordinates multi-step autonomous work.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Invent new interaction patterns.&lt;/strong&gt; Claude Code is intentionally low-level and unopinionated—a power tool for sophisticated users. Design conventions that respect developer expertise while making complex agentic behaviors feel intuitive and trustworthy.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Prototype in code.&lt;/strong&gt; This is a developer tool. You&#39;ll work directly with terminal interfaces, understand CLI constraints, and build functional prototypes. The best ideas will come from hands-on exploration, not just mockups.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ship fast and iterate.&lt;/strong&gt; Claude Code moves quickly—new capabilities ship constantly as models improve. You&#39;ll need to design, test, and refine in tight cycles, often on critical-path work for major launches.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Work fluidly across the team.&lt;/strong&gt; Partner with engineering, research, and product without needing clear handoffs or defined lanes. Jump into problems wherever you&#39;re useful—whether that&#39;s pairing with an engineer on implementation details, exploring a new model capability with a researcher, or pressure-testing an idea with users directly.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Raise the bar on craft.&lt;/strong&gt; Obsess over the details that make power tools feel right: information density, speed, keyboard-first interaction, clear feedback loops, minimal friction.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Why this role matters:&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Claude Code started as a research project and became one of Anthropic&#39;s most successful products, generating over $1B in annualized revenue within six months of launch. It redefined how developers work, and we&#39;re just getting started.&lt;/p&gt;\n&lt;p&gt;This is genuinely new territory. We&#39;re designing the &lt;em&gt;future of coding &lt;/em&gt;— Claude working autonomously on tasks, making decisions, asking for input when needed, and coordinating with humans throughout. The interaction patterns for this don&#39;t exist yet. We need to invent them.&lt;/p&gt;\n&lt;p&gt;The product is expanding fast: from terminal to VS Code and JetBrains IDEs, to web, to Slack. Each surface brings new design challenges. And the underlying models keep getting more capable, which means the design problems keep evolving. We need designers who can move as fast as the technology—people who are excited by the ambiguity, not frustrated by it.&lt;/p&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;You might be a great fit if:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;You live at the intersection of code and design&lt;/strong&gt;. You genuinely enjoy developer tools and tinker with new things for fun. This role will shape how developers experience agentic coding—not just at Anthropic, but across the industry..&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;You&#39;re a tinkerer and explorer.&lt;/strong&gt; You try new tools before anyone asks you to. You have opinions about terminal emulators and keyboard shortcuts. You&#39;re energized by where AI is headed—and want to be part of figuring out what comes next.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 class=&quot;heading&quot;&gt;&lt;strong&gt;Bonus points:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Experience designing for command-line interfaces, IDEs or other dev tools&lt;/li&gt;\n&lt;li&gt;Contributions to open source projects or developer tools&lt;/li&gt;\n&lt;li&gt;Understanding of how LLMs work and their current capabilities/limitations&lt;/li&gt;\n&lt;li&gt;A GitHub profile, personal site, or side projects that show what you build when no one&#39;s asking&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5025976008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Designer, Claude Developer Platform",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5055448008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a Designer for Claude Developer Platform at Anthropic, you'll shape how developers experience our API products—from the Console and documentation to Workbench and beyond. This role focuses on the core developer platform, including: Make building and maintaining high-quality applications with the Anthropic API frictionless. Support frontier capabilities and API features via tooling, workflows, and documentation. Design best-in-class admin experiences for API utilities like billing, usage, and access management. Define the future suite of utilities for developers to confidently build, monitor and control agentic systems. As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator: We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs. Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy. Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility. We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement. Read more here for the type of features we build. Responsibilities: Contribute to the strategic direction of our tools, rooted in deep user empathy Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps Rapidly prototype ideas using code and other methods to communicate concepts and build excitement Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment You may be a good fit if you have: 8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred) Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred Strong candidates may: Ship opinionated products and make things customers want. Model a builder mindset to explore and communicate through prototyping and design. Build trust with users through craft and connection. Be proactive and make things happen in a startup environment Have a technical understanding of LLMs and can build on top of them. Design new, functional and easy to use interaction design conventions that are on the frontier. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$260,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-designer-claude-developer-platform-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5055448008",
    "title": "Product Designer, Claude Developer Platform",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5055448008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;As a &lt;strong&gt;Designer for Claude Developer Platform&lt;/strong&gt; at Anthropic, you&#39;ll shape how developers experience our API products—from the Console and documentation to Workbench and beyond. This role focuses on the core developer platform, including:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Make building and maintaining high-quality applications with the Anthropic API frictionless.&amp;nbsp;&lt;/li&gt;\n&lt;li&gt;Support frontier capabilities and API features via tooling, workflows, and documentation.&lt;/li&gt;\n&lt;li&gt;Design best-in-class admin experiences for API utilities like billing, usage, and access management.&lt;/li&gt;\n&lt;li&gt;Define the future suite of utilities for developers to confidently build, monitor and control agentic systems.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more &lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&amp;nbsp;&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Contribute to the strategic direction of our tools, rooted in deep user empathy&lt;/li&gt;\n&lt;li&gt;Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows&lt;/li&gt;\n&lt;li&gt;Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology&lt;/li&gt;\n&lt;li&gt;Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps&lt;/li&gt;\n&lt;li&gt;Rapidly prototype ideas using code and other methods to communicate concepts and build excitement&lt;/li&gt;\n&lt;li&gt;Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5055448008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Designer, Enterprise ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5055600008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator: We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs. Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy. Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility. We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement. Read more here for the type of features we build. Responsibilities: Build expertise in industries like education, financial services, and healthcare to design intuitive experiences that help people leverage AI at work in transformative ways. Remove enterprise adoption barriers and create solutions to help companies realize value quickly. Build intuitive tooling to ensure the successful rollout of Claude to large organizations. Design intuitive and scalable self-serve solutions. Improve understanding & help employees learn how to use Claude to gain value faster. Contribute to the strategic direction of our tools, rooted in deep user empathy Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps Rapidly prototype ideas using code and other methods to communicate concepts and build excitement Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment You may be a good fit if you have: 8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred) Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred Strong candidates may: Ship opinionated products and make things customers want. Model a builder mindset to explore and communicate through prototyping and design. Build trust with users through craft and connection. Be proactive and make things happen in a startup environment Have a technical understanding of LLMs and can build on top of them. Design new, functional and easy to use interaction design conventions that are on the frontier. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$305,000 - $385,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-designer-enterprise-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5055600008",
    "title": "Product Designer, Enterprise ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5055600008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more&amp;nbsp;&lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Build expertise in industries like education, financial services, and healthcare to design intuitive experiences that help people leverage AI at work in transformative ways.&lt;/li&gt;\n&lt;li&gt;Remove enterprise adoption barriers and create solutions to help companies realize value quickly.&lt;/li&gt;\n&lt;li&gt;Build intuitive tooling to ensure the successful rollout of Claude to large organizations.&lt;/li&gt;\n&lt;li&gt;Design intuitive and scalable self-serve solutions.&lt;/li&gt;\n&lt;li&gt;Improve understanding &amp;amp; help employees learn how to use Claude to gain value faster.&lt;/li&gt;\n&lt;li&gt;Contribute to the strategic direction of our tools, rooted in deep user empathy&lt;/li&gt;\n&lt;li&gt;Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows&lt;/li&gt;\n&lt;li&gt;Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology&lt;/li&gt;\n&lt;li&gt;Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps&lt;/li&gt;\n&lt;li&gt;Rapidly prototype ideas using code and other methods to communicate concepts and build excitement&lt;/li&gt;\n&lt;li&gt;Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$305,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$385,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5055600008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Designer, Growth ",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY | Seattle, WA",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/4963443008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the role As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator: We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs. Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy. Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility. We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement. Read more here for the type of features we build. Responsibilities: Design intuitive onboarding flows that help new users get started quickly, understand Claude's capabilities, and achieve their goals in the first session. Create scalable education systems that help people deepen their understanding of Claude over time and seamlessly integrate it into their workflows Design clear, trust-building upgrade experiences that help users understand the right plan for their needs. Uncover barriers that prevent users from getting the most out of Claude and create experiences that empower them to make it a trusted part of their routine. Contribute to the strategic direction of our tools, rooted in deep user empathy Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps Rapidly prototype ideas using code and other methods to communicate concepts and build excitement Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment You may be a good fit if you have: 8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred) Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred Strong candidates may: Ship opinionated products and make things customers want. Model a builder mindset to explore and communicate through prototyping and design. Build trust with users through craft and connection. Be proactive and make things happen in a startup environment Have a technical understanding of LLMs and can build on top of them. Design new, functional and easy to use interaction design conventions that are on the frontier. The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$260,000 - $305,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-designer-growth-san-francisco-ca-new-york-city-ny-seattle-wa",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "4963443008",
    "title": "Product Designer, Growth ",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY | Seattle, WA",
    "locations": [
      "San Francisco, CA | New York City, NY | Seattle, WA"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/4963443008",
    "departments": [
      "Engineering & Design - Product"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;About the role&lt;/h2&gt;\n&lt;p&gt;As a designer at Anthropic, you’ll work alongside product managers, engineers, and AI researchers to shape experiences that transform Claude from a tool into a trusted collaborator:&amp;nbsp;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;We design products that solve real problems by combining deep understanding of user needs with our unique perspective on LLMs.&lt;/li&gt;\n&lt;li&gt;Design plays a critical role in building transformative AI systems that feel reliable, interpretable, and trustworthy.&lt;/li&gt;\n&lt;li&gt;Designers give shape to our vision for tremendous human progress through AI. We leverage unique skills like storytelling and prototyping to communicate ideas and their feasibility.&lt;/li&gt;\n&lt;li&gt;We execute on interaction and visual details with a high degree of polish, focusing on shipping, learning, and continuous improvement.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;Read more&amp;nbsp;&lt;a href=&quot;https://www.anthropic.com/news&quot;&gt;here&lt;/a&gt; for the type of features we build.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Design intuitive onboarding flows that help new users get started quickly, understand Claude&#39;s capabilities, and achieve their goals in the first session.&lt;/li&gt;\n&lt;li&gt;Create scalable education systems that help people deepen their understanding of Claude over time and seamlessly integrate it into their workflows&lt;/li&gt;\n&lt;li&gt;Design clear, trust-building upgrade experiences that help users understand the right plan for their needs.&lt;/li&gt;\n&lt;li&gt;Uncover barriers that prevent users from getting the most out of Claude and create experiences that empower them to make it a trusted part of their routine.&lt;/li&gt;\n&lt;li&gt;Contribute to the strategic direction of our tools, rooted in deep user empathy&lt;/li&gt;\n&lt;li&gt;Define feature areas with exceptional attention to detail and polish, identifying opportunities to improve quality and consistency of broader flows&lt;/li&gt;\n&lt;li&gt;Craft beautiful, polished, and delightful user interfaces that build trust and showcase the power of our AI technology&lt;/li&gt;\n&lt;li&gt;Collaborate with product managers, engineers, AI researchers and other stakeholders to define product vision, strategy and roadmaps&lt;/li&gt;\n&lt;li&gt;Rapidly prototype ideas using code and other methods to communicate concepts and build excitement&lt;/li&gt;\n&lt;li&gt;Find creative ways to ship high-quality work in a fast-paced, often ambiguous, resource-constrained startup environment&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;You may be a good fit if you have:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;8+ years of product design experience (experience designing complex workflows, enterprise/B2B SaaS, developer tools, or API products preferred)&lt;/li&gt;\n&lt;li&gt;Strong portfolio showcasing user-centric design thinking, polished UI craftsmanship, and innovative interaction paradigms&lt;/li&gt;\n&lt;li&gt;Proven track record of executing end-to-end on large and complex products or a series of products in ambiguous environments&lt;/li&gt;\n&lt;li&gt;Excellent collaboration and communication skills to work effectively with cross-functional teams and influence without authority&lt;/li&gt;\n&lt;li&gt;Passion for crafting scaled, highly impactful, safe and beneficial artificial intelligence technologies to enable new possibilities&lt;/li&gt;\n&lt;li&gt;Experience with prototyping, especially using front-end code (e.g. HTML/CSS/JS) preferred&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;Strong candidates may:&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Ship opinionated products and make things customers want.&lt;/li&gt;\n&lt;li&gt;Model a builder mindset to explore and communicate through prototyping and design.&lt;/li&gt;\n&lt;li&gt;Build trust with users through craft and connection.&lt;/li&gt;\n&lt;li&gt;Be proactive and make things happen in a startup environment&lt;/li&gt;\n&lt;li&gt;Have a technical understanding of LLMs and can build on top of them.&lt;/li&gt;\n&lt;li&gt;Design new, functional and easy to use interaction design conventions that are on the frontier.&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$260,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$305,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 4963443008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  },
  {
    "job_title": "Product Lead, Consumer",
    "employer_name": "anthropic",
    "job_city": "San Francisco, CA | New York City, NY",
    "job_apply_link": "https://job-boards.greenhouse.io/anthropic/jobs/5042055008",
    "job_posted_at_datetime_utc": "2026-01-14T13:17:10-05:00",
    "job_description": "About Anthropic Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.About the Role Our goal is to build AI that millions of people use every day—to think, create, learn, and accomplish what matters to them. As Head of Consumer Product at Anthropic, you will be a key strategic leader driving our consumer product vision and bringing Claude to everyone. We're looking for an exceptional product leader who has built consumer products at scale, deeply understands what makes experiences intuitive and indispensable, ships products that people love and tell their friends about, and is eager to dive into everything from interaction design to retention strategy. The best candidates will be extremely hands-on, obsessed with user experience, and opinionated about a future where AI genuinely improves people's daily lives. You'll work on new consumer experiences at the frontier of what's possible with AI. You'll partner with research, design, and engineering to translate breakthrough model capabilities into products people actually want to use. Ultimately you'll help us build the AI assistant that millions of people choose for their most important work and creative pursuits. Responsibilities: Strategic Leadership: Own the complete vision for how consumers experience Claude—from core chat interactions to new modalities, features, and form factors that make AI useful across every context of daily life. User Champion: Deeply understand what drives people to try, love, and recommend Claude. Build feedback systems that surface user needs, identify friction, and inform product priorities. Drive sustainable growth through product excellence. Consumer Product Excellence: Ship experiences that feel considered: intuitive interactions, thoughtful defaults, and capabilities that surprise and delight. Obsess over the details that create products people love—onboarding flows, error states, performance, and polish. Product Execution at Scale: Partner with engineering and design on products serving millions of daily users. Navigate the unique challenges of consumer AI: managing user expectations, building trust, ensuring safety, and creating experiences that work for everyone from students to professionals to casual users. Research Partnership: Work closely with research to identify which model capabilities will most delight users. Partner with trust & safety to build products that are both capable and responsible. Collaborate with marketing and communications to tell Claude's story authentically. You may be a good fit if you have: 10+ years of progressive experience in product management, including at least 5 years in senior roles leading consumer products Track record of building consumer products with millions of users that people genuinely love Appreciation for the responsibility that comes with building AI products people rely on daily Deep experience with consumer growth, retention, and engagement and opinions about what metrics actually matter Strong design sensibility and experience partnering closely with design teams on consumer experiences Experience building products where user trust and safety are core to the value proposition Experience with AI or ML-powered products and a perspective on how AI will change consumer software Demonstrated success building and leading high-performing product teams Comfort with ambiguity and the ability to define product direction in a fast-moving, novel space User-obsessed mindset with a habit of talking to users directly and frequently Experience across multiple platforms (web, mobile, desktop) and an understanding of how context shapes product design The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (\"OTE\") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.Annual Salary:$385,000 - $460,000 USDLogistics Education requirements: We require at least a Bachelor's degree in a related field or equivalent experience.Location-based hybrid policy: Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices. Visa sponsorship: We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this. We encourage you to apply even if you do not believe you meet every single qualification. Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.Your safety matters to us. To protect yourself from potential scams, remember that Anthropic recruiters only contact you from @anthropic.com email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you're ever unsure about a communication, don't click any links—visit anthropic.com/careers directly for confirmed position openings. How we're different We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills. The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences. Come work with us! Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on Candidates' AI Usage: Learn about our policy for using AI in our application process",
    "id": "anthropic-product-lead-consumer-san-francisco-ca-new-york-city-ny",
    "source": "greenhouse",
    "source_url": "boards-api.greenhouse.io",
    "source_id": "5042055008",
    "title": "Product Lead, Consumer",
    "company_name": "anthropic",
    "company_slug": "anthropic",
    "location": "San Francisco, CA | New York City, NY",
    "locations": [
      "San Francisco, CA | New York City, NY"
    ],
    "url": "https://job-boards.greenhouse.io/anthropic/jobs/5042055008",
    "departments": [
      "Product Management, Support, & Operations"
    ],
    "employment_type": null,
    "posted_at": "2026-01-14T13:17:10-05:00",
    "fetched_at": "2026-01-17T04:05:13.932Z",
    "description": "&lt;div class=&quot;content-intro&quot;&gt;&lt;h2&gt;&lt;strong&gt;About Anthropic&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic’s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.&lt;/p&gt;&lt;/div&gt;&lt;h2&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Our goal is to build AI that millions of people use every day—to think, create, learn, and accomplish what matters to them. As Head of Consumer Product at Anthropic, you will be a key strategic leader driving our consumer product vision and bringing Claude to everyone.&lt;/p&gt;\n&lt;p&gt;We&#39;re looking for an exceptional product leader who has built consumer products at scale, deeply understands what makes experiences intuitive and indispensable, ships products that people love and tell their friends about, and is eager to dive into everything from interaction design to retention strategy. The best candidates will be extremely hands-on, obsessed with user experience, and opinionated about a future where AI genuinely improves people&#39;s daily lives.&lt;/p&gt;\n&lt;p&gt;You&#39;ll work on new consumer experiences at the frontier of what&#39;s possible with AI. You&#39;ll partner with research, design, and engineering to translate breakthrough model capabilities into products people actually want to use. Ultimately you&#39;ll help us build the AI assistant that millions of people choose for their most important work and creative pursuits.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Responsibilities:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Strategic Leadership:&lt;/strong&gt; Own the complete vision for how consumers experience Claude—from core chat interactions to new modalities, features, and form factors that make AI useful across every context of daily life.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;User Champion&lt;/strong&gt;: Deeply understand what drives people to try, love, and recommend Claude. Build feedback systems that surface user needs, identify friction, and inform product priorities. Drive sustainable growth through product excellence.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Consumer Product Excellence:&lt;/strong&gt; Ship experiences that feel considered: intuitive interactions, thoughtful defaults, and capabilities that surprise and delight. Obsess over the details that create products people love—onboarding flows, error states, performance, and polish.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Product Execution at Scale&lt;/strong&gt;: Partner with engineering and design on products serving millions of daily users. Navigate the unique challenges of consumer AI: managing user expectations, building trust, ensuring safety, and creating experiences that work for everyone from students to professionals to casual users.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Research Partnership&lt;/strong&gt;: Work closely with research to identify which model capabilities will most delight users. Partner with trust &amp;amp; safety to build products that are both capable and responsible. Collaborate with marketing and communications to tell Claude&#39;s story authentically.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2&gt;&lt;strong&gt;You may be a good fit if you have:&lt;/strong&gt;&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;10+ years of progressive experience in product management, including at least 5 years in senior roles leading consumer products&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Track record of building consumer products with millions of users that people genuinely love&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Appreciation for the responsibility that comes with building AI products people rely on daily&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Deep experience with consumer growth, retention, and engagement and opinions about what metrics actually matter&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Strong design sensibility and experience partnering closely with design teams on consumer experiences&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience building products where user trust and safety are core to the value proposition&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience with AI or ML-powered products and a perspective on how AI will change consumer software&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Demonstrated success building and leading high-performing product teams&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Comfort with ambiguity and the ability to define product direction in a fast-moving, novel space&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;User-obsessed mindset with a habit of talking to users directly and frequently&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;Experience across multiple platforms (web, mobile, desktop) and an understanding of how context shapes product design&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;&lt;div class=&quot;content-pay-transparency&quot;&gt;&lt;div class=&quot;pay-input&quot;&gt;&lt;div class=&quot;description&quot;&gt;&lt;p&gt;The annual compensation range for this role is below. For sales roles, the range provided is the role’s On Target Earnings (&quot;OTE&quot;) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. Our total compensation package for full-time employees includes equity and benefits.&lt;/p&gt;&lt;/div&gt;&lt;div class=&quot;title&quot;&gt;Annual Salary:&lt;/div&gt;&lt;div class=&quot;pay-range&quot;&gt;&lt;span&gt;$385,000&lt;/span&gt;&lt;span class=&quot;divider&quot;&gt;&amp;mdash;&lt;/span&gt;&lt;span&gt;$460,000 USD&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;content-conclusion&quot;&gt;&lt;h2&gt;&lt;strong&gt;Logistics&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Education requirements: &lt;/strong&gt;We require at least a Bachelor&#39;s degree in a related field or equivalent experience.&lt;strong&gt;&lt;br&gt;&lt;br&gt;Location-based hybrid policy:&lt;/strong&gt; Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.&lt;/p&gt;\n&lt;p&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Visa sponsorship:&lt;/strong&gt;&amp;nbsp;We do sponsor visas! However, we aren&#39;t able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;We encourage you to apply even if you do not believe you meet every single qualification.&lt;/strong&gt; Not all strong candidates will meet every single qualification as listed.&amp;nbsp; Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you&#39;re interested in this work. We think AI systems like the ones we&#39;re building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.&lt;br&gt;&lt;br&gt;&lt;strong data-stringify-type=&quot;bold&quot;&gt;Your safety matters to us.&lt;/strong&gt;&amp;nbsp;To protect yourself from potential scams, remember that Anthropic recruiters only contact you from&amp;nbsp;@anthropic.com&amp;nbsp;email addresses. Be cautious of emails from other domains. Legitimate Anthropic recruiters will never ask for money, fees, or banking information before your first day. If you&#39;re ever unsure about a communication, don&#39;t click any links—visit&amp;nbsp;&lt;u data-stringify-type=&quot;underline&quot;&gt;&lt;a class=&quot;c-link c-link--underline&quot; href=&quot;http://anthropic.com/careers&quot; target=&quot;_blank&quot; data-stringify-link=&quot;http://anthropic.com/careers&quot; data-sk=&quot;tooltip_parent&quot; data-remove-tab-index=&quot;true&quot;&gt;anthropic.com/careers&lt;/a&gt;&lt;/u&gt;&amp;nbsp;directly for confirmed position openings.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;How we&#39;re different&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;We believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact — advancing our long-term goals of steerable, trustworthy AI — rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We&#39;re an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.&lt;/p&gt;\n&lt;p&gt;The easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI &amp;amp; Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.&lt;/p&gt;\n&lt;h2&gt;&lt;strong&gt;Come work with us!&lt;/strong&gt;&lt;/h2&gt;\n&lt;p&gt;Anthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. &lt;strong data-stringify-type=&quot;bold&quot;&gt;Guidance on Candidates&#39; AI Usage:&lt;/strong&gt;&amp;nbsp;Learn about&amp;nbsp;&lt;a class=&quot;c-link&quot; href=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; target=&quot;_blank&quot; data-stringify-link=&quot;https://www.anthropic.com/candidate-ai-guidance&quot; data-sk=&quot;tooltip_parent&quot;&gt;our policy&lt;/a&gt;&amp;nbsp;for using AI in our application process&lt;/p&gt;&lt;/div&gt;",
    "_raw": {
      "source": "greenhouse",
      "original_id": 5042055008
    },
    "job_posted_at": "1h",
    "description_platform": "greenhouse",
    "description_success": true
  }
]