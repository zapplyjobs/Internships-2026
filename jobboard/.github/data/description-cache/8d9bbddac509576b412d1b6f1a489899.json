{
  "url": "https://cooperstandard.wd1.myworkdayjobs.com/CooperStandard/job/Livonia-Michigan/Data-Science-Intern_R017907",
  "data": {
    "success": true,
    "platform": "workday",
    "description": "Job Description:The RoleWe are seeking a Data Science Intern to help develop and deliver the core products of our AI stack: trained models of process physics and AI controllers for edge deployment. Unlike a traditional theoretical research role, this position focuses heavily on implementation. You will define, automate, and optimize the entire analytics path—including signal processing, training, validation, deployment, and monitoring. You will work within a dynamic team to deploy models for inference within mission-critical manufacturing environments, optimizing for real-time response.Key ResponsibilitiesPipeline & Code Development: Design, develop, and iterate on algorithms using robust coding practices, including the use of code development tools like GitHub.Model Deployment: Experience deploying models in local or cloud environments. You will help deploy policies to the edge where they run real-time inference and continuously make adjustments to physical hardware.Data Engineering: Assess new data sources and interact with data ingestion pipelines or data warehouses.Automation: Automate the creation of automated controls and the analytics path to ensure the technology is scalable.Collaboration: Collaborate with process domain experts to determine what data to collect to ensure high data quality.Required Technical SkillsWe prioritize candidates with strong software engineering fundamentals and fluency in modern data stacks.Core Languages: Proficiency in Python is required.Libraries & Frameworks: Expertise with data analysis and ML libraries, specifically TensorFlow, PyTorch, Numpy, Pandas, Scikit-learn, and Spark ML.DevOps & Environment: Fluency with standard DevOps tools. Experience working on Linux ML libraries and compilation.Cloud Technologies: Familiarity with cloud technologies such as AWS, Azure, Databricks, or Hadoop/Spark.Data Visualization: Expertise in data visualization techniques to present actionable insights.Domain KnowledgeWhile programming is the primary focus, familiarity with the following application areas is essential:Time Series & Deep Learning: Demonstrated skills in time series data analysis and Deep Learning architectures including LSTM, RNN, and CNN.Reinforcement Learning: Understanding of reinforcement learning techniques for developing optimal control policies.Qualifications & Soft SkillsEducation: Currently pursuing or recently completed a Master’s Degree or PhD in Computer Science, Engineering, or Science.Problem Solving: Intellectual curiosity, entrepreneurial drive, and innovative thinking.Communication: Ability to explain moderately complex information in a concise manner to both specialists and non-technical audiences.What's In It for YouCompetitive compensation.The opportunity to join a startup with funding, a major customer, and a world-class tech center.Access to full-scale production lines to generate proprietary data and test your code on physical hardware.Position Type:Intern (Trainee)Additional Locations: Additional Information:Cooper Standard is proud of its diverse workforce and committed to providing equal employment opportunities to applicants and employees without regard to race, color, religion, sex, national origin, genetic information, physical or mental disability, age, veteran or military status, or any other characteristic protected by applicable law. We are dedicated to creating an environment at work that not only values diversity but also encourages inclusion and a sense of belonging. We firmly believe that a diverse workplace fosters an environment where our employees can flourish and provide superior service to our customers. Because we recognize and value the range of ways in which people acquire experiences, whether personal, professional, or via education or volunteerism, we invite interested applicants to evaluate the key duties and requirements and apply for any opportunities that fit your experience and qualifications. Applicants with disabilities may be entitled to reasonable accommodations under the Americans with Disabilities Act, as well as certain state and/or local laws. If you believe you require such assistance to complete our online application or to participate in an interview, you (or someone on your behalf) may request assistance by emailing recruitment@cooperstandard.com with a description of the accommodation you seek. Application materials submitted to this email address will not be considered.Remote Status:Hybrid",
    "requirements": [
      "Core Languages: Proficiency in Python is required.",
      "Education: Currently pursuing or recently completed a Master’s Degree or PhD in Computer Science, Engineering, or Science."
    ],
    "responsibilities": [
      "Pipeline & Code Development: Design, develop, and iterate on algorithms using robust coding practices, including the use of code development tools like GitHub.",
      "Model Deployment: Experience deploying models in local or cloud environments. You will help deploy policies to the edge where they run real-time inference and continuously make adjustments to physical hardware.",
      "Collaboration: Collaborate with process domain experts to determine what data to collect to ensure high data quality.",
      "Reinforcement Learning: Understanding of reinforcement learning techniques for developing optimal control policies."
    ],
    "metadata": {
      "source": "workday-puppeteer",
      "url": "https://cooperstandard.wd1.myworkdayjobs.com/CooperStandard/job/Livonia-Michigan/Data-Science-Intern_R017907",
      "fetchedAt": "2026-01-29T23:41:21.658Z"
    }
  },
  "cachedAt": 1769730081658
}